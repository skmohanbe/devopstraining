=~=~=~=~=~=~=~=~=~=~=~= PuTTY log 2020.01.24 22:16:52 =~=~=~=~=~=~=~=~=~=~=~=
Using username "root".
Authenticating with public key "rsa-key-20200124" from agent
Welcome to Ubuntu 16.04.6 LTS (GNU/Linux 4.4.0-1099-aws x86_64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/advantage

 * Overheard at KubeCon: "microk8s.status just blew my mind".

     https://microk8s.io/docs/commands#microk8s.status

  Get cloud support with Ubuntu Advantage Cloud Guest:
    http://www.ubuntu.com/business/services/cloud

15 packages can be updated.
0 updates are security updates.

New release '18.04.3 LTS' available.
Run 'do-release-upgrade' to upgrade to it.


*** System restart required ***
Last login: Fri Jan 24 13:26:51 2020 from 49.37.206.100
root@master1:~# cat/ /etc/hosts
127.0.0.1 localhost

# The following lines are desirable for IPv6 capable hosts
::1 ip6-localhost ip6-loopback
fe00::0 ip6-localnet
ff00::0 ip6-mcastprefix
ff02::1 ip6-allnodes
ff02::2 ip6-allrouters
ff02::3 ip6-allhosts
# Cloud Server Hostname mapping
172.31.122.25   rameshhms1c.mylabserver.com
172.31.122.25master1
172.31.125.181master2
172.31.115.2master3
172.31.122.147worker1
172.31.123.142loadbalancer
root@master1:~# 
root@master1:~# mkdir -p /etc/etcd /var/lib/etcd
root@master1:~# ls-l/var/lib/etcdls -l              ls-lls -l /var/lib/etcd
total 0
root@master1:~# ls -l /var/lib/etcdmkdir -p /etc/etcdcat /etc/hostsfor instance in master2 master3; do ssh -n $instance "mkdir -p /etc/etcd /var/lib/etcd";done-n "ls -ld
drwxr-xr-x 2 root root 4096 Jan 24 13:32 /etc/etcd
drwxr-xr-x 2 root root 4096 Jan 24 13:32 /var/lib/etcd
drwxr-xr-x 2 root root 4096 Jan 24 13:32 /etc/etcd
drwxr-xr-x 2 root root 4096 Jan 24 13:32 /var/lib/etcd
root@master1:~# 
root@master1:~# cp /root/keys/ca.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /etc/etcd/
root@master1:~# 
root@master1:~# 
root@master1:~# cp /root/keys/ca.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /etc/etcd/for instance in master2 master3; do ssh -n $instance "ls -ld /etc/etcd /var/lib/etcd";done";done";done";done;done";done";done";done;dones;donec;donep;done ;done/;doner;doneo;doneo;donet;done/;donek;donee;doney;dones;done/;donec;donea;done.;donec;doner;donet;done ;done/;doner;doneo;doneo;donet;done/;donek;donee;doney;dones;done/;donee;donet;donec;doned;done-;dones;donee;doner;donev;donee;doner;done.;donek;donee;doney;done ;done/;doner;doneo;doneo;donet;done/;donek;donee;doney;dones;done/;donee;donet;donec;doned;done-;dones;donee;doner;done root@master1:~# v;doneeroot@master1:~# e;doneroot@master1:~# r;doneroot@master1:~# .;doneroot@master1:~# c;doner;donet;done ;done/;donee;donet;donec;done/;donee;donet;donec;doned;done/;done$/etc/etcd/;donei/etc/etcd/;donen/etc/etcd/;dones/etc/etcd/;donet/etc/etcd/;donea/etc/etcd/;donen/etc/etcd/;donec/etc/etcd/;donee/etc/etcd/;done:/etc/etcd/;done
ca.crt                                                                                       0%    0     0.0KB/s   --:-- ETAca.crt                                                                                     100%  989     1.0KB/s   00:00    
etcd-server.key                                                                              0%    0     0.0KB/s   --:-- ETAetcd-server.key                                                                            100% 1679     1.6KB/s   00:00    
etcd-server.crt                                                                              0%    0     0.0KB/s   --:-- ETAetcd-server.crt                                                                            100% 1078     1.1KB/s   00:00    
ca.crt                                                                                       0%    0     0.0KB/s   --:-- ETAca.crt                                                                                     100%  989     1.0KB/s   00:00    
etcd-server.key                                                                              0%    0     0.0KB/s   --:-- ETAetcd-server.key                                                                            100% 1679     1.6KB/s   00:00    
etcd-server.crt                                                                              0%    0     0.0KB/s   --:-- ETAetcd-server.crt                                                                            100% 1078     1.1KB/s   00:00    
root@master1:~# 
root@master1:~# ip addr show ens5| grep "inet " | awk '{print $2}' | cut -d / -f 1
172.31.122.25
root@master1:~# INTERNAL_IP=$(ip addr show ens5| grep "inet " | awk '{print $2}' | cut -d / -f 1)
root@master1:~# ETCD_NAME=$(hostname -s)
root@master1:~# cd keys/
root@master1:~/keys# cat <<EOF | sudo tee /etc/systemd/system/etcd.service
> [Unit]
> Description=etcd
> Documentation=https://github.com/coreos
> 
> [Service]
> ExecStart=/usr/local/bin/etcd \\
>   --name ${ETCD_NAME} \\
>   --cert-file=/etc/etcd/etcd-server.crt \\
>   --key-file=/etc/etcd/etcd-server.key \\
>   --peer-cert-file=/etc/etcd/etcd-server.crt \\
>   --peer-key-file=/etc/etcd/etcd-server.key \\
>   --trusted-ca-file=/etc/etcd/ca.crt \\
>   --peer-trusted-ca-file=/etc/etcd/ca.crt \\
>   --peer-client-cert-auth \\
>   --client-cert-auth \\
>   --initial-advertise-peer-urls https://${INTERNAL_IP}:2380 \\
>   --listen-peer-urls https://${INTERNAL_IP}:2380 \\
>   --listen-client-urls https://${INTERNAL_IP}:2379,https://127.0.0.1:2379 \\
>   --advertise-client-urls https://${INTERNAL_IP}:2379 \\
>   --initial-cluster-token etcd-cluster-0 \\
>   --initial-cluster master1=https://172.31.16.151:2380,master2=https://172.31.24.188:2380,master3=https://172.31.22.217:238 0 \\
>   --initial-cluster-state new \\
>   --data-dir=/var/lib/etcd
> Restart=on-failure
> RestartSec=5
> 
> [Install]
> WantedBy=multi-user.target
> EOF
[Unit]
Description=etcd
Documentation=https://github.com/coreos

[Service]
ExecStart=/usr/local/bin/etcd \
  --name master1 \
  --cert-file=/etc/etcd/etcd-server.crt \
  --key-file=/etc/etcd/etcd-server.key \
  --peer-cert-file=/etc/etcd/etcd-server.crt \
  --peer-key-file=/etc/etcd/etcd-server.key \
  --trusted-ca-file=/etc/etcd/ca.crt \
  --peer-trusted-ca-file=/etc/etcd/ca.crt \
  --peer-client-cert-auth \
  --client-cert-auth \
  --initial-advertise-peer-urls https://172.31.122.25:2380 \
  --listen-peer-urls https://172.31.122.25:2380 \
  --listen-client-urls https://172.31.122.25:2379,https://127.0.0.1:2379 \
  --advertise-client-urls https://172.31.122.25:2379 \
  --initial-cluster-token etcd-cluster-0 \
  --initial-cluster master1=https://172.31.16.151:2380,master2=https://172.31.24.188:2380,master3=https://172.31.22.217:2380 \
  --initial-cluster-state new \
  --data-dir=/var/lib/etcd
Restart=on-failure
RestartSec=5

[Install]
WantedBy=multi-user.target
root@master1:~/keys# 
root@master1:~/keys# rm /etc/systemd/system/etcd.service
root@master1:~/keys# 
root@master1:~/keys# 
root@master1:~/keys# cat /etc/hosts
127.0.0.1 localhost

# The following lines are desirable for IPv6 capable hosts
::1 ip6-localhost ip6-loopback
fe00::0 ip6-localnet
ff00::0 ip6-mcastprefix
ff02::1 ip6-allnodes
ff02::2 ip6-allrouters
ff02::3 ip6-allhosts
# Cloud Server Hostname mapping
172.31.122.25   rameshhms1c.mylabserver.com
172.31.122.25master1
172.31.125.181master2
172.31.115.2master3
172.31.122.147worker1
172.31.123.142loadbalancer
root@master1:~/keys# cat <<EOF | sudo tee /etc/systemd/system/etcd.service
> [Unit]
> Description=etcd
> Documentation=https://github.com/coreos
> 
> [Service]
> ExecStart=/usr/local/bin/etcd \\
>   --name ${ETCD_NAME} \\
>   --cert-file=/etc/etcd/etcd-server.crt \\
>   --key-file=/etc/etcd/etcd-server.key \\
>   --peer-cert-file=/etc/etcd/etcd-server.crt \\
>   --peer-key-file=/etc/etcd/etcd-server.key \\
>   --trusted-ca-file=/etc/etcd/ca.crt \\
>   --peer-trusted-ca-file=/etc/etcd/ca.crt \\
Restart=on-failure
RestartSec=5

[Install]
>   --peer-client-cert-auth \\
>   --client-cert-auth \\
>   --initial-advertise-peer-urls https://${INTERNAL_IP}:2380 \\
>   --listen-peer-urls https://${INTERNAL_IP}:2380 \\
>   --listen-client-urls https://${INTERNAL_IP}:2379,https://127.0.0.1:2379 \\
>   --advertise-client-urls https://${INTERNAL_IP}:2379 \\
>   --initial-cluster-token etcd-cluster-0 \\
>   --initial-cluster master1=https://172.31.122.25:2380,master2=https://172.31.125.181:2380,master3=https://172.31.115.2:238 0 \\
>   --initial-cluster-state new \\
>   --data-dir=/var/lib/etcd
> Restart=on-failure
> RestartSec=5
> 
> [Install]
> WantedBy=multi-user.target
> EOF
[Unit]
Description=etcd
Documentation=https://github.com/coreos

[Service]
ExecStart=/usr/local/bin/etcd \
  --name master1 \
  --cert-file=/etc/etcd/etcd-server.crt \
  --key-file=/etc/etcd/etcd-server.key \
  --peer-cert-file=/etc/etcd/etcd-server.crt \
  --peer-key-file=/etc/etcd/etcd-server.key \
  --trusted-ca-file=/etc/etcd/ca.crt \
  --peer-trusted-ca-file=/etc/etcd/ca.crt \
  --peer-client-cert-auth \
  --client-cert-auth \
  --initial-advertise-peer-urls https://172.31.122.25:2380 \
  --listen-peer-urls https://172.31.122.25:2380 \
  --listen-client-urls https://172.31.122.25:2379,https://127.0.0.1:2379 \
  --advertise-client-urls https://172.31.122.25:2379 \
  --initial-cluster-token etcd-cluster-0 \
  --initial-cluster master1=https://172.31.122.25:2380,master2=https://172.31.125.181:2380,master3=https://172.31.115.2:2380 \
  --initial-cluster-state new \
  --data-dir=/var/lib/etcd
Restart=on-failure
RestartSec=5

[Install]
WantedBy=multi-user.target
root@master1:~/keys# systemctl daemon-reload
root@master1:~/keys# systemctl enable etcd
Created symlink from /etc/systemd/system/multi-user.target.wants/etcd.service to /etc/systemd/system/etcd.service.
root@master1:~/keys# systemctl start etcd
root@master1:~/keys# systemctl status etcd
 etcd.service - etcd
   Loaded: loaded (/etc/systemd/system/etcd.service; enabled; vendor preset: enabled)
   Active: active (running) since Fri 2020-01-24 16:51:38 UTC; 5s ago
     Docs: https://github.com/coreos
 Main PID: 2829 (etcd)
    Tasks: 8
   Memory: 4.6M
      CPU: 142ms
   CGroup: /system.slice/etcd.service
           2829 /usr/local/bin/etcd --name master1 --cert-file=/etc/etcd/etcd-server.crt --key-file=/etc/etcd/etcd-server.k

Jan 24 16:51:40 master1 etcd[2829]: c54eae14ec78233 received MsgVoteResp from c54eae14ec78233 at term 3
Jan 24 16:51:40 master1 etcd[2829]: c54eae14ec78233 [logterm: 1, index: 3] sent MsgVote request to 2356cc8de1dc7a23 at term 3
Jan 24 16:51:40 master1 etcd[2829]: c54eae14ec78233 [logterm: 1, index: 3] sent MsgVote request to 83b0c9b79ada9b8d at term 3
Jan 24 16:51:42 master1 etcd[2829]: c54eae14ec78233 is starting a new election at term 3
Jan 24 16:51:42 master1 etcd[2829]: c54eae14ec78233 became candidate at term 4
Jan 24 16:51:42 master1 etcd[2829]: c54eae14ec78233 received MsgVoteResp from c54eae14ec78233 at term 4
Jan 24 16:51:42 master1 etcd[2829]: c54eae14ec78233 [logterm: 1, index: 3] sent MsgVote request to 2356cc8de1dc7a23 at term 4
Jan 24 16:51:42 master1 etcd[2829]: c54eae14ec78233 [logterm: 1, index: 3] sent MsgVote request to 83b0c9b79ada9b8d at term 4
Jan 24 16:51:43 master1 etcd[2829]: health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: con
Jan 24 16:51:43 master1 etcd[2829]: health check for peer 83b0c9b79ada9b8d could not connect: dial tcp 172.31.125.181:2380: c
lines 1-21/21 (END)lines 1-21/21 (END)root@master1:~/keys# ETCDCTL_API=3 etcdctl -w table member list  --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.cr t  --cert=/etc/etcd/etcd-server.crt --key=/etc/etcd/etcd-server.key
Error: context deadline exceeded
root@master1:~/keys# 
root@master1:~/keys# ETCDCTL_API=3 etcdctl -w table member list  --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crtt  --cert=/etc/etcd/etcd-server.crt --key=/etc/etcd/etcd-server.keysystemctl status etcd

 etcd.service - etcd
   Loaded: loaded (/etc/systemd/system/etcd.service; enabled; vendor preset: enabled)
   Active: active (running) since Fri 2020-01-24 16:51:38 UTC; 49s ago
     Docs: https://github.com/coreos
 Main PID: 2829 (etcd)
    Tasks: 8
   Memory: 10.3M
      CPU: 919ms
   CGroup: /system.slice/etcd.service
           2829 /usr/local/bin/etcd --name master1 --cert-file=/etc/etcd/etcd-server.crt --key-file=/etc/etcd/etcd-server.k

Jan 24 16:52:25 master1 etcd[2829]: c54eae14ec78233 became candidate at term 36
Jan 24 16:52:25 master1 etcd[2829]: c54eae14ec78233 received MsgVoteResp from c54eae14ec78233 at term 36
Jan 24 16:52:25 master1 etcd[2829]: c54eae14ec78233 [logterm: 1, index: 3] sent MsgVote request to 2356cc8de1dc7a23 at term 3
Jan 24 16:52:25 master1 etcd[2829]: c54eae14ec78233 [logterm: 1, index: 3] sent MsgVote request to 83b0c9b79ada9b8d at term 3
Jan 24 16:52:26 master1 etcd[2829]: c54eae14ec78233 is starting a new election at term 36
Jan 24 16:52:26 master1 etcd[2829]: c54eae14ec78233 became candidate at term 37
Jan 24 16:52:26 master1 etcd[2829]: c54eae14ec78233 received MsgVoteResp from c54eae14ec78233 at term 37
Jan 24 16:52:26 master1 etcd[2829]: c54eae14ec78233 [logterm: 1, index: 3] sent MsgVote request to 2356cc8de1dc7a23 at term 3
Jan 24 16:52:26 master1 etcd[2829]: c54eae14ec78233 [logterm: 1, index: 3] sent MsgVote request to 83b0c9b79ada9b8d at term 3
Jan 24 16:52:27 master1 etcd[2829]: publish error: etcdserver: request timed out
lines 1-21/21 (END)root@master1:~/keys# cat /etc/systemd/system/etcd.service
[Unit]
Description=etcd
Documentation=https://github.com/coreos

[Service]
ExecStart=/usr/local/bin/etcd \
  --name master1 \
  --cert-file=/etc/etcd/etcd-server.crt \
  --key-file=/etc/etcd/etcd-server.key \
  --peer-cert-file=/etc/etcd/etcd-server.crt \
  --peer-key-file=/etc/etcd/etcd-server.key \
  --trusted-ca-file=/etc/etcd/ca.crt \
  --peer-trusted-ca-file=/etc/etcd/ca.crt \
  --peer-client-cert-auth \
  --client-cert-auth \
  --initial-advertise-peer-urls https://172.31.122.25:2380 \
  --listen-peer-urls https://172.31.122.25:2380 \
  --listen-client-urls https://172.31.122.25:2379,https://127.0.0.1:2379 \
  --advertise-client-urls https://172.31.122.25:2379 \
  --initial-cluster-token etcd-cluster-0 \
  --initial-cluster master1=https://172.31.122.25:2380,master2=https://172.31.125.181:2380,master3=https://172.31.115.2:2380 \
  --initial-cluster-state new \
  --data-dir=/var/lib/etcd
Restart=on-failure
RestartSec=5

[Install]
WantedBy=multi-user.target
root@master1:~/keys# cat /etc/systemd/system/etcd.servicesystemctl status etcd
 etcd.service - etcd
   Loaded: loaded (/etc/systemd/system/etcd.service; enabled; vendor preset: enabled)
   Active: active (running) since Fri 2020-01-24 16:51:38 UTC; 1min 20s ago
     Docs: https://github.com/coreos
 Main PID: 2829 (etcd)
    Tasks: 8
   Memory: 11.8M
      CPU: 1.460s
   CGroup: /system.slice/etcd.service
           2829 /usr/local/bin/etcd --name master1 --cert-file=/etc/etcd/etcd-server.crt --key-file=/etc/etcd/etcd-server.k

Jan 24 16:52:57 master1 etcd[2829]: c54eae14ec78233 received MsgVoteResp from c54eae14ec78233 at term 57
Jan 24 16:52:57 master1 etcd[2829]: c54eae14ec78233 [logterm: 1, index: 3] sent MsgVote request to 2356cc8de1dc7a23 at term 5
Jan 24 16:52:57 master1 etcd[2829]: c54eae14ec78233 [logterm: 1, index: 3] sent MsgVote request to 83b0c9b79ada9b8d at term 5
Jan 24 16:52:58 master1 etcd[2829]: health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: con
Jan 24 16:52:58 master1 etcd[2829]: health check for peer 83b0c9b79ada9b8d could not connect: dial tcp 172.31.125.181:2380: c
Jan 24 16:52:58 master1 etcd[2829]: c54eae14ec78233 is starting a new election at term 57
Jan 24 16:52:58 master1 etcd[2829]: c54eae14ec78233 became candidate at term 58
Jan 24 16:52:58 master1 etcd[2829]: c54eae14ec78233 received MsgVoteResp from c54eae14ec78233 at term 58
Jan 24 16:52:58 master1 etcd[2829]: c54eae14ec78233 [logterm: 1, index: 3] sent MsgVote request to 2356cc8de1dc7a23 at term 5
Jan 24 16:52:58 master1 etcd[2829]: c54eae14ec78233 [logterm: 1, index: 3] sent MsgVote request to 83b0c9b79ada9b8d at term 5
lines 1-21/21 (END)lines 1-21/21 (END)root@master1:~/keys# systemctl status etcdcat /etc/systemd/system/etcd.servicesystemctl status etcdETCDCTL_API=3 etcdctl -w table member list  --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crtt  --cert=/etc/etcd/etcd-server.crt --key=/etc/etcd/etcd-server.key
Error: context deadline exceeded
root@master1:~/keys# 
root@master1:~/keys# ETCDCTL_API=3 etcdctl -w table member list  --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crtt  --cert=/etc/etcd/etcd-server.crt --key=/etc/etcd/etcd-server.key member list  --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt root@master1:~/keys#  member list  --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt  root@master1:~/keys#  member list  --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt 
 member list  --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt  --root@master1:~/keys#  member list  --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt  --croot@master1:~/keys# member list  --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt  --ceroot@master1:~/keys#  member list  --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt  --cerroot@master1:~/keys#  member list  --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt  --certroot@master1:~/keys# member list  --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt  --cert=root@master1:~/keys#  member list  --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt  --cert=/root@master1:~/keys#  member list  --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt  --cert=/eroot@master1:~/keys# tl member list  --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt  --cert=/eroot@master1:~/keys# 

Error: context deadline exceeded
root@master1:~/keys# etcd
etcd     etcdctl  
root@master1:~/keys# etcdctl 
NAME:
   etcdctl - A simple command line client for etcd.

WARNING:
   Environment variable ETCDCTL_API is not set; defaults to etcdctl v2.
   Set environment variable ETCDCTL_API=3 to use v3 API or ETCDCTL_API=2 to use v2 API.

USAGE:
   etcdctl [global options] command [command options] [arguments...]
   
VERSION:
   3.3.9
   
COMMANDS:
     backup          backup an etcd directory
     cluster-health  check the health of the etcd cluster
     mk              make a new key with a given value
     mkdir           make a new directory
     rm              remove a key or a directory
     rmdir           removes the key if it is an empty directory or a key-value pair
     get             retrieve the value of a key
     ls              retrieve a directory
     set             set the value of a key
     setdir          create a new directory or update an existing directory TTL
     update          update an existing key with a given value
     updatedir       update an existing directory
     watch           watch a key for changes
     exec-watch      watch a key for changes and exec an executable
     member          member add, remove and list subcommands
     user            user add, grant and revoke subcommands
     role            role add, grant and revoke subcommands
     auth            overall auth controls
     help, h         Shows a list of commands or help for one command

GLOBAL OPTIONS:
   --debug                          output cURL commands which can be used to reproduce the request
   --no-sync                        don't synchronize cluster information before sending request
   --output simple, -o simple       output response in the given format (simple, `extended` or `json`) (default: "simple")
   --discovery-srv value, -D value  domain name to query for SRV records describing cluster endpoints
   --insecure-discovery             accept insecure SRV records describing cluster endpoints
   --peers value, -C value          DEPRECATED - "--endpoints" should be used instead
   --endpoint value                 DEPRECATED - "--endpoints" should be used instead
   --endpoints value                a comma-delimited list of machine addresses in the cluster (default: "http://127.0.0.1:2379,http://127.0.0.1:4001")
   --cert-file value                identify HTTPS client using this SSL certificate file
   --key-file value                 identify HTTPS client using this SSL key file
   --ca-file value                  verify certificates of HTTPS-enabled servers using this CA bundle
   --username value, -u value       provide username[:password] and prompt if password is not supplied.
   --timeout value                  connection timeout per request (default: 2s)
   --total-timeout value            timeout for the command execution (except watch) (default: 5s)
   --help, -h                       show help
   --version, -v                    print the version
   
root@master1:~/keys# etcdctl member list
client: etcd cluster is unavailable or misconfigured; error #0: client: endpoint http://127.0.0.1:2379 exceeded header timeout
; error #1: dial tcp 127.0.0.1:4001: connect: connection refused

root@master1:~/keys# etcdctl member list http://127.0.0.1:2379
No arguments accepted
root@master1:~/keys# etcdctl member list http://127.0.0.1:2379 http://127.0.0.1:2379-http://127.0.0.1:2379-http://127.0.0.1:2379ehttp://127.0.0.1:2379http://127.0.0.1:2379ehttp://127.0.0.1:2379nhttp://127.0.0.1:2379dhttp://127.0.0.1:2379phttp://127.0.0.1:2379ohttp://127.0.0.1:2379ihttp://127.0.0.1:2379nhttp://127.0.0.1:2379thttp://127.0.0.1:2379=http://127.0.0.1:2379
Incorrect Usage.

NAME:
   etcdctl member list - enumerate existing cluster members

USAGE:
   etcdctl member list  
flag provided but not defined: -endpoint
root@master1:~/keys# etcdctl member list --endpoint=http://127.0.0.1:2379s=http://127.0.0.1:2379
Incorrect Usage.

NAME:
   etcdctl member list - enumerate existing cluster members

USAGE:
   etcdctl member list  
flag provided but not defined: -endpoints
root@master1:~/keys# etcdctl member list --endpoints=http://127.0.0.1:2379 --cacert=/etc/etcd/ca.crt  --cert=/etc/etcd/etcd-s erver.crt --key=/etc/etcd/etcd-server.key
Incorrect Usage.

NAME:
   etcdctl member list - enumerate existing cluster members

USAGE:
   etcdctl member list  
flag provided but not defined: -endpoints
root@master1:~/keys# ls -l /etc/etcd/ca.crt
-rw-r--r-- 1 root root 989 Jan 24 16:48 /etc/etcd/ca.crt
root@master1:~/keys# ls -l /etc/etcd/etcd-server.crt
-rw-r--r-- 1 root root 1078 Jan 24 16:48 /etc/etcd/etcd-server.crt
root@master1:~/keys# ls -l /etc/etcd/etcd-server.key
-rw-r--r-- 1 root root 1679 Jan 24 16:48 /etc/etcd/etcd-server.key
root@master1:~/keys# ETCDCTL_API=3 etcdctl -w table member list  --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.cr t  --cert=/etc/etcd/etcd-server.crt --key=/etc/etcd/etcd-server.key

Error: context deadline exceeded
root@master1:~/keys# 
root@master1:~/keys# ssh master2
Welcome to Ubuntu 16.04.6 LTS (GNU/Linux 4.4.0-1099-aws x86_64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/advantage

 * Overheard at KubeCon: "microk8s.status just blew my mind".

     https://microk8s.io/docs/commands#microk8s.status

  Get cloud support with Ubuntu Advantage Cloud Guest:
    http://www.ubuntu.com/business/services/cloud

15 packages can be updated.
0 updates are security updates.

New release '18.04.3 LTS' available.
Run 'do-release-upgrade' to upgrade to it.


*** System restart required ***
Last login: Fri Jan 24 12:45:30 2020 from 172.31.122.25
root@master2:~# 
root@master2:~# INTERNAL_IP=$(ip addr show ens5| grep "inet " | awk '{print $2}' | cut -d / -f 1)
root@master2:~# ls -l /etc/etcd/
total 12
-rw-r--r-- 1 root root  989 Jan 24 16:49 ca.crt
-rw-r--r-- 1 root root 1078 Jan 24 16:49 etcd-server.crt
-rw-r--r-- 1 root root 1679 Jan 24 16:49 etcd-server.key
root@master2:~# 
root@master2:~# 
root@master2:~# ETCD_NAME=$(hostname -s)
root@master2:~# hostname -s
master2
root@master2:~# 
root@master2:~# cat <<EOF | sudo tee /etc/systemd/system/etcd.service
> [Unit]
> Description=etcd
> Documentation=https://github.com/coreos
> 
> [Service]
> ExecStart=/usr/local/bin/etcd \\
>   --name ${ETCD_NAME} \\
>   --cert-file=/etc/etcd/etcd-server.crt \\
>   --key-file=/etc/etcd/etcd-server.key \\
>   --peer-cert-file=/etc/etcd/etcd-server.crt \\
>   --peer-key-file=/etc/etcd/etcd-server.key \\
>   --trusted-ca-file=/etc/etcd/ca.crt \\
>   --peer-trusted-ca-file=/etc/etcd/ca.crt \\
>   --peer-client-cert-auth \\
>   --client-cert-auth \\
>   --initial-advertise-peer-urls https://${INTERNAL_IP}:2380 \\
>   --listen-peer-urls https://${INTERNAL_IP}:2380 \\
>   --listen-client-urls https://${INTERNAL_IP}:2379,https://127.0.0.1:2379 \\
>   --advertise-client-urls https://${INTERNAL_IP}:2379 \\
>   --initial-cluster-token etcd-cluster-0 \\
>   --initial-cluster master1=https://172.31.122.25:2380,master2=https://172.31.125.181:2380,master3=https://172.31.115.2:238 0 \\
>   --initial-cluster-state new \\
>   --data-dir=/var/lib/etcd
> Restart=on-failure
> RestartSec=5
> 
> [Install]
> WantedBy=multi-user.target
> EOF
[Unit]
Description=etcd
Documentation=https://github.com/coreos

[Service]
ExecStart=/usr/local/bin/etcd \
  --name master2 \
  --cert-file=/etc/etcd/etcd-server.crt \
  --key-file=/etc/etcd/etcd-server.key \
  --peer-cert-file=/etc/etcd/etcd-server.crt \
  --peer-key-file=/etc/etcd/etcd-server.key \
  --trusted-ca-file=/etc/etcd/ca.crt \
  --peer-trusted-ca-file=/etc/etcd/ca.crt \
  --peer-client-cert-auth \
  --client-cert-auth \
  --initial-advertise-peer-urls https://172.31.125.181:2380 \
  --listen-peer-urls https://172.31.125.181:2380 \
  --listen-client-urls https://172.31.125.181:2379,https://127.0.0.1:2379 \
  --advertise-client-urls https://172.31.125.181:2379 \
  --initial-cluster-token etcd-cluster-0 \
  --initial-cluster master1=https://172.31.122.25:2380,master2=https://172.31.125.181:2380,master3=https://172.31.115.2:2380 \
  --initial-cluster-state new \
  --data-dir=/var/lib/etcd
Restart=on-failure
RestartSec=5

[Install]
WantedBy=multi-user.target
root@master2:~# systemctl daemon-reload
root@master2:~# systemctl enable etcd
Created symlink from /etc/systemd/system/multi-user.target.wants/etcd.service to /etc/systemd/system/etcd.service.
root@master2:~# systemctl start etcd
root@master2:~# systemctl status etcd
 etcd.service - etcd
   Loaded: loaded (/etc/systemd/system/etcd.service; enabled; vendor preset: enabled)
   Active: active (running) since Fri 2020-01-24 16:56:47 UTC; 5s ago
     Docs: https://github.com/coreos
 Main PID: 29617 (etcd)
    Tasks: 10
   Memory: 6.9M
      CPU: 233ms
   CGroup: /system.slice/etcd.service
           29617 /usr/local/bin/etcd --name master2 --cert-file=/etc/etcd/etcd-server.crt --key-file=/etc/etcd/etcd-server.

Jan 24 16:56:47 master2 etcd[29617]: raft.node: 83b0c9b79ada9b8d elected leader c54eae14ec78233 at term 216
Jan 24 16:56:47 master2 etcd[29617]: ready to serve client requests
Jan 24 16:56:47 master2 etcd[29617]: forgot to set Type=notify in systemd service file?
Jan 24 16:56:47 master2 etcd[29617]: ready to serve client requests
Jan 24 16:56:47 master2 etcd[29617]: serving client requests on 127.0.0.1:2379
Jan 24 16:56:47 master2 etcd[29617]: serving client requests on 172.31.125.181:2379
Jan 24 16:56:47 master2 etcd[29617]: published {Name:master2 ClientURLs:[https://172.31.125.181:2379]} to cluster 1f9cddabdc8
Jan 24 16:56:47 master2 etcd[29617]: set the initial cluster version to 3.0
Jan 24 16:56:47 master2 etcd[29617]: enabled capabilities for version 3.0
Jan 24 16:56:52 master2 etcd[29617]: health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: co
lines 1-21/21 (END)lines 1-21/21 (END)root@master2:~# systemctl status etcd
 etcd.service - etcd
   Loaded: loaded (/etc/systemd/system/etcd.service; enabled; vendor preset: enabled)
   Active: active (running) since Fri 2020-01-24 16:56:47 UTC; 11s ago
     Docs: https://github.com/coreos
 Main PID: 29617 (etcd)
    Tasks: 10
   Memory: 7.7M
      CPU: 321ms
   CGroup: /system.slice/etcd.service
           29617 /usr/local/bin/etcd --name master2 --cert-file=/etc/etcd/etcd-server.crt --key-file=/etc/etcd/etcd-server.

Jan 24 16:56:47 master2 etcd[29617]: ready to serve client requests
Jan 24 16:56:47 master2 etcd[29617]: forgot to set Type=notify in systemd service file?
Jan 24 16:56:47 master2 etcd[29617]: ready to serve client requests
Jan 24 16:56:47 master2 etcd[29617]: serving client requests on 127.0.0.1:2379
Jan 24 16:56:47 master2 etcd[29617]: serving client requests on 172.31.125.181:2379
Jan 24 16:56:47 master2 etcd[29617]: published {Name:master2 ClientURLs:[https://172.31.125.181:2379]} to cluster 1f9cddabdc8
Jan 24 16:56:47 master2 etcd[29617]: set the initial cluster version to 3.0
Jan 24 16:56:47 master2 etcd[29617]: enabled capabilities for version 3.0
Jan 24 16:56:52 master2 etcd[29617]: health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: co
Jan 24 16:56:57 master2 etcd[29617]: health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: co
lines 1-21/21 (END)lines 1-21/21 (END)root@master2:~# systemctl status etcd
 etcd.service - etcd
   Loaded: loaded (/etc/systemd/system/etcd.service; enabled; vendor preset: enabled)
   Active: active (running) since Fri 2020-01-24 16:56:47 UTC; 14s ago
     Docs: https://github.com/coreos
 Main PID: 29617 (etcd)
    Tasks: 10
   Memory: 8.1M
      CPU: 369ms
   CGroup: /system.slice/etcd.service
           29617 /usr/local/bin/etcd --name master2 --cert-file=/etc/etcd/etcd-server.crt --key-file=/etc/etcd/etcd-server.

Jan 24 16:56:47 master2 etcd[29617]: ready to serve client requests
Jan 24 16:56:47 master2 etcd[29617]: forgot to set Type=notify in systemd service file?
Jan 24 16:56:47 master2 etcd[29617]: ready to serve client requests
Jan 24 16:56:47 master2 etcd[29617]: serving client requests on 127.0.0.1:2379
Jan 24 16:56:47 master2 etcd[29617]: serving client requests on 172.31.125.181:2379
Jan 24 16:56:47 master2 etcd[29617]: published {Name:master2 ClientURLs:[https://172.31.125.181:2379]} to cluster 1f9cddabdc8
Jan 24 16:56:47 master2 etcd[29617]: set the initial cluster version to 3.0
Jan 24 16:56:47 master2 etcd[29617]: enabled capabilities for version 3.0
Jan 24 16:56:52 master2 etcd[29617]: health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: co
Jan 24 16:56:57 master2 etcd[29617]: health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: co
lines 1-21/21 (END)lines 1-21/21 (END)root@master2:~# systemctl status etcd
 etcd.service - etcd
   Loaded: loaded (/etc/systemd/system/etcd.service; enabled; vendor preset: enabled)
   Active: active (running) since Fri 2020-01-24 16:56:47 UTC; 18s ago
     Docs: https://github.com/coreos
 Main PID: 29617 (etcd)
    Tasks: 10
   Memory: 8.5M
      CPU: 416ms
   CGroup: /system.slice/etcd.service
           29617 /usr/local/bin/etcd --name master2 --cert-file=/etc/etcd/etcd-server.crt --key-file=/etc/etcd/etcd-server.

Jan 24 16:56:47 master2 etcd[29617]: forgot to set Type=notify in systemd service file?
Jan 24 16:56:47 master2 etcd[29617]: ready to serve client requests
Jan 24 16:56:47 master2 etcd[29617]: serving client requests on 127.0.0.1:2379
Jan 24 16:56:47 master2 etcd[29617]: serving client requests on 172.31.125.181:2379
Jan 24 16:56:47 master2 etcd[29617]: published {Name:master2 ClientURLs:[https://172.31.125.181:2379]} to cluster 1f9cddabdc8
Jan 24 16:56:47 master2 etcd[29617]: set the initial cluster version to 3.0
Jan 24 16:56:47 master2 etcd[29617]: enabled capabilities for version 3.0
Jan 24 16:56:52 master2 etcd[29617]: health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: co
Jan 24 16:56:57 master2 etcd[29617]: health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: co
Jan 24 16:57:02 master2 etcd[29617]: health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: co
lines 1-21/21 (END)lines 1-21/21 (END)root@master2:~# systemctl status etcd
 etcd.service - etcd
   Loaded: loaded (/etc/systemd/system/etcd.service; enabled; vendor preset: enabled)
   Active: active (running) since Fri 2020-01-24 16:56:47 UTC; 30s ago
     Docs: https://github.com/coreos
 Main PID: 29617 (etcd)
    Tasks: 10
   Memory: 10.1M
      CPU: 586ms
   CGroup: /system.slice/etcd.service
           29617 /usr/local/bin/etcd --name master2 --cert-file=/etc/etcd/etcd-server.crt --key-file=/etc/etcd/etcd-server.

Jan 24 16:56:47 master2 etcd[29617]: serving client requests on 172.31.125.181:2379
Jan 24 16:56:47 master2 etcd[29617]: published {Name:master2 ClientURLs:[https://172.31.125.181:2379]} to cluster 1f9cddabdc8
Jan 24 16:56:47 master2 etcd[29617]: set the initial cluster version to 3.0
Jan 24 16:56:47 master2 etcd[29617]: enabled capabilities for version 3.0
Jan 24 16:56:52 master2 etcd[29617]: health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: co
Jan 24 16:56:57 master2 etcd[29617]: health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: co
Jan 24 16:57:02 master2 etcd[29617]: health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: co
Jan 24 16:57:07 master2 etcd[29617]: health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: co
Jan 24 16:57:12 master2 etcd[29617]: health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: co
Jan 24 16:57:17 master2 etcd[29617]: health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: co
lines 1-21/21 (END)lines 1-21/21 (END)root@master2:~# jounrnalctl -u etcd.service -l
-- Logs begin at Fri 2020-01-24 12:05:16 UTC, end at Fri 2020-01-24 16:57:27 UTC. --
Jan 24 16:56:47 master2 systemd[1]: Started etcd.
Jan 24 16:56:47 master2 etcd[29617]: etcd Version: 3.3.9
Jan 24 16:56:47 master2 etcd[29617]: Git SHA: fca8add78
Jan 24 16:56:47 master2 etcd[29617]: Go Version: go1.10.3
Jan 24 16:56:47 master2 etcd[29617]: Go OS/Arch: linux/amd64
Jan 24 16:56:47 master2 etcd[29617]: setting maximum number of CPUs to 2, total number of available CPUs is 2
Jan 24 16:56:47 master2 etcd[29617]: peerTLS: cert = /etc/etcd/etcd-server.crt, key = /etc/etcd/etcd-server.key, ca = , trust
Jan 24 16:56:47 master2 etcd[29617]: listening for peers on https://172.31.125.181:2380
Jan 24 16:56:47 master2 etcd[29617]: listening for client requests on 127.0.0.1:2379
Jan 24 16:56:47 master2 etcd[29617]: listening for client requests on 172.31.125.181:2379
Jan 24 16:56:47 master2 etcd[29617]: name = master2
Jan 24 16:56:47 master2 etcd[29617]: data dir = /var/lib/etcd
Jan 24 16:56:47 master2 etcd[29617]: member dir = /var/lib/etcd/member
Jan 24 16:56:47 master2 etcd[29617]: heartbeat = 100ms
Jan 24 16:56:47 master2 etcd[29617]: election = 1000ms
Jan 24 16:56:47 master2 etcd[29617]: snapshot count = 100000
Jan 24 16:56:47 master2 etcd[29617]: advertise client URLs = https://172.31.125.181:2379
Jan 24 16:56:47 master2 etcd[29617]: initial advertise peer URLs = https://172.31.125.181:2380
Jan 24 16:56:47 master2 etcd[29617]: initial cluster = master1=https://172.31.122.25:2380,master2=https://172.31.125.181:2380
Jan 24 16:56:47 master2 etcd[29617]: starting member 83b0c9b79ada9b8d in cluster 1f9cddabdc85ecd2
Jan 24 16:56:47 master2 etcd[29617]: 83b0c9b79ada9b8d became follower at term 0
Jan 24 16:56:47 master2 etcd[29617]: newRaft 83b0c9b79ada9b8d [peers: [], term: 0, commit: 0, applied: 0, lastindex: 0, lastt
Jan 24 16:56:47 master2 etcd[29617]: 83b0c9b79ada9b8d became follower at term 1
Jan 24 16:56:47 master2 etcd[29617]: simple token is not cryptographically signed
Jan 24 16:56:47 master2 etcd[29617]: starting peer c54eae14ec78233...
Jan 24 16:56:47 master2 etcd[29617]: started HTTP pipelining with peer c54eae14ec78233
Jan 24 16:56:47 master2 etcd[29617]: started streaming with peer c54eae14ec78233 (writer)
Jan 24 16:56:47 master2 etcd[29617]: started streaming with peer c54eae14ec78233 (writer)
Jan 24 16:56:47 master2 etcd[29617]: started peer c54eae14ec78233
Jan 24 16:56:47 master2 etcd[29617]: added peer c54eae14ec78233
Jan 24 16:56:47 master2 etcd[29617]: starting peer 2356cc8de1dc7a23...
Jan 24 16:56:47 master2 etcd[29617]: started HTTP pipelining with peer 2356cc8de1dc7a23
Jan 24 16:56:47 master2 etcd[29617]: started streaming with peer c54eae14ec78233 (stream MsgApp v2 reader)
Jan 24 16:56:47 master2 etcd[29617]: started streaming with peer c54eae14ec78233 (stream Message reader)
Jan 24 16:56:47 master2 etcd[29617]: started streaming with peer 2356cc8de1dc7a23 (writer)
Jan 24 16:56:47 master2 etcd[29617]: started streaming with peer 2356cc8de1dc7a23 (writer)
Jan 24 16:56:47 master2 etcd[29617]: started peer 2356cc8de1dc7a23
Jan 24 16:56:47 master2 etcd[29617]: added peer 2356cc8de1dc7a23
Jan 24 16:56:47 master2 etcd[29617]: starting server... [version: 3.3.9, cluster version: to_be_decided]
Jan 24 16:56:47 master2 etcd[29617]: started streaming with peer 2356cc8de1dc7a23 (stream MsgApp v2 reader)
Jan 24 16:56:47 master2 etcd[29617]: started streaming with peer 2356cc8de1dc7a23 (stream Message reader)
Jan 24 16:56:47 master2 etcd[29617]: added member c54eae14ec78233 [https://172.31.122.25:2380] to cluster 1f9cddabdc85ecd2
lines 1-43Jan 24 16:56:47 master2 etcd[29617]: added member 2356cc8de1dc7a23 [https://172.31.115.2:2380] to cluster 1f9cddabdc85ecd2
Jan 24 16:56:47 master2 etcd[29617]: added member 83b0c9b79ada9b8d [https://172.31.125.181:2380] to cluster 1f9cddabdc85ecd2
Jan 24 16:56:47 master2 etcd[29617]: ClientTLS: cert = /etc/etcd/etcd-server.crt, key = /etc/etcd/etcd-server.key, ca = , tru
Jan 24 16:56:47 master2 etcd[29617]: peer c54eae14ec78233 became active
Jan 24 16:56:47 master2 etcd[29617]: established a TCP streaming connection with peer c54eae14ec78233 (stream Message writer)
Jan 24 16:56:47 master2 etcd[29617]: established a TCP streaming connection with peer c54eae14ec78233 (stream MsgApp v2 write
Jan 24 16:56:47 master2 etcd[29617]: established a TCP streaming connection with peer c54eae14ec78233 (stream MsgApp v2 reade
Jan 24 16:56:47 master2 etcd[29617]: established a TCP streaming connection with peer c54eae14ec78233 (stream Message reader)
Jan 24 16:56:47 master2 etcd[29617]: 83b0c9b79ada9b8d [term: 1] received a MsgVote message with higher term from c54eae14ec78
Jan 24 16:56:47 master2 etcd[29617]: 83b0c9b79ada9b8d became follower at term 216
Jan 24 16:56:47 master2 etcd[29617]: 83b0c9b79ada9b8d [logterm: 1, index: 3, vote: 0] cast MsgVote for c54eae14ec78233 [logte
Jan 24 16:56:47 master2 etcd[29617]: raft.node: 83b0c9b79ada9b8d elected leader c54eae14ec78233 at term 216
Jan 24 16:56:47 master2 etcd[29617]: ready to serve client requests
Jan 24 16:56:47 master2 etcd[29617]: forgot to set Type=notify in systemd service file?
Jan 24 16:56:47 master2 etcd[29617]: ready to serve client requests
Jan 24 16:56:47 master2 etcd[29617]: serving client requests on 127.0.0.1:2379
Jan 24 16:56:47 master2 etcd[29617]: serving client requests on 172.31.125.181:2379
Jan 24 16:56:47 master2 etcd[29617]: published {Name:master2 ClientURLs:[https://172.31.125.181:2379]} to cluster 1f9cddabdc8
Jan 24 16:56:47 master2 etcd[29617]: set the initial cluster version to 3.0
Jan 24 16:56:47 master2 etcd[29617]: enabled capabilities for version 3.0
Jan 24 16:56:52 master2 etcd[29617]: health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: co
Jan 24 16:56:57 master2 etcd[29617]: health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: co
Jan 24 16:57:02 master2 etcd[29617]: health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: co
Jan 24 16:57:07 master2 etcd[29617]: health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: co
Jan 24 16:57:12 master2 etcd[29617]: health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: co
Jan 24 16:57:17 master2 etcd[29617]: health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: co
Jan 24 16:57:22 master2 etcd[29617]: health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: co
Jan 24 16:57:27 master2 etcd[29617]: health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: co
lines 29-71/71 (END)lines 29-71/71 (END)Jan 24 16:56:47 master2 etcd[29617]: started streaming with peer c54eae14ec78233 (writer)
Jan 24 16:56:47 master2 etcd[29617]: started HTTP pipelining with peer c54eae14ec78233
Jan 24 16:56:47 master2 etcd[29617]: starting peer c54eae14ec78233...
Jan 24 16:56:47 master2 etcd[29617]: simple token is not cryptographically signed
Jan 24 16:56:47 master2 etcd[29617]: 83b0c9b79ada9b8d became follower at term 1
Jan 24 16:56:47 master2 etcd[29617]: newRaft 83b0c9b79ada9b8d [peers: [], term: 0, commit: 0, applied: 0, lastindex: 0, lastt
Jan 24 16:56:47 master2 etcd[29617]: 83b0c9b79ada9b8d became follower at term 0
Jan 24 16:56:47 master2 etcd[29617]: starting member 83b0c9b79ada9b8d in cluster 1f9cddabdc85ecd2
Jan 24 16:56:47 master2 etcd[29617]: initial cluster = master1=https://172.31.122.25:2380,master2=https://172.31.125.181:2380
Jan 24 16:56:47 master2 etcd[29617]: initial advertise peer URLs = https://172.31.125.181:2380
Jan 24 16:56:47 master2 etcd[29617]: advertise client URLs = https://172.31.125.181:2379
Jan 24 16:56:47 master2 etcd[29617]: snapshot count = 100000
Jan 24 16:56:47 master2 etcd[29617]: election = 1000ms
Jan 24 16:56:47 master2 etcd[29617]: heartbeat = 100ms
Jan 24 16:56:47 master2 etcd[29617]: member dir = /var/lib/etcd/member
Jan 24 16:56:47 master2 etcd[29617]: data dir = /var/lib/etcd
Jan 24 16:56:47 master2 etcd[29617]: name = master2
Jan 24 16:56:47 master2 etcd[29617]: listening for client requests on 172.31.125.181:2379
Jan 24 16:56:47 master2 etcd[29617]: listening for client requests on 127.0.0.1:2379
Jan 24 16:56:47 master2 etcd[29617]: listening for peers on https://172.31.125.181:2380
Jan 24 16:56:47 master2 etcd[29617]: peerTLS: cert = /etc/etcd/etcd-server.crt, key = /etc/etcd/etcd-server.key, ca = , trust
Jan 24 16:56:47 master2 etcd[29617]: setting maximum number of CPUs to 2, total number of available CPUs is 2
Jan 24 16:56:47 master2 etcd[29617]: Go OS/Arch: linux/amd64
Jan 24 16:56:47 master2 etcd[29617]: Go Version: go1.10.3
Jan 24 16:56:47 master2 etcd[29617]: Git SHA: fca8add78
Jan 24 16:56:47 master2 etcd[29617]: etcd Version: 3.3.9
Jan 24 16:56:47 master2 systemd[1]: Started etcd.
-- Logs begin at Fri 2020-01-24 12:05:16 UTC, end at Fri 2020-01-24 16:57:27 UTC. --
lines 1-43/71 51%Jan 24 16:56:47 master2 etcd[29617]: added member 2356cc8de1dc7a23 [https://172.31.115.2:2380] to cluster 1f9cddabdc85ecd2
Jan 24 16:56:47 master2 etcd[29617]: added member 83b0c9b79ada9b8d [https://172.31.125.181:2380] to cluster 1f9cddabdc85ecd2
Jan 24 16:56:47 master2 etcd[29617]: ClientTLS: cert = /etc/etcd/etcd-server.crt, key = /etc/etcd/etcd-server.key, ca = , tru
Jan 24 16:56:47 master2 etcd[29617]: peer c54eae14ec78233 became active
Jan 24 16:56:47 master2 etcd[29617]: established a TCP streaming connection with peer c54eae14ec78233 (stream Message writer)
Jan 24 16:56:47 master2 etcd[29617]: established a TCP streaming connection with peer c54eae14ec78233 (stream MsgApp v2 write
Jan 24 16:56:47 master2 etcd[29617]: established a TCP streaming connection with peer c54eae14ec78233 (stream MsgApp v2 reade
Jan 24 16:56:47 master2 etcd[29617]: established a TCP streaming connection with peer c54eae14ec78233 (stream Message reader)
Jan 24 16:56:47 master2 etcd[29617]: 83b0c9b79ada9b8d [term: 1] received a MsgVote message with higher term from c54eae14ec78
Jan 24 16:56:47 master2 etcd[29617]: 83b0c9b79ada9b8d became follower at term 216
Jan 24 16:56:47 master2 etcd[29617]: 83b0c9b79ada9b8d [logterm: 1, index: 3, vote: 0] cast MsgVote for c54eae14ec78233 [logte
Jan 24 16:56:47 master2 etcd[29617]: raft.node: 83b0c9b79ada9b8d elected leader c54eae14ec78233 at term 216
Jan 24 16:56:47 master2 etcd[29617]: ready to serve client requests
Jan 24 16:56:47 master2 etcd[29617]: forgot to set Type=notify in systemd service file?
Jan 24 16:56:47 master2 etcd[29617]: ready to serve client requests
Jan 24 16:56:47 master2 etcd[29617]: serving client requests on 127.0.0.1:2379
Jan 24 16:56:47 master2 etcd[29617]: serving client requests on 172.31.125.181:2379
Jan 24 16:56:47 master2 etcd[29617]: published {Name:master2 ClientURLs:[https://172.31.125.181:2379]} to cluster 1f9cddabdc8
Jan 24 16:56:47 master2 etcd[29617]: set the initial cluster version to 3.0
Jan 24 16:56:47 master2 etcd[29617]: enabled capabilities for version 3.0
Jan 24 16:56:52 master2 etcd[29617]: health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: co
Jan 24 16:56:57 master2 etcd[29617]: health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: co
Jan 24 16:57:02 master2 etcd[29617]: health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: co
Jan 24 16:57:07 master2 etcd[29617]: health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: co
Jan 24 16:57:12 master2 etcd[29617]: health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: co
Jan 24 16:57:17 master2 etcd[29617]: health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: co
Jan 24 16:57:22 master2 etcd[29617]: health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: co
Jan 24 16:57:27 master2 etcd[29617]: health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: co
lines 29-71/71 (END)lines 29-71/71 (END)root@master2:~# tail /var/log/syslog
Jan 24 16:56:47 rameshhms2c etcd[29617]: serving client requests on 127.0.0.1:2379
Jan 24 16:56:47 rameshhms2c etcd[29617]: serving client requests on 172.31.125.181:2379
Jan 24 16:56:47 rameshhms2c etcd[29617]: published {Name:master2 ClientURLs:[https://172.31.125.181:2379]} to cluster 1f9cddabdc85ecd2
Jan 24 16:56:47 rameshhms2c etcd[29617]: set the initial cluster version to 3.0
Jan 24 16:56:47 rameshhms2c etcd[29617]: enabled capabilities for version 3.0
Jan 24 16:56:52 rameshhms2c etcd[29617]: health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: connect: connection refused
Jan 24 16:56:52 rameshhms2c dhclient[1141]: PRC: Renewing lease on ens5.
Jan 24 16:56:52 rameshhms2c dhclient[1141]: XMT: Renew on ens5, interval 10830ms.
Jan 24 16:56:52 rameshhms2c dhclient[1141]: RCV: Reply message on ens5 from fe80::56:94ff:feb6:db26.
Jan 24 16:56:57 rameshhms2c etcd[29617]: health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: connect: connection refused
root@master2:~# ls -l /etc/etcd/
total 12
-rw-r--r-- 1 root root  989 Jan 24 16:49 ca.crt
-rw-r--r-- 1 root root 1078 Jan 24 16:49 etcd-server.crt
-rw-r--r-- 1 root root 1679 Jan 24 16:49 etcd-server.key
root@master2:~# ETCDCTL_API=3 etcdctl -w table member list  --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt  -- cert=/etc/etcd/etcd-server.crt --key=/etc/etcd/etcd-server.key
+------------------+---------+---------+-----------------------------+-----------------------------+
|        ID        | STATUS  |  NAME   |         PEER ADDRS          |        CLIENT ADDRS         |
+------------------+---------+---------+-----------------------------+-----------------------------+
|  c54eae14ec78233 | started | master1 |  https://172.31.122.25:2380 |  https://172.31.122.25:2379 |
| 2356cc8de1dc7a23 | started | master3 |   https://172.31.115.2:2380 |                             |
| 83b0c9b79ada9b8d | started | master2 | https://172.31.125.181:2380 | https://172.31.125.181:2379 |
+------------------+---------+---------+-----------------------------+-----------------------------+
root@master2:~# 
root@master2:~# ETCDCTL_API=3 etcdctl -w table member list  --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt  --ccert=/etc/etcd/etcd-server.crt --key=/etc/etcd/etcd-server.keyls -l /etc/etcd/
tail /var/log/syslog
Jan 24 16:56:52 rameshhms2c etcd[29617]: health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: connect: connection refused
Jan 24 16:56:52 rameshhms2c dhclient[1141]: PRC: Renewing lease on ens5.
Jan 24 16:56:52 rameshhms2c dhclient[1141]: XMT: Renew on ens5, interval 10830ms.
Jan 24 16:56:52 rameshhms2c dhclient[1141]: RCV: Reply message on ens5 from fe80::56:94ff:feb6:db26.
Jan 24 16:56:57 rameshhms2c etcd[29617]: health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: connect: connection refused
Jan 24 16:58:07 rameshhms2c etcd[29617]: message repeated 14 times: [ health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: connect: connection refused]
Jan 24 16:58:07 rameshhms2c dhclient[1141]: PRC: Renewing lease on ens5.
Jan 24 16:58:07 rameshhms2c dhclient[1141]: XMT: Renew on ens5, interval 10330ms.
Jan 24 16:58:07 rameshhms2c dhclient[1141]: RCV: Reply message on ens5 from fe80::56:94ff:feb6:db26.
Jan 24 16:58:12 rameshhms2c etcd[29617]: health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: connect: connection refused
root@master2:~# tail /var/log/syslogETCDCTL_API=3 etcdctl -w table member list  --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt  --ccert=/etc/etcd/etcd-server.crt --key=/etc/etcd/etcd-server.key
+------------------+---------+---------+-----------------------------+-----------------------------+
|        ID        | STATUS  |  NAME   |         PEER ADDRS          |        CLIENT ADDRS         |
+------------------+---------+---------+-----------------------------+-----------------------------+
|  c54eae14ec78233 | started | master1 |  https://172.31.122.25:2380 |  https://172.31.122.25:2379 |
| 2356cc8de1dc7a23 | started | master3 |   https://172.31.115.2:2380 |                             |
| 83b0c9b79ada9b8d | started | master2 | https://172.31.125.181:2380 | https://172.31.125.181:2379 |
+------------------+---------+---------+-----------------------------+-----------------------------+
root@master2:~# 
root@master2:~# 
root@master2:~# ETCDCTL_API=3 etcdctl -w table member list  --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt  --ccert=/etc/etcd/etcd-server.crt --key=/etc/etcd/etcd-server.key --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt  --cert=/root@master2:~#  --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt  --cert=/etc/etcroot@master2:~# h --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt  --cert=/etc/etcroot@master2:~# e --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt  --cert=/etc/etroot@master2:~# a --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt  --cert=/etc/eroot@master2:~# l --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt  --cert=/etc/root@master2:~# t --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt  --cert=/etcroot@master2:~# h --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt  --cert=/etroot@master2:~#  --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt  --cert=/eroot@master2:~# c --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt  --cert=/root@master2:~# h --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt  --cert=root@master2:~# e --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt  --certroot@master2:~# c --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt  --cerroot@master2:~# k --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt  --ceroot@master2:~# 

Error: unknown command "health" for "etcdctl"
Run 'etcdctl --help' for usage.
Error: unknown command "health" for "etcdctl"
root@master2:~# ETCDCTL_API=3 etcdctl -w table endpoint --cluster status --endpoints=https://127.0.0.1:2379  --cacert=/etc/et cd/ca.crt  --cert=/etc/etcd/etcd-server.crt --key=/etc/etcd/etcd-server.key
+-----------------------------+------------------+---------+---------+-----------+-----------+------------+
|          ENDPOINT           |        ID        | VERSION | DB SIZE | IS LEADER | RAFT TERM | RAFT INDEX |
+-----------------------------+------------------+---------+---------+-----------+-----------+------------+
|  https://172.31.122.25:2379 |  c54eae14ec78233 |   3.3.9 |   20 kB |      true |       216 |          7 |
| https://172.31.125.181:2379 | 83b0c9b79ada9b8d |   3.3.9 |   20 kB |     false |       216 |          7 |
+-----------------------------+------------------+---------+---------+-----------+-----------+------------+
root@master2:~# 
root@master2:~# 
root@master2:~# ETCDCTL_API=3 etcdctl -w table endpoint --cluster status --endpoints=https://127.0.0.1:2379  --cacert=/etc/etccd/ca.crt  --cert=/etc/etcd/etcd-server.crt --key=/etc/etcd/etcd-server.keyhealth check --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt  --cmember list 
tail /var/log/syslog
ETCDCTL_API=3 etcdctl -w table member list  --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt  --ccert=/etc/etcd/etcd-server.crt --key=/etc/etcd/etcd-server.keyls -l /etc/etcd/
tail /var/log/syslogjournalctl -u etcd.service -lsystemctl status etcd
 etcd.service - etcd
   Loaded: loaded (/etc/systemd/system/etcd.service; enabled; vendor preset: enabled)
   Active: active (running) since Fri 2020-01-24 16:56:47 UTC; 3min 0s ago
     Docs: https://github.com/coreos
 Main PID: 29617 (etcd)
    Tasks: 10
   Memory: 17.7M
      CPU: 2.781s
   CGroup: /system.slice/etcd.service
           29617 /usr/local/bin/etcd --name master2 --cert-file=/etc/etcd/etcd-server.crt --key-file=/etc/etcd/etcd-server.

Jan 24 16:59:02 master2 etcd[29617]: health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: co
Jan 24 16:59:07 master2 etcd[29617]: health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: co
Jan 24 16:59:12 master2 etcd[29617]: health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: co
Jan 24 16:59:17 master2 etcd[29617]: health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: co
Jan 24 16:59:22 master2 etcd[29617]: health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: co
Jan 24 16:59:27 master2 etcd[29617]: health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: co
Jan 24 16:59:32 master2 etcd[29617]: health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: co
Jan 24 16:59:37 master2 etcd[29617]: health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: co
Jan 24 16:59:42 master2 etcd[29617]: health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: co
Jan 24 16:59:47 master2 etcd[29617]: health check for peer 2356cc8de1dc7a23 could not connect: dial tcp 172.31.115.2:2380: co
lines 1-21/21 (END)root@master2:~# logout
Connection to master2 closed.
root@master1:~/keys# 
root@master1:~/keys# ssh master223
Welcome to Ubuntu 16.04.6 LTS (GNU/Linux 4.4.0-1099-aws x86_64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/advantage

 * Overheard at KubeCon: "microk8s.status just blew my mind".

     https://microk8s.io/docs/commands#microk8s.status

  Get cloud support with Ubuntu Advantage Cloud Guest:
    http://www.ubuntu.com/business/services/cloud

15 packages can be updated.
0 updates are security updates.

New release '18.04.3 LTS' available.
Run 'do-release-upgrade' to upgrade to it.


*** System restart required ***
root@master3:~# ls -l /etc/etcd
total 12
-rw-r--r-- 1 root root  989 Jan 24 16:49 ca.crt
-rw-r--r-- 1 root root 1078 Jan 24 16:49 etcd-server.crt
-rw-r--r-- 1 root root 1679 Jan 24 16:49 etcd-server.key
root@master3:~# INTERNAL_IP=$(ip addr show ens5| grep "inet " | awk '{print $2}' | cut -d / -f 1)
root@master3:~# ETCD_NAME=$(hostname -s)
root@master3:~# 
root@master3:~# cat <<EOF | sudo tee /etc/systemd/system/etcd.service
> [Unit]
> Description=etcd
> Documentation=https://github.com/coreos
> 
> [Service]
> ExecStart=/usr/local/bin/etcd \\
>   --name ${ETCD_NAME} \\
>   --cert-file=/etc/etcd/etcd-server.crt \\
>   --key-file=/etc/etcd/etcd-server.key \\
>   --peer-cert-file=/etc/etcd/etcd-server.crt \\
>   --peer-key-file=/etc/etcd/etcd-server.key \\
>   --trusted-ca-file=/etc/etcd/ca.crt \\
>   --peer-trusted-ca-file=/etc/etcd/ca.crt \\
>   --peer-client-cert-auth \\
>   --client-cert-auth \\
>   --initial-advertise-peer-urls https://${INTERNAL_IP}:2380 \\
>   --listen-peer-urls https://${INTERNAL_IP}:2380 \\
>   --listen-client-urls https://${INTERNAL_IP}:2379,https://127.0.0.1:2379 \\
>   --advertise-client-urls https://${INTERNAL_IP}:2379 \\
>   --initial-cluster-token etcd-cluster-0 \\
>   --initial-cluster master1=https://172.31.122.25:2380,master2=https://172.31.125.181:2380,master3=https://172.31.115.2:238 0 \\
>   --initial-cluster-state new \\
>   --data-dir=/var/lib/etcd
> Restart=on-failure
> RestartSec=5
> 
> [Install]
> WantedBy=multi-user.target
> EOF
[Unit]
Description=etcd
Documentation=https://github.com/coreos

[Service]
ExecStart=/usr/local/bin/etcd \
  --name master3 \
  --cert-file=/etc/etcd/etcd-server.crt \
  --key-file=/etc/etcd/etcd-server.key \
  --peer-cert-file=/etc/etcd/etcd-server.crt \
  --peer-key-file=/etc/etcd/etcd-server.key \
  --trusted-ca-file=/etc/etcd/ca.crt \
  --peer-trusted-ca-file=/etc/etcd/ca.crt \
  --peer-client-cert-auth \
  --client-cert-auth \
  --initial-advertise-peer-urls https://172.31.115.2:2380 \
  --listen-peer-urls https://172.31.115.2:2380 \
  --listen-client-urls https://172.31.115.2:2379,https://127.0.0.1:2379 \
  --advertise-client-urls https://172.31.115.2:2379 \
  --initial-cluster-token etcd-cluster-0 \
  --initial-cluster master1=https://172.31.122.25:2380,master2=https://172.31.125.181:2380,master3=https://172.31.115.2:2380 \
  --initial-cluster-state new \
  --data-dir=/var/lib/etcd
Restart=on-failure
RestartSec=5

[Install]
WantedBy=multi-user.target
root@master3:~# 
root@master3:~# systemctl daemon-reload
root@master3:~# systemctl enable etcd
Created symlink from /etc/systemd/system/multi-user.target.wants/etcd.service to /etc/systemd/system/etcd.service.
root@master3:~# systemctl start etcd
root@master3:~# ETCDCTL_API=3 etcdctl -w table member list  --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt  -- cert=/etc/etcd/etcd-server.crt --key=/etc/etcd/etcd-server.key
+------------------+---------+---------+-----------------------------+-----------------------------+
|        ID        | STATUS  |  NAME   |         PEER ADDRS          |        CLIENT ADDRS         |
+------------------+---------+---------+-----------------------------+-----------------------------+
|  c54eae14ec78233 | started | master1 |  https://172.31.122.25:2380 |  https://172.31.122.25:2379 |
| 2356cc8de1dc7a23 | started | master3 |   https://172.31.115.2:2380 |   https://172.31.115.2:2379 |
| 83b0c9b79ada9b8d | started | master2 | https://172.31.125.181:2380 | https://172.31.125.181:2379 |
+------------------+---------+---------+-----------------------------+-----------------------------+
root@master3:~# 
root@master3:~# ETCDCTL_API=3 etcdctl -w table endpoint --cluster status --endpoints=https://127.0.0.1:2379  --cacert=/etc/et cd/ca.crt  --cert=/etc/etcd/etcd-server.crt --key=/etc/etcd/etcd-server.key
+-----------------------------+------------------+---------+---------+-----------+-----------+------------+
|          ENDPOINT           |        ID        | VERSION | DB SIZE | IS LEADER | RAFT TERM | RAFT INDEX |
+-----------------------------+------------------+---------+---------+-----------+-----------+------------+
|  https://172.31.122.25:2379 |  c54eae14ec78233 |   3.3.9 |   20 kB |      true |       216 |          9 |
|   https://172.31.115.2:2379 | 2356cc8de1dc7a23 |   3.3.9 |   20 kB |     false |       216 |          9 |
| https://172.31.125.181:2379 | 83b0c9b79ada9b8d |   3.3.9 |   20 kB |     false |       216 |          9 |
+-----------------------------+------------------+---------+---------+-----------+-----------+------------+
root@master3:~# 
root@master3:~# 
root@master3:~# ETCDCTL_API=3 etcdctl -w table endpoint --cluster status --endpoints=https://127.0.0.1:2379  --cacert=/etc/etccd/ca.crt  --cert=/etc/etcd/etcd-server.crt --key=/etc/etcd/etcd-server.key --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.croot@master3:~# h --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.croot@master3:~# e --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.root@master3:~# a --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/caroot@master3:~# l --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/croot@master3:~# t --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/root@master3:~# h --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcdroot@master3:~# 

https://172.31.122.25:2379 is healthy: successfully committed proposal: took = 1.388284ms
https://172.31.125.181:2379 is healthy: successfully committed proposal: took = 2.346182ms
https://172.31.115.2:2379 is healthy: successfully committed proposal: took = 3.15418ms
root@master3:~# 
root@master3:~# 
root@master3:~# logout
Connection to master3 closed.
root@master1:~/keys# 
root@master1:~/keys# 
root@master1:~/keys# cd ../package/
root@master1:~/package# l;s -lls -l 
total 10996
drwxr-xr-x 3 ubuntu ubuntu     4096 Jul 24  2018 etcd-v3.3.9-linux-amd64
-rw-r--r-- 1 root   root   11254519 Jul 24  2018 etcd-v3.3.9-linux-amd64.tar.gz
root@master1:~/package# mkdir -p /etc/kubernetes/config
root@master1:~/package# wget -q --show-progress --https-only --timestamping \
>   "https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kube-apiserver" \
>   "https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kube-controller-manager" \
>   "https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kube-scheduler" \
>   "https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kubectl"
kube-apiserver                    0%[                                                     ]       0  --.-KB/s               kube-apiserver                    5%[=>                                                   ]   6.82M  34.1MB/s               kube-apiserver                   24%[===========>                                         ]  32.01M  67.4MB/s               kube-apiserver                   36%[==================>                                  ]  48.01M  62.8MB/s               kube-apiserver                   55%[============================>                        ]  73.66M  76.4MB/s               kube-apiserver                   71%[====================================>                ]  93.88M  80.6MB/s               kube-apiserver                   85%[============================================>        ] 113.23M  83.0MB/s               kube-apiserver                  100%[====================================================>] 132.15M  86.9MB/s    in 1.5s    
kube-controller-manager           0%[                                                     ]       0  --.-KB/s               kube-controller-manager           8%[===>                                                 ]   8.79M  43.8MB/s               kube-controller-manager          24%[===========>                                         ]  24.01M  51.4MB/s               kube-controller-manager          48%[========================>                            ]  48.01M  67.1MB/s               kube-controller-manager          76%[=======================================>             ]  76.23M  83.2MB/s               kube-controller-manager         100%[====================================================>]  99.04M  89.8MB/s    in 1.1s    
kube-scheduler                    0%[                                                     ]       0  --.-KB/s               kube-scheduler                   11%[====>                                                ]   4.01M  9.03MB/s               kube-scheduler                   45%[======================>                              ]  16.01M  24.2MB/s               kube-scheduler                   67%[==================================>                  ]  24.01M  24.2MB/s               kube-scheduler                  100%[====================================================>]  35.54M  33.6MB/s    in 1.1s    
kubectl                           0%[                                                     ]       0  --.-KB/s               kubectl                          42%[=====================>                               ]  16.00M  14.4MB/s               kubectl                         100%[====================================================>]  37.40M  29.8MB/s    in 1.3s    
root@master1:~/package# chmod +x kube-apiserver kube-controller-manager kube-scheduler kubectl
root@master1:~/package# scp kube-apiserver kube-controller-manager kube-scheduler kubectl $instance:/usr/local/bin//usr/local/bin//usr/local/bin//usr/local/bin//usr/local/bin//usr/local/bin//usr/local/bin//usr/local/bin//usr/local/bin//usr/local/bin//usr/local/bin/
root@master1:~/package# ^C
root@master1:~/package# ls -l /usr/local/bin/
total 345372
-rwxr-xr-x 1 root root  18934016 Jan 24 13:31 etcd
-rwxr-xr-x 1 root root  15809280 Jan 24 13:31 etcdctl
-rwxr-xr-x 1 root root 138570976 Jan 24 17:02 kube-apiserver
-rwxr-xr-x 1 root root 103856032 Jan 24 17:02 kube-controller-manager
-rwxr-xr-x 1 root root  39214560 Jan 24 17:02 kubectl
-rwxr-xr-x 1 root root  37263616 Jan 24 17:02 kube-scheduler
root@master1:~/package# (reverse-i-search)`':f': mkdir -p /etc/kubernetes/configo': for instance in master2 master3; do scp /root/keys/ca.crt /root/keys/etcd-server.key /root/keys/etcd-sserver.crt $instance:/etc/etcd/;doner': for instance in master2 master3; do scp /root/keys/ca.crt /root/keys/etcd-server.key /root/keys/etcd-sroot@master1:~/package# for instance in master2 master3; do scp /root/keys/ca.crt /root/keys/etcd-server.key /root/keys/etcd-sroot@master1:~/package# cp /root/keys/ca.crt /root/keys/etcd-server.key /root/keys/etcd-seroot@master1:~/package# p /root/keys/ca.crt /root/keys/etcd-server.key /root/keys/etcd-serroot@master1:~/package#  /root/keys/ca.crt /root/keys/etcd-server.key /root/keys/etcd-servroot@master1:~/package# /root/keys/ca.crt /root/keys/etcd-server.key /root/keys/etcd-serveroot@master1:~/package# root/keys/ca.crt /root/keys/etcd-server.key /root/keys/etcd-serverroot@master1:~/package# oot/keys/ca.crt /root/keys/etcd-server.key /root/keys/etcd-server.root@master1:~/package# t/keys/ca.crt /root/keys/etcd-server.key /root/keys/etcd-server.croot@master1:~/package# t/keys/ca.crt /root/keys/etcd-server.key /root/keys/etcd-server.crroot@master1:~/package# /keys/ca.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt $instance:/etc/etcd/;donekeys/ca.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt $instance:/etc/etcd/;doneeys/ca.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt $instance:/etc/etcd/;doneys/ca.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt $instance:/etc/etcd/;dones/ca.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt $instance:/etc/etcd/;doneroot@master1:~/package# /ca.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt $instance:/etc/etcd/;doneroot@master1:~/package# ca.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt $instance:/etc/etcd/;doneroot@master1:~/package# a.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt $instance:/etc/etcd/;doneroot@master1:~/package# .crt /root/keys/etcd-server.key /root/keys/etcd-server.crt $instance:/etc/etcd/;doneroot@master1:~/package# crt /root/keys/etcd-server.key /root/keys/etcd-server.crt $instance:/etc/etcd/;doneroot@master1:~/package# rt /root/keys/etcd-server.key /root/keys/etcd-server.crt $instance:/etc/etcd/;doneroot@master1:~/package# t /root/keys/etcd-server.key /root/keys/etcd-server.crt $instance:/etc/etcd/;doneroot@master1:~/package#  /root/keys/etcd-server.key /root/keys/etcd-server.crt $instance:/etc/etcd/;doneroot@master1:~/package# /root/keys/etcd-server.key /root/keys/etcd-server.crt $instance:/etc/etcd/;doneroot@master1:~/package# root/keys/etcd-server.key /root/keys/etcd-server.crt $instance:/etc/etcd/;doneroot@master1:~/package# oot/keys/etcd-server.key /root/keys/etcd-server.crt $instance:/etc/etcd/;doneroot@master1:~/package# t/keys/etcd-server.key /root/keys/etcd-server.crt $instance:/etc/etcd/;doneroot@master1:~/package# t/keys/etcd-server.key /root/keys/etcd-server.crt $instance:/etc/etcd/;doneroot@master1:~/package# /keys/etcd-server.key /root/keys/etcd-server.crt $instance:/etc/etcd/;doneroot@master1:~/package# keys/etcd-server.key /root/keys/etcd-server.crt $instance:/etc/etcd/;doneroot@master1:~/package# eys/etcd-server.key /root/keys/etcd-server.crt $instance:/etc/etcd/;doneroot@master1:~/package# ys/etcd-server.key /root/keys/etcd-server.crt $instance:/etc/etcd/;doneroot@master1:~/package# s/etcd-server.key /root/keys/etcd-server.crt $instance:/etc/etcd/;doneroot@master1:~/package# /etcd-server.key /root/keys/etcd-server.crt $instance:/etc/etcd/;doneroot@master1:~/package# etcd-server.key /root/keys/etcd-server.crt $instance:/etc/etcd/;doneroot@master1:~/package# tcd-server.key /root/keys/etcd-server.crt $instance:/etc/etcd/;doneroot@master1:~/package# cd-server.key /root/keys/etcd-server.crt $instance:/etc/etcd/;doneroot@master1:~/package# d-server.key /root/keys/etcd-server.crt $instance:/etc/etcd/;done 
 $instance:/etc/etcd/;done$instance:/etc/etcd/;doneinstance:/etc/etcd/;donenstance:/etc/etcd/;donestance:/etc/etcd/;donetance:/etc/etcd/;doneance:/etc/etcd/;donence:/etc/etcd/;donece:/etc/etcd/;donee:/etc/etcd/;done:/etc/etcd/;done/etc/etcd/;doneetc/etcd/;donetc/etcd/;donec/etcd/;done/etcd/;doneetcd/;donetcd/;donecd/;doned/;done/;done;dones;donec;donep;done ;donek;doneu;doneb;donee;done-;donea;donep;donei;dones;donee;doner;donev;donee;doner;done ;donek;doneu;doneb;donee;done-;donec;doneo;donen;donet;doner;doneo;donel;donel;donee;doner;done-;donem;donea;donen;donea;doneg;donee;doner;done ;donek;doneu;doneb;donee;done-;dones;donec;doneh;donee;doned;doneu;donel;donee;doner;done ;donek;doneu;done root@master1:~/package# b;doneeroot@master1:~/package# e;doneroot@master1:~/package# c;doneroot@master1:~/package# t;doneroot@master1:~/package# l;done ;done$;donei;donen;dones;donet;donea;donen;donec;donee;done:;done/;doneu;dones;doner;done/;donel;doneo;donec;donea;donel;done/;doneb;donei;donen;done/;done
kube-apiserver                                                                               0%    0     0.0KB/s   --:-- ETAkube-apiserver                                                                              50%   67MB  66.7MB/s   00:00 ETAkube-apiserver                                                                             100%  132MB 132.2MB/s   00:01    
kube-controller-manager                                                                      0%    0     0.0KB/s   --:-- ETAkube-controller-manager                                                                    100%   99MB  99.0MB/s   00:01    
kube-scheduler                                                                               0%    0     0.0KB/s   --:-- ETAkube-scheduler                                                                             100%   36MB  35.5MB/s   00:00    
kubectl                                                                                      0%    0     0.0KB/s   --:-- ETAkubectl                                                                                    100%   37MB  37.4MB/s   00:00    
kube-apiserver                                                                               0%    0     0.0KB/s   --:-- ETAkube-apiserver                                                                              77%  102MB 102.4MB/s   00:00 ETAkube-apiserver                                                                             100%  132MB 132.2MB/s   00:01    
kube-controller-manager                                                                      0%    0     0.0KB/s   --:-- ETAkube-controller-manager                                                                    100%   99MB  99.0MB/s   00:01    
kube-scheduler                                                                               0%    0     0.0KB/s   --:-- ETAkube-scheduler                                                                             100%   36MB  35.5MB/s   00:00    
kubectl                                                                                      0%    0     0.0KB/s   --:-- ETAkubectl                                                                                    100%   37MB  37.4MB/s   00:00    
root@master1:~/package# mkdir -p /var/lib/kubernetes/
root@master1:~/package# mkdir -p /var/lib/kubernetes/for instance in master2 master3; do scp kube-apiserver kube-controller-manager kube-scheduler kubectl  $instance:/usr/local/bin/;donels -l /usr/local/bin/
for instance in master2 master3; do scp kube-apiserver kube-controller-manager kube-scheduler kubectl  $instance:/usr/local/bin/;done;doneroot@master1:~/package# ;done
;done;done;done;dones;dones;doneh;done ;done$;donei;donen;dones;donet;donea;donen;donec;donee;done ;done";donem;donek;doned;donei;doner;done ;done/;donee;donet;donec;done/;donek;doneu;doneb;donee;doner;donen;donee;donet;donee;dones;done/;donec;doneo;donen;donef;donei;doneg;done ;donem;donek;doned;donei;doner;done ;done-;donep;done ;done/;donev;donea;doner;done/;donel;donei;done root@master1:~/package# b;doneeroot@master1:~/package# /;doneroot@master1:~/package# k;doneroot@master1:~/package# u;doneroot@master1:~/package# b;donee;doner;donen;donee;donet;donee;dones;done/;done/var/lib/kubernetes/;doneroot@master1:~/package# /var/lib/kubernetes/;doneroot@master1:~/package# /var/lib/kubernetes/;doneroot@master1:~/package# /var/lib/kubernetes/;doneroot@master1:~/package# /var/lib/kubernetes/;doneroot@master1:~/package# /var/lib/kubernetes/;doneroot@master1:~/package# /var/lib/kubernetes/;doneroot@master1:~/package# /var/lib/kubernetes/;doneroot@master1:~/package# /var/lib/kubernetes/;doneroot@master1:~/package# -/etc/kubernetes/config /var/lib/kubernetes/;doneroot@master1:~/package# p/etc/kubernetes/config /var/lib/kubernetes/;doneroot@master1:~/package#  /etc/kubernetes/config /var/lib/kubernetes/;doneroot@master1:~/package# 

> ^C
root@master1:~/package# for instance in master2 master3; do ssh $instance "mkdir -p /etc/kubernetes/config /var/lib/kubernetess/;done
";done
root@master1:~/package# cd ../keys/
root@master1:~/keys# cp /root/keys/ca.crt /root/keys/ca.key /root/keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root /keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/enc ryption-config.yaml /var/lib/kubernetes/
root@master1:~/keys# ls -l /var/lib/kubernetes/
total 36
-rw-r--r-- 1 root root  989 Jan 24 17:05 ca.crt
-rw-r--r-- 1 root root 1679 Jan 24 17:05 ca.key
-rw-r--r-- 1 root root  240 Jan 24 17:05 encryption-config.yaml
-rw-r--r-- 1 root root 1078 Jan 24 17:05 etcd-server.crt
-rw-r--r-- 1 root root 1679 Jan 24 17:05 etcd-server.key
-rw-r--r-- 1 root root 1489 Jan 24 17:05 kube-apiserver.crt
-rw-r--r-- 1 root root 1675 Jan 24 17:05 kube-apiserver.key
-rw-r--r-- 1 root root  993 Jan 24 17:05 service-account.crt
-rw-r--r-- 1 root root 1675 Jan 24 17:05 service-account.key
root@master1:~/keys# for instance in master2 master3; do scp /root/keys/ca.crt /root/keys/ca.key /root/keys/kube-apiserver.cr t /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /roo t/keys/etcd-server.crt /root/keys/encryption-config.yaml /var/lib/kubernetes/$/var/lib/kubernetes/i/var/lib/kubernetes/n/var/lib/kubernetes/s/var/lib/kubernetes/t/var/lib/kubernetes/a/var/lib/kubernetes/n/var/lib/kubernetes/c/var/lib/kubernetes/e/var/lib/kubernetes/:/var/lib/kubernetes/;done
ca.crt                                                                                       0%    0     0.0KB/s   --:-- ETAca.crt                                                                                     100%  989     1.0KB/s   00:00    
ca.key                                                                                       0%    0     0.0KB/s   --:-- ETAca.key                                                                                     100% 1679     1.6KB/s   00:00    
kube-apiserver.crt                                                                           0%    0     0.0KB/s   --:-- ETAkube-apiserver.crt                                                                         100% 1489     1.5KB/s   00:00    
kube-apiserver.key                                                                           0%    0     0.0KB/s   --:-- ETAkube-apiserver.key                                                                         100% 1675     1.6KB/s   00:00    
service-account.key                                                                          0%    0     0.0KB/s   --:-- ETAservice-account.key                                                                        100% 1675     1.6KB/s   00:00    
service-account.crt                                                                          0%    0     0.0KB/s   --:-- ETAservice-account.crt                                                                        100%  993     1.0KB/s   00:00    
etcd-server.key                                                                              0%    0     0.0KB/s   --:-- ETAetcd-server.key                                                                            100% 1679     1.6KB/s   00:00    
etcd-server.crt                                                                              0%    0     0.0KB/s   --:-- ETAetcd-server.crt                                                                            100% 1078     1.1KB/s   00:00    
encryption-config.yaml                                                                       0%    0     0.0KB/s   --:-- ETAencryption-config.yaml                                                                     100%  240     0.2KB/s   00:00    
ca.crt                                                                                       0%    0     0.0KB/s   --:-- ETAca.crt                                                                                     100%  989     1.0KB/s   00:00    
ca.key                                                                                       0%    0     0.0KB/s   --:-- ETAca.key                                                                                     100% 1679     1.6KB/s   00:00    
kube-apiserver.crt                                                                           0%    0     0.0KB/s   --:-- ETAkube-apiserver.crt                                                                         100% 1489     1.5KB/s   00:00    
kube-apiserver.key                                                                           0%    0     0.0KB/s   --:-- ETAkube-apiserver.key                                                                         100% 1675     1.6KB/s   00:00    
service-account.key                                                                          0%    0     0.0KB/s   --:-- ETAservice-account.key                                                                        100% 1675     1.6KB/s   00:00    
service-account.crt                                                                          0%    0     0.0KB/s   --:-- ETAservice-account.crt                                                                        100%  993     1.0KB/s   00:00    
etcd-server.key                                                                              0%    0     0.0KB/s   --:-- ETAetcd-server.key                                                                            100% 1679     1.6KB/s   00:00    
etcd-server.crt                                                                              0%    0     0.0KB/s   --:-- ETAetcd-server.crt                                                                            100% 1078     1.1KB/s   00:00    
encryption-config.yaml                                                                       0%    0     0.0KB/s   --:-- ETAencryption-config.yaml                                                                     100%  240     0.2KB/s   00:00    
root@master1:~/keys# INTERNAL_IP=$(ip addr show ens5| grep "inet " | awk '{print $2}' | cut -d / -f 1)
root@master1:~/keys# ls -l /etc/kubernetes/config
total 0
root@master1:~/keys# ls -l ../package/
total 322440
drwxr-xr-x 3 ubuntu ubuntu      4096 Jul 24  2018 etcd-v3.3.9-linux-amd64
-rw-r--r-- 1 root   root    11254519 Jul 24  2018 etcd-v3.3.9-linux-amd64.tar.gz
-rwxr-xr-x 1 root   root   138570976 Dec  3  2018 kube-apiserver
-rwxr-xr-x 1 root   root   103856032 Dec  3  2018 kube-controller-manager
-rwxr-xr-x 1 root   root    39214560 Dec  3  2018 kubectl
-rwxr-xr-x 1 root   root    37263616 Dec  3  2018 kube-scheduler
root@master1:~/keys# cat /etc/holstssosts
127.0.0.1 localhost

# The following lines are desirable for IPv6 capable hosts
::1 ip6-localhost ip6-loopback
fe00::0 ip6-localnet
ff00::0 ip6-mcastprefix
ff02::1 ip6-allnodes
ff02::2 ip6-allrouters
ff02::3 ip6-allhosts
# Cloud Server Hostname mapping
172.31.122.25   rameshhms1c.mylabserver.com
172.31.122.25master1
172.31.125.181master2
172.31.115.2master3
172.31.122.147worker1
172.31.123.142loadbalancer
root@master1:~/keys# cat <<EOF | sudo tee /etc/systemd/system/kube-apiserver.service
> [Unit]
> Description=Kubernetes API Server
> Documentation=https://github.com/kubernetes/kubernetes
> 
> [Service]
> ExecStart=/usr/local/bin/kube-apiserver \\
>   --advertise-address=${INTERNAL_IP} \\
>   --allow-privileged=true \\
>   --apiserver-count=3 \\
>   --audit-log-maxage=30 \\
>   --audit-log-maxbackup=3 \\
>   --audit-log-maxsize=100 \\
>   --audit-log-path=/var/log/audit.log \\
>   --authorization-mode=Node,RBAC \\
>   --bind-address=0.0.0.0 \\
>   --client-ca-file=/var/lib/kubernetes/ca.crt \\
>   --enable-admission-plugins=NodeRestriction,ServiceAccount \\
>   --enable-swagger-ui=true \\
>   --enable-bootstrap-token-auth=true \\
>   --etcd-cafile=/var/lib/kubernetes/ca.crt \\
>   --etcd-certfile=/var/lib/kubernetes/etcd-server.crt \\
>   --etcd-keyfile=/var/lib/kubernetes/etcd-server.key \\
>   --etcd-servers=https://172.31.122.25:2379,https://172.31.125.181:2379,https://172.31.115.2:2379 \\
>   --event-ttl=1h \\
>   --encryption-provider-config=/var/lib/kubernetes/encryption-config.yaml \\
>   --kubelet-certificate-authority=/var/lib/kubernetes/ca.crt \\
>   --kubelet-client-certificate=/var/lib/kubernetes/kube-apiserver.crt \\
>   --kubelet-client-key=/var/lib/kubernetes/kube-apiserver.key \\
>   --kubelet-https=true \\
>   --runtime-config=api/all \\
>   --service-account-key-file=/var/lib/kubernetes/service-account.crt \\
>   --service-cluster-ip-range=10.96.0.0/24 \\
>   --service-node-port-range=30000-32767 \\
>   --tls-cert-file=/var/lib/kubernetes/kube-apiserver.crt \\
>   --tls-private-key-file=/var/lib/kubernetes/kube-apiserver.key \\
>   --v=2
> Restart=on-failure
> RestartSec=5
> 
> [Install]
> WantedBy=multi-user.target
> EOF
[Unit]
Description=Kubernetes API Server
Documentation=https://github.com/kubernetes/kubernetes

[Service]
ExecStart=/usr/local/bin/kube-apiserver \
  --advertise-address=172.31.122.25 \
  --allow-privileged=true \
  --apiserver-count=3 \
  --audit-log-maxage=30 \
  --audit-log-maxbackup=3 \
  --audit-log-maxsize=100 \
  --audit-log-path=/var/log/audit.log \
  --authorization-mode=Node,RBAC \
  --bind-address=0.0.0.0 \
  --client-ca-file=/var/lib/kubernetes/ca.crt \
  --enable-admission-plugins=NodeRestriction,ServiceAccount \
  --enable-swagger-ui=true \
  --enable-bootstrap-token-auth=true \
  --etcd-cafile=/var/lib/kubernetes/ca.crt \
  --etcd-certfile=/var/lib/kubernetes/etcd-server.crt \
  --etcd-keyfile=/var/lib/kubernetes/etcd-server.key \
  --etcd-servers=https://172.31.122.25:2379,https://172.31.125.181:2379,https://172.31.115.2:2379 \
  --event-ttl=1h \
  --encryption-provider-config=/var/lib/kubernetes/encryption-config.yaml \
  --kubelet-certificate-authority=/var/lib/kubernetes/ca.crt \
  --kubelet-client-certificate=/var/lib/kubernetes/kube-apiserver.crt \
  --kubelet-client-key=/var/lib/kubernetes/kube-apiserver.key \
  --kubelet-https=true \
  --runtime-config=api/all \
  --service-account-key-file=/var/lib/kubernetes/service-account.crt \
  --service-cluster-ip-range=10.96.0.0/24 \
  --service-node-port-range=30000-32767 \
  --tls-cert-file=/var/lib/kubernetes/kube-apiserver.crt \
  --tls-private-key-file=/var/lib/kubernetes/kube-apiserver.key \
  --v=2
Restart=on-failure
RestartSec=5

[Install]
WantedBy=multi-user.target
root@master1:~/keys# ssh master2
Welcome to Ubuntu 16.04.6 LTS (GNU/Linux 4.4.0-1099-aws x86_64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/advantage

 * Overheard at KubeCon: "microk8s.status just blew my mind".

     https://microk8s.io/docs/commands#microk8s.status

  Get cloud support with Ubuntu Advantage Cloud Guest:
    http://www.ubuntu.com/business/services/cloud

15 packages can be updated.
0 updates are security updates.

New release '18.04.3 LTS' available.
Run 'do-release-upgrade' to upgrade to it.


*** System restart required ***
Last login: Fri Jan 24 16:55:29 2020 from 172.31.122.25
root@master2:~# INTERNAL_IP=$(ip addr show ens5| grep "inet " | awk '{print $2}' | cut -d / -f 1)
root@master2:~# 
root@master2:~# cat <<EOF | sudo tee /etc/systemd/system/kube-apiserver.service
> [Unit]
> Description=Kubernetes API Server
> Documentation=https://github.com/kubernetes/kubernetes
> 
> [Service]
> ExecStart=/usr/local/bin/kube-apiserver \\
>   --advertise-address=${INTERNAL_IP} \\
>   --allow-privileged=true \\
>   --apiserver-count=3 \\
>   --audit-log-maxage=30 \\
>   --audit-log-maxbackup=3 \\
>   --audit-log-maxsize=100 \\
>   --audit-log-path=/var/log/audit.log \\
>   --authorization-mode=Node,RBAC \\
>   --bind-address=0.0.0.0 \\
>   --client-ca-file=/var/lib/kubernetes/ca.crt \\
>   --enable-admission-plugins=NodeRestriction,ServiceAccount \\
>   --enable-swagger-ui=true \\
>   --enable-bootstrap-token-auth=true \\
>   --etcd-cafile=/var/lib/kubernetes/ca.crt \\
>   --etcd-certfile=/var/lib/kubernetes/etcd-server.crt \\
>   --etcd-keyfile=/var/lib/kubernetes/etcd-server.key \\
>   --etcd-servers=https://172.31.122.25:2379,https://172.31.125.181:2379,https://172.31.115.2:2379 \\
>   --event-ttl=1h \\
>   --encryption-provider-config=/var/lib/kubernetes/encryption-config.yaml \\
>   --kubelet-certificate-authority=/var/lib/kubernetes/ca.crt \\
>   --kubelet-client-certificate=/var/lib/kubernetes/kube-apiserver.crt \\
>   --kubelet-client-key=/var/lib/kubernetes/kube-apiserver.key \\
>   --kubelet-https=true \\
>   --runtime-config=api/all \\
>   --service-account-key-file=/var/lib/kubernetes/service-account.crt \\
>   --service-cluster-ip-range=10.96.0.0/24 \\
>   --service-node-port-range=30000-32767 \\
>   --tls-cert-file=/var/lib/kubernetes/kube-apiserver.crt \\
>   --tls-private-key-file=/var/lib/kubernetes/kube-apiserver.key \\
>   --v=2
> Restart=on-failure
> RestartSec=5
> 
> [Install]
> WantedBy=multi-user.target
> EOF
[Unit]
Description=Kubernetes API Server
Documentation=https://github.com/kubernetes/kubernetes

[Service]
ExecStart=/usr/local/bin/kube-apiserver \
  --advertise-address=172.31.125.181 \
  --allow-privileged=true \
  --apiserver-count=3 \
  --audit-log-maxage=30 \
  --audit-log-maxbackup=3 \
  --audit-log-maxsize=100 \
  --audit-log-path=/var/log/audit.log \
  --authorization-mode=Node,RBAC \
  --bind-address=0.0.0.0 \
  --client-ca-file=/var/lib/kubernetes/ca.crt \
  --enable-admission-plugins=NodeRestriction,ServiceAccount \
  --enable-swagger-ui=true \
  --enable-bootstrap-token-auth=true \
  --etcd-cafile=/var/lib/kubernetes/ca.crt \
  --etcd-certfile=/var/lib/kubernetes/etcd-server.crt \
  --etcd-keyfile=/var/lib/kubernetes/etcd-server.key \
  --etcd-servers=https://172.31.122.25:2379,https://172.31.125.181:2379,https://172.31.115.2:2379 \
  --event-ttl=1h \
  --encryption-provider-config=/var/lib/kubernetes/encryption-config.yaml \
  --kubelet-certificate-authority=/var/lib/kubernetes/ca.crt \
  --kubelet-client-certificate=/var/lib/kubernetes/kube-apiserver.crt \
  --kubelet-client-key=/var/lib/kubernetes/kube-apiserver.key \
  --kubelet-https=true \
  --runtime-config=api/all \
  --service-account-key-file=/var/lib/kubernetes/service-account.crt \
  --service-cluster-ip-range=10.96.0.0/24 \
  --service-node-port-range=30000-32767 \
  --tls-cert-file=/var/lib/kubernetes/kube-apiserver.crt \
  --tls-private-key-file=/var/lib/kubernetes/kube-apiserver.key \
  --v=2
Restart=on-failure
RestartSec=5

[Install]
WantedBy=multi-user.target
root@master2:~# 
root@master2:~# 
root@master2:~# ls -l /var/lib/kubernetes/encryption-config.yaml
-rw-r--r-- 1 root root 240 Jan 24 17:05 /var/lib/kubernetes/encryption-config.yaml
root@master2:~# ls -l /var/lib/kubernetes/
total 36
-rw-r--r-- 1 root root  989 Jan 24 17:05 ca.crt
-rw-r--r-- 1 root root 1679 Jan 24 17:05 ca.key
-rw-r--r-- 1 root root  240 Jan 24 17:05 encryption-config.yaml
-rw-r--r-- 1 root root 1078 Jan 24 17:05 etcd-server.crt
-rw-r--r-- 1 root root 1679 Jan 24 17:05 etcd-server.key
-rw-r--r-- 1 root root 1489 Jan 24 17:05 kube-apiserver.crt
-rw-r--r-- 1 root root 1675 Jan 24 17:05 kube-apiserver.key
-rw-r--r-- 1 root root  993 Jan 24 17:05 service-account.crt
-rw-r--r-- 1 root root 1675 Jan 24 17:05 service-account.key
root@master2:~# logout
Connection to master2 closed.
root@master1:~/keys# ssh master23
Welcome to Ubuntu 16.04.6 LTS (GNU/Linux 4.4.0-1099-aws x86_64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/advantage

 * Overheard at KubeCon: "microk8s.status just blew my mind".

     https://microk8s.io/docs/commands#microk8s.status

  Get cloud support with Ubuntu Advantage Cloud Guest:
    http://www.ubuntu.com/business/services/cloud

15 packages can be updated.
0 updates are security updates.

New release '18.04.3 LTS' available.
Run 'do-release-upgrade' to upgrade to it.


*** System restart required ***
Last login: Fri Jan 24 17:00:01 2020 from 172.31.122.25
root@master3:~# INTERNAL_IP=$(ip addr show ens5| grep "inet " | awk '{print $2}' | cut -d / -f 1)
root@master3:~# cat <<EOF | sudo tee /etc/systemd/system/kube-apiserver.service
> [Unit]
> Description=Kubernetes API Server
> Documentation=https://github.com/kubernetes/kubernetes
> 
> [Service]
> ExecStart=/usr/local/bin/kube-apiserver \\
>   --advertise-address=${INTERNAL_IP} \\
>   --allow-privileged=true \\
>   --apiserver-count=3 \\
>   --audit-log-maxage=30 \\
>   --audit-log-maxbackup=3 \\
>   --audit-log-maxsize=100 \\
>   --audit-log-path=/var/log/audit.log \\
>   --authorization-mode=Node,RBAC \\
>   --bind-address=0.0.0.0 \\
>   --client-ca-file=/var/lib/kubernetes/ca.crt \\
>   --enable-admission-plugins=NodeRestriction,ServiceAccount \\
>   --enable-swagger-ui=true \\
>   --enable-bootstrap-token-auth=true \\
>   --etcd-cafile=/var/lib/kubernetes/ca.crt \\
>   --etcd-certfile=/var/lib/kubernetes/etcd-server.crt \\
>   --etcd-keyfile=/var/lib/kubernetes/etcd-server.key \\
>   --etcd-servers=https://172.31.122.25:2379,https://172.31.125.181:2379,https://172.31.115.2:2379 \\
>   --event-ttl=1h \\
>   --encryption-provider-config=/var/lib/kubernetes/encryption-config.yaml \\
>   --kubelet-certificate-authority=/var/lib/kubernetes/ca.crt \\
>   --kubelet-client-certificate=/var/lib/kubernetes/kube-apiserver.crt \\
>   --kubelet-client-key=/var/lib/kubernetes/kube-apiserver.key \\
>   --kubelet-https=true \\
>   --runtime-config=api/all \\
>   --service-account-key-file=/var/lib/kubernetes/service-account.crt \\
>   --service-cluster-ip-range=10.96.0.0/24 \\
>   --service-node-port-range=30000-32767 \\
>   --tls-cert-file=/var/lib/kubernetes/kube-apiserver.crt \\
>   --tls-private-key-file=/var/lib/kubernetes/kube-apiserver.key \\
>   --v=2
> Restart=on-failure
> RestartSec=5
> 
> [Install]
> WantedBy=multi-user.target
> EOF
[Unit]
Description=Kubernetes API Server
Documentation=https://github.com/kubernetes/kubernetes

[Service]
ExecStart=/usr/local/bin/kube-apiserver \
  --advertise-address=172.31.115.2 \
  --allow-privileged=true \
  --apiserver-count=3 \
  --audit-log-maxage=30 \
  --audit-log-maxbackup=3 \
  --audit-log-maxsize=100 \
  --audit-log-path=/var/log/audit.log \
  --authorization-mode=Node,RBAC \
  --bind-address=0.0.0.0 \
  --client-ca-file=/var/lib/kubernetes/ca.crt \
  --enable-admission-plugins=NodeRestriction,ServiceAccount \
  --enable-swagger-ui=true \
  --enable-bootstrap-token-auth=true \
  --etcd-cafile=/var/lib/kubernetes/ca.crt \
  --etcd-certfile=/var/lib/kubernetes/etcd-server.crt \
  --etcd-keyfile=/var/lib/kubernetes/etcd-server.key \
  --etcd-servers=https://172.31.122.25:2379,https://172.31.125.181:2379,https://172.31.115.2:2379 \
  --event-ttl=1h \
  --encryption-provider-config=/var/lib/kubernetes/encryption-config.yaml \
  --kubelet-certificate-authority=/var/lib/kubernetes/ca.crt \
  --kubelet-client-certificate=/var/lib/kubernetes/kube-apiserver.crt \
  --kubelet-client-key=/var/lib/kubernetes/kube-apiserver.key \
  --kubelet-https=true \
  --runtime-config=api/all \
  --service-account-key-file=/var/lib/kubernetes/service-account.crt \
  --service-cluster-ip-range=10.96.0.0/24 \
  --service-node-port-range=30000-32767 \
  --tls-cert-file=/var/lib/kubernetes/kube-apiserver.crt \
  --tls-private-key-file=/var/lib/kubernetes/kube-apiserver.key \
  --v=2
Restart=on-failure
RestartSec=5

[Install]
WantedBy=multi-user.target
root@master3:~# 
root@master3:~# logout
Connection to master3 closed.
root@master1:~/keys# 
root@master1:~/keys# ls -l kube-controller-manager.kubeconfig
-rw------- 1 root root 5289 Jan 24 13:12 kube-controller-manager.kubeconfig
root@master1:~/keys# (reverse-i-search)`':f': ls -l kube-controller-manager.kubeconfigo': for instance in master2 master3; do scp /root/keys/ca.crt /root/keys/ca.key /root/keys/kube-apiserver..crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /rroot/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doner': for instance in master2 master3; do scp /root/keys/ca.crt /root/keys/ca.key /root/keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /rroot@master1:~/keys# for instance in master2 master3; do scp /root/keys/ca.crt /root/keys/ca.key /root/keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /rootroot@master1:~/keys# cp /root/keys/ca.crt /root/keys/ca.key /root/keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/root@master1:~/keys# p /root/keys/ca.crt /root/keys/ca.key /root/keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/kroot@master1:~/keys#  /root/keys/ca.crt /root/keys/ca.key /root/keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keroot@master1:~/keys# /root/keys/ca.crt /root/keys/ca.key /root/keys/kube-apiserver.crt /rot/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keyroot@master1:~/keys# root/keys/ca.crt /root/keys/ca.key /root/keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keysroot@master1:~/keys# oot/keys/ca.crt /root/keys/ca.key /root/keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/root@master1:~/keys# t/keys/ca.crt /root/keys/ca.key /root/keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/eroot@master1:~/keys# t/keys/ca.crt /root/keys/ca.key /root/keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etroot@master1:~/keys# /keys/ca.crt /root/keys/ca.key /root/keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcroot@master1:~/keys# keys/ca.crt /root/keys/ca.key /root/keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcdroot@master1:~/keys# eys/ca.crt /root/keys/ca.key /root/keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-root@master1:~/keys# ys/ca.crt /root/keys/ca.key /root/keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-sroot@master1:~/keys# s/ca.crt /root/keys/ca.key /root/keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-seroot@master1:~/keys# /ca.crt /root/keys/ca.key /root/keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-serroot@master1:~/keys# ca.crt /root/keys/ca.key /root/keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-servroot@master1:~/keys# a.crt /root/keys/ca.key /root/keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-serveroot@master1:~/keys# .crt /root/keys/ca.key /root/keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-serverroot@master1:~/keys# crt /root/keys/ca.key /root/keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.root@master1:~/keys# rt /root/keys/ca.key /root/keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.croot@master1:~/keys# t /root/keys/ca.key /root/keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crroot@master1:~/keys#  /root/keys/ca.key /root/keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crtroot@master1:~/keys# /root/keys/ca.key /root/keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt root@master1:~/keys# root/keys/ca.key /root/keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root@master1:~/keys# oot/keys/ca.key /root/keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /rroot@master1:~/keys# t/keys/ca.key /root/keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /roroot@master1:~/keys# t/keys/ca.key /root/keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /rooroot@master1:~/keys# /keys/ca.key /root/keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /rootroot@master1:~/keys# keys/ca.key /root/keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/root@master1:~/keys# eys/ca.key /root/keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/kroot@master1:~/keys# ys/ca.key /root/keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keroot@master1:~/keys# s/ca.key /root/keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keyroot@master1:~/keys# /ca.key /root/keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keysroot@master1:~/keys# ca.key /root/keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/root@master1:~/keys# a.key /root/keys/kube-apiserver.crt /root/keys/kube-apiserver.key /rot/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/eroot@master1:~/keys# .key /root/keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/enroot@master1:~/keys# key /root/keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encroot@master1:~/keys# ey /root/keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encrroot@master1:~/keys# y /root/keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryroot@master1:~/keys#  /root/keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryproot@master1:~/keys# /root/keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryptroot@master1:~/keys# root/keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryptiroot@master1:~/keys# oot/keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryptioroot@master1:~/keys# t/keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryptionroot@master1:~/keys# t/keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-root@master1:~/keys# /keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-croot@master1:~/keys# keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-coroot@master1:~/keys# eys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-conroot@master1:~/keys# ys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-confroot@master1:~/keys# s/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-confiroot@master1:~/keys# /kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-configroot@master1:~/keys# kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-config.root@master1:~/keys# ube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-acount.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-config.yroot@master1:~/keys# be-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-config.yaroot@master1:~/keys# e-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-config.yamroot@master1:~/keys# -apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneapiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;donepiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneerver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;donerver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;donever.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneer.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doner.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;done.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /rot/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;donecrt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;donert /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;donet /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;done /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;done/root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneroot/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneoot/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneroot@master1:~/keys# t/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneroot@master1:~/keys# t/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneroot@master1:~/keys# /keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneroot@master1:~/keys# keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneroot@master1:~/keys# eys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneroot@master1:~/keys# ys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneroot@master1:~/keys# s/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneroot@master1:~/keys# /kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneroot@master1:~/keys# kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneroot@master1:~/keys# ube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneroot@master1:~/keys# be-apiserver.key /root/keys/service-account.key /root/keys/service-acount.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneroot@master1:~/keys# e-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneroot@master1:~/keys# -apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneroot@master1:~/keys# apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneroot@master1:~/keys# piserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneroot@master1:~/keys# iserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneroot@master1:~/keys# server.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneroot@master1:~/keys# erver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneroot@master1:~/keys# rver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneroot@master1:~/keys# ver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;done er.key /root/keys/service-account.key /root/keys/service-account.crt 
r.key /root/keys/service-account.key /root/keys/service-account.crt /root@master1:~/keys# .key /root/keys/service-account.key /root/keys/service-account.crt /rroot@master1:~/keys# key /root/keys/service-account.key /root/keys/service-account.crt /roroot@master1:~/keys# ey /root/keys/service-account.key /root/keys/service-account.crt /rooroot@master1:~/keys# y /root/keys/service-account.key /root/keys/service-account.crt /rootroot@master1:~/keys#  /root/keys/service-account.key /root/keys/service-account.crt /root/root@master1:~/keys# /root/keys/service-account.key /root/keys/service-account.crt /root/kroot@master1:~/keys# root/keys/service-account.key /root/keys/service-account.crt /root/keroot@master1:~/keys# oot/keys/service-account.key /root/keys/service-account.crt /root/keyroot@master1:~/keys# t/keys/service-account.key /root/keys/service-account.crt /root/keysroot@master1:~/keys# t/keys/service-account.key /root/keys/service-account.crt /root/keys/root@master1:~/keys# /keys/service-account.key /root/keys/service-account.crt /root/keys/eroot@master1:~/keys# keys/service-account.key /root/keys/service-account.crt /root/keys/etroot@master1:~/keys# eys/service-account.key /root/keys/service-account.crt /root/keys/etcroot@master1:~/keys# ys/service-account.key /root/keys/service-account.crt /root/keys/etcdroot@master1:~/keys# s/service-account.key /root/keys/service-account.crt /root/keys/etcd-root@master1:~/keys# /service-account.key /root/keys/service-account.crt /root/keys/etcd-sroot@master1:~/keys# service-account.key /root/keys/service-account.crt /root/keys/etcd-seroot@master1:~/keys# ervice-account.key /root/keys/service-account.crt /root/keys/etcd-serroot@master1:~/keys# rvice-account.key /root/keys/service-account.crt /root/keys/etcd-servroot@master1:~/keys# vice-account.key /root/keys/service-account.crt /root/keys/etcd-serveroot@master1:~/keys# ice-account.key /root/keys/service-account.crt /root/keys/etcd-serverroot@master1:~/keys# ce-account.key /root/keys/service-account.crt /root/keys/etcd-server.root@master1:~/keys# e-account.key /root/keys/service-account.crt /root/keys/etcd-server.kroot@master1:~/keys# -account.key /root/keys/service-account.crt /root/keys/etcd-server.keroot@master1:~/keys# account.key /root/keys/service-account.crt /root/keys/etcd-server.keyroot@master1:~/keys# ccount.key /root/keys/service-account.crt /root/keys/etcd-server.key root@master1:~/keys# ount.key /root/keys/service-account.crt /root/keys/etcd-server.key /root@master1:~/keys# ount.key /root/keys/service-account.crt /root/keys/etcd-server.key /rroot@master1:~/keys# unt.key /root/keys/service-account.crt /root/keys/etcd-server.key /roroot@master1:~/keys# nt.key /root/keys/service-account.crt /root/keys/etcd-server.key /rooroot@master1:~/keys# t.key /root/keys/service-account.crt /root/keys/etcd-server.key /rootroot@master1:~/keys# .key /root/keys/service-account.crt /root/keys/etcd-server.key /root/root@master1:~/keys# key /root/keys/service-account.crt /root/keys/etcd-server.key /root/kroot@master1:~/keys# ey /root/keys/service-account.crt /root/keys/etcd-server.key /root/keroot@master1:~/keys# y /root/keys/service-account.crt /root/keys/etcd-server.key /root/keyroot@master1:~/keys#  /root/keys/service-account.crt /root/keys/etcd-server.key /root/keysroot@master1:~/keys# /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/root@master1:~/keys# root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/eroot@master1:~/keys# oot/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etroot@master1:~/keys# t/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcroot@master1:~/keys# t/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcdroot@master1:~/keys# /keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-root@master1:~/keys# keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-sroot@master1:~/keys# eys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-seroot@master1:~/keys# ys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-serroot@master1:~/keys# s/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-servroot@master1:~/keys# /service-account.crt /root/keys/etcd-server.key /root/keys/etcd-serveroot@master1:~/keys# service-account.crt /root/keys/etcd-server.key /root/keys/etcd-serverroot@master1:~/keys# ervice-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.root@master1:~/keys# rvice-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.croot@master1:~/keys# vice-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crroot@master1:~/keys# ice-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crtroot@master1:~/keys# ce-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt root@master1:~/keys# e-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root@master1:~/keys# -account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /rroot@master1:~/keys# account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /roroot@master1:~/keys# ccount.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /rooroot@master1:~/keys# ount.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /rootroot@master1:~/keys# ount.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/root@master1:~/keys# unt.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/kroot@master1:~/keys# nt.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keroot@master1:~/keys# t.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keyroot@master1:~/keys# .crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keysroot@master1:~/keys# crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/root@master1:~/keys# rt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/eroot@master1:~/keys# t /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/enroot@master1:~/keys#  /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encroot@master1:~/keys# /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encrroot@master1:~/keys# root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryroot@master1:~/keys# oot/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryproot@master1:~/keys# t/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryptroot@master1:~/keys# t/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryptiroot@master1:~/keys# /keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryptioroot@master1:~/keys# keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryptionroot@master1:~/keys# eys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-root@master1:~/keys# ys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-croot@master1:~/keys# s/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-coroot@master1:~/keys# /etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-conroot@master1:~/keys# etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-confroot@master1:~/keys# tcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-confiroot@master1:~/keys# cd-server.key /root/keys/etcd-server.crt /root/keys/encryption-configroot@master1:~/keys# d-server.key /root/keys/etcd-server.crt /root/keys/encryption-config.root@master1:~/keys# -server.key /root/keys/etcd-server.crt /root/keys/encryption-config.yroot@master1:~/keys# server.key /root/keys/etcd-server.crt /root/keys/encryption-config.yaroot@master1:~/keys# erver.key /root/keys/etcd-server.crt /root/keys/encryption-config.yamroot@master1:~/keys# rver.key /root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;donever.key /root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneer.key /root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doner.key /root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;done.key /root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;donekey /root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneey /root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doney /root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;done /root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;done/root/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneroot/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneoot/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;donet/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;donet/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;done/keys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;donekeys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneeys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneys/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneroot@master1:~/keys# s/etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneroot@master1:~/keys# /etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneroot@master1:~/keys# etcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneroot@master1:~/keys# tcd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneroot@master1:~/keys# cd-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneroot@master1:~/keys# d-server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneroot@master1:~/keys# -server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneroot@master1:~/keys# server.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneroot@master1:~/keys# erver.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneroot@master1:~/keys# rver.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneroot@master1:~/keys# ver.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneroot@master1:~/keys# er.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneroot@master1:~/keys# r.crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneroot@master1:~/keys# .crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneroot@master1:~/keys# crt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneroot@master1:~/keys# rt /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneroot@master1:~/keys# t /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneroot@master1:~/keys#  /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneroot@master1:~/keys# /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;doneroot@master1:~/keys# root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/;done 
 $instance:/var/lib/kubernetes/;done$instance:/var/lib/kubernetes/;doneinstance:/var/lib/kubernetes/;donenstance:/var/lib/kubernetes/;donestance:/var/lib/kubernetes/;donetance:/var/lib/kubernetes/;doneance:/var/lib/kubernetes/;donence:/var/lib/kubernetes/;donece:/var/lib/kubernetes/;donee:/var/lib/kubernetes/;done:/var/lib/kubernetes/;done/var/lib/kubernetes/;donevar/lib/kubernetes/;donear/lib/kubernetes/;doner/lib/kubernetes/;done/lib/kubernetes/;donelib/kubernetes/;doneib/kubernetes/;doneb/kubernetes/;done/kubernetes/;donekubernetes/;doneubernetes/;donebernetes/;doneernetes/;donernetes/;donenetes/;doneetes/;donetes/;donees/;dones/;done/;done;dones;donec;donep;done ;donek;doneu;doneb;donee;done-;donec;doneo;donen;donet;doner;doneo;donel;donel;donee;doner;done-;donem;donea;donen;donea;doneg;donee;doner;done.;donek;doneu;doneb;donee;donec;doneo;donen;donef;donei;doneg;done ;done$;donei;donen;dones;donet;donea;donen;donec;donee;done:;done/;donev;donea;doner;done/;donel;donei;doneb;done/;donek;doneu;doneb;donee;doner;done root@master1:~/keys# n;doneeroot@master1:~/keys# e;doneroot@master1:~/keys# t;doneroot@master1:~/keys# e;doneroot@master1:~/keys# s;done/;done;doned;doneo;donen;donee;done;done;done;done;donedone
kube-controller-manager.kubeconfig                                                           0%    0     0.0KB/s   --:-- ETAkube-controller-manager.kubeconfig                                                         100% 5289     5.2KB/s   00:00    
kube-controller-manager.kubeconfig                                                           0%    0     0.0KB/s   --:-- ETAkube-controller-manager.kubeconfig                                                         100% 5289     5.2KB/s   00:00    
root@master1:~/keys# cp kube-controller-manager.kubeconfig /var/lib/kubernetes/
root@master1:~/keys# cat <<EOF | sudo tee /etc/systemd/system/kube-controller-manager.service
> [Unit]
> Description=Kubernetes Controller Manager
> Documentation=https://github.com/kubernetes/kubernetes
> 
> [Service]
> ExecStart=/usr/local/bin/kube-controller-manager \\
>   --address=0.0.0.0 \\
>   --cluster-cidr=172.31.0.0/20 \\
>   --cluster-name=kubernetes \\
>   --cluster-signing-cert-file=/var/lib/kubernetes/ca.crt \\
>   --cluster-signing-key-file=/var/lib/kubernetes/ca.key \\
>   --kubeconfig=/var/lib/kubernetes/kube-controller-manager.kubeconfig \\
>   --leader-elect=true \\
>   --root-ca-file=/var/lib/kubernetes/ca.crt \\
>   --service-account-private-key-file=/var/lib/kubernetes/service-account.key \\
>   --service-cluster-ip-range=10.96.0.0/24 \\
>   --use-service-account-credentials=true \\
>   --v=2
> Restart=on-failure
> RestartSec=5
> 
> [Install]
> WantedBy=multi-user.target
> EOF
[Unit]
Description=Kubernetes Controller Manager
Documentation=https://github.com/kubernetes/kubernetes

[Service]
ExecStart=/usr/local/bin/kube-controller-manager \
  --address=0.0.0.0 \
  --cluster-cidr=172.31.0.0/20 \
  --cluster-name=kubernetes \
  --cluster-signing-cert-file=/var/lib/kubernetes/ca.crt \
  --cluster-signing-key-file=/var/lib/kubernetes/ca.key \
  --kubeconfig=/var/lib/kubernetes/kube-controller-manager.kubeconfig \
  --leader-elect=true \
  --root-ca-file=/var/lib/kubernetes/ca.crt \
  --service-account-private-key-file=/var/lib/kubernetes/service-account.key \
  --service-cluster-ip-range=10.96.0.0/24 \
  --use-service-account-credentials=true \
  --v=2
Restart=on-failure
RestartSec=5

[Install]
WantedBy=multi-user.target
root@master1:~/keys# cp kube-scheduler.kubeconfig /var/lib/kubernetes/
root@master1:~/keys# ls -l kube-scheduler.k
ls: cannot access 'kube-scheduler.k': No such file or directory
root@master1:~/keys# ls -l kube-scheduler.k*
-rw-r--r-- 1 root root 1679 Jan 24 12:58 kube-scheduler.key
-rw------- 1 root root 5259 Jan 24 13:12 kube-scheduler.kubeconfig
root@master1:~/keys# ls -l /var/lib/kubernetes/
total 52
-rw-r--r-- 1 root root  989 Jan 24 17:05 ca.crt
-rw-r--r-- 1 root root 1679 Jan 24 17:05 ca.key
-rw-r--r-- 1 root root  240 Jan 24 17:05 encryption-config.yaml
-rw-r--r-- 1 root root 1078 Jan 24 17:05 etcd-server.crt
-rw-r--r-- 1 root root 1679 Jan 24 17:05 etcd-server.key
-rw-r--r-- 1 root root 1489 Jan 24 17:05 kube-apiserver.crt
-rw-r--r-- 1 root root 1675 Jan 24 17:05 kube-apiserver.key
-rw------- 1 root root 5289 Jan 24 17:11 kube-controller-manager.kubeconfig
-rw------- 1 root root 5259 Jan 24 17:12 kube-scheduler.kubeconfig
-rw-r--r-- 1 root root  993 Jan 24 17:05 service-account.crt
-rw-r--r-- 1 root root 1675 Jan 24 17:05 service-account.key
root@master1:~/keys# ls -l /var/lib/kubernetes/kube-scheduler.k*cp kube-scheduler.kubeconfig /var/lib/kubernetes/EOFWantedBy=multi-user.target[Install]RestartSec=5=on-failure  --v=2use-service-account-credentials=true \\^C
root@master1:~/keys# (reverse-i-search)`':s': ls -l /var/lib/kubernetes/f': cp kube-scheduler.kubeconfigo': for instance in master2 master3; do scp kube-controller-manager.kubeconfig $instance:/var/lib/kubernettes/;doner': for instance in master2 master3; do scp kube-controller-manager.kubeconfig $instance:/var/lib/kubernetes/;doneroot@master1:~/keys# for instance in master2 master3; do scp kube-controller-manager.kubeconfig $instance:/var/lib/kubernetes/;doneroot@master1:~/keys#  $instance:/var/lib/kubernetes/;done
k $instance:/var/lib/kubernetes/;doneu $instance:/var/lib/kubernetes/;doneb $instance:/var/lib/kubernetes/;donee $instance:/var/lib/kubernetes/;done- $instance:/var/lib/kubernetes/;dones $instance:/var/lib/kubernetes/;donec $instance:/var/lib/kubernetes/;doneh $instance:/var/lib/kubernetes/;donee $instance:/var/lib/kubernetes/;doned $instance:/var/lib/kubernetes/;doneu $instance:/var/lib/kubernetes/;donel $instance:/var/lib/kubernetes/;donee $instance:/var/lib/kubernetes/;doner $instance:/var/lib/kubernetes/;done. $instance:/var/lib/kubernetes/;donek $instance:/var/lib/kubernetes/;doneu $instance:/var/lib/kubernetes/;doneb $instance:/var/lib/kubernetes/;donee $instance:/var/lib/kubernetes/;donec $instance:/var/lib/kubernetes/;doneo $instance:/var/lib/kubernetes/;donen $instance:/var/lib/kubernetes/;donef $instance:/var/lib/kubernetes/;donei $instance:/var/lib/kubernetes/;doneg $instance:/var/lib/kubernetes/;done
kube-scheduler.kubeconfig                                                                    0%    0     0.0KB/s   --:-- ETAkube-scheduler.kubeconfig                                                                  100% 5259     5.1KB/s   00:00    
kube-scheduler.kubeconfig                                                                    0%    0     0.0KB/s   --:-- ETAkube-scheduler.kubeconfig                                                                  100% 5259     5.1KB/s   00:00    
root@master1:~/keys# cat <<EOF | sudo tee /etc/systemd/system/kube-scheduler.service
> [Unit]
> Description=Kubernetes Scheduler
> Documentation=https://github.com/kubernetes/kubernetes
> 
> [Service]
> ExecStart=/usr/local/bin/kube-scheduler \\
>   --kubeconfig=/var/lib/kubernetes/kube-scheduler.kubeconfig \\
>   --address=127.0.0.1 \\
>   --leader-elect=true \\
>   --v=2
> Restart=on-failure
> RestartSec=5
> 
> [Install]
> WantedBy=multi-user.target
> EOF
[Unit]
Description=Kubernetes Scheduler
Documentation=https://github.com/kubernetes/kubernetes

[Service]
ExecStart=/usr/local/bin/kube-scheduler \
  --kubeconfig=/var/lib/kubernetes/kube-scheduler.kubeconfig \
  --address=127.0.0.1 \
  --leader-elect=true \
  --v=2
Restart=on-failure
RestartSec=5

[Install]
WantedBy=multi-user.target
root@master1:~/keys# systemctl daemon-reload
root@master1:~/keys# ssh master2
Welcome to Ubuntu 16.04.6 LTS (GNU/Linux 4.4.0-1099-aws x86_64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/advantage

 * Overheard at KubeCon: "microk8s.status just blew my mind".

     https://microk8s.io/docs/commands#microk8s.status

  Get cloud support with Ubuntu Advantage Cloud Guest:
    http://www.ubuntu.com/business/services/cloud

15 packages can be updated.
0 updates are security updates.

New release '18.04.3 LTS' available.
Run 'do-release-upgrade' to upgrade to it.


*** System restart required ***
Last login: Fri Jan 24 17:09:17 2020 from 172.31.122.25
root@master2:~# ls -l /etc/systemd/system/kube-apiserver.service
-rw-r--r-- 1 root root 1566 Jan 24 17:09 /etc/systemd/system/kube-apiserver.service
root@master2:~# ls -l  /etc/systemd/system/kube-controller-manager.service
ls: cannot access '/etc/systemd/system/kube-controller-manager.service': No such file or directory
root@master2:~# cat <<EOF | sudo tee /etc/systemd/system/kube-controller-manager.service
> [Unit]
> Description=Kubernetes Controller Manager
> Documentation=https://github.com/kubernetes/kubernetes
> 
> [Service]
> ExecStart=/usr/local/bin/kube-controller-manager \\
>   --address=0.0.0.0 \\
>   --cluster-cidr=172.31.0.0/20 \\
>   --cluster-name=kubernetes \\
>   --cluster-signing-cert-file=/var/lib/kubernetes/ca.crt \\
>   --cluster-signing-key-file=/var/lib/kubernetes/ca.key \\
>   --kubeconfig=/var/lib/kubernetes/kube-controller-manager.kubeconfig \\
>   --leader-elect=true \\
>   --root-ca-file=/var/lib/kubernetes/ca.crt \\
>   --service-account-private-key-file=/var/lib/kubernetes/service-account.key \\
>   --service-cluster-ip-range=10.96.0.0/24 \\
>   --use-service-account-credentials=true \\
>   --v=2
> Restart=on-failure
> RestartSec=5
> 
> [Install]
> WantedBy=multi-user.target
> EOF
[Unit]
Description=Kubernetes Controller Manager
Documentation=https://github.com/kubernetes/kubernetes

[Service]
ExecStart=/usr/local/bin/kube-controller-manager \
  --address=0.0.0.0 \
  --cluster-cidr=172.31.0.0/20 \
  --cluster-name=kubernetes \
  --cluster-signing-cert-file=/var/lib/kubernetes/ca.crt \
  --cluster-signing-key-file=/var/lib/kubernetes/ca.key \
  --kubeconfig=/var/lib/kubernetes/kube-controller-manager.kubeconfig \
  --leader-elect=true \
  --root-ca-file=/var/lib/kubernetes/ca.crt \
  --service-account-private-key-file=/var/lib/kubernetes/service-account.key \
  --service-cluster-ip-range=10.96.0.0/24 \
  --use-service-account-credentials=true \
  --v=2
Restart=on-failure
RestartSec=5

[Install]
WantedBy=multi-user.target
root@master2:~# 
root@master2:~# ls -l /var/lib/kubernetes/kube-scheduler.kubeconfig
-rw------- 1 root root 5259 Jan 24 17:12 /var/lib/kubernetes/kube-scheduler.kubeconfig
root@master2:~# cat <<EOF | sudo tee /etc/systemd/system/kube-scheduler.service
> [Unit]
> Description=Kubernetes Scheduler
> Documentation=https://github.com/kubernetes/kubernetes
> 
> [Service]
> ExecStart=/usr/local/bin/kube-scheduler \\
>   --kubeconfig=/var/lib/kubernetes/kube-scheduler.kubeconfig \\
>   --address=127.0.0.1 \\
>   --leader-elect=true \\
>   --v=2
> Restart=on-failure
> RestartSec=5
> 
> [Install]
> WantedBy=multi-user.target
> EOF
[Unit]
Description=Kubernetes Scheduler
Documentation=https://github.com/kubernetes/kubernetes

[Service]
ExecStart=/usr/local/bin/kube-scheduler \
  --kubeconfig=/var/lib/kubernetes/kube-scheduler.kubeconfig \
  --address=127.0.0.1 \
  --leader-elect=true \
  --v=2
Restart=on-failure
RestartSec=5

[Install]
WantedBy=multi-user.target
root@master2:~# 
root@master2:~# logout
Connection to master2 closed.
root@master1:~/keys# ssh master23
Welcome to Ubuntu 16.04.6 LTS (GNU/Linux 4.4.0-1099-aws x86_64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/advantage

 * Overheard at KubeCon: "microk8s.status just blew my mind".

     https://microk8s.io/docs/commands#microk8s.status

  Get cloud support with Ubuntu Advantage Cloud Guest:
    http://www.ubuntu.com/business/services/cloud

15 packages can be updated.
0 updates are security updates.

New release '18.04.3 LTS' available.
Run 'do-release-upgrade' to upgrade to it.


*** System restart required ***
Last login: Fri Jan 24 17:09:55 2020 from 172.31.122.25
root@master3:~# cat <<EOF | sudo tee /etc/systemd/system/kube-scheduler.service
> [Unit]
> Description=Kubernetes Scheduler
> Documentation=https://github.com/kubernetes/kubernetes
> 
> [Service]
> ExecStart=/usr/local/bin/kube-scheduler \\
>   --kubeconfig=/var/lib/kubernetes/kube-scheduler.kubeconfig \\
>   --address=127.0.0.1 \\
>   --leader-elect=true \\
>   --v=2
> Restart=on-failure
> RestartSec=5
> 
> [Install]
> WantedBy=multi-user.target
> EOF
[Unit]
Description=Kubernetes Scheduler
Documentation=https://github.com/kubernetes/kubernetes

[Service]
ExecStart=/usr/local/bin/kube-scheduler \
  --kubeconfig=/var/lib/kubernetes/kube-scheduler.kubeconfig \
  --address=127.0.0.1 \
  --leader-elect=true \
  --v=2
Restart=on-failure
RestartSec=5

[Install]
WantedBy=multi-user.target
root@master3:~# 
root@master3:~# ls -l /var/lib/kubernetes/kube-scheduler.kubeconfig
-rw------- 1 root root 5259 Jan 24 17:13 /var/lib/kubernetes/kube-scheduler.kubeconfig
root@master3:~# cat <<EOF | sudo tee /etc/systemd/system/kube-controller-manager.service
> [Unit]
> Description=Kubernetes Controller Manager
> Documentation=https://github.com/kubernetes/kubernetes
> 
> [Service]
> ExecStart=/usr/local/bin/kube-controller-manager \\
>   --address=0.0.0.0 \\
>   --cluster-cidr=172.31.0.0/20 \\
>   --cluster-name=kubernetes \\
>   --cluster-signing-cert-file=/var/lib/kubernetes/ca.crt \\
>   --cluster-signing-key-file=/var/lib/kubernetes/ca.key \\
>   --kubeconfig=/var/lib/kubernetes/kube-controller-manager.kubeconfig \\
>   --leader-elect=true \\
>   --root-ca-file=/var/lib/kubernetes/ca.crt \\
>   --service-account-private-key-file=/var/lib/kubernetes/service-account.key \\
>   --service-cluster-ip-range=10.96.0.0/24 \\
>   --use-service-account-credentials=true \\
>   --v=2
> Restart=on-failure
> RestartSec=5
> 
> [Install]
> WantedBy=multi-user.target
> EOF
[Unit]
Description=Kubernetes Controller Manager
Documentation=https://github.com/kubernetes/kubernetes

[Service]
ExecStart=/usr/local/bin/kube-controller-manager \
  --address=0.0.0.0 \
  --cluster-cidr=172.31.0.0/20 \
  --cluster-name=kubernetes \
  --cluster-signing-cert-file=/var/lib/kubernetes/ca.crt \
  --cluster-signing-key-file=/var/lib/kubernetes/ca.key \
  --kubeconfig=/var/lib/kubernetes/kube-controller-manager.kubeconfig \
  --leader-elect=true \
  --root-ca-file=/var/lib/kubernetes/ca.crt \
  --service-account-private-key-file=/var/lib/kubernetes/service-account.key \
  --service-cluster-ip-range=10.96.0.0/24 \
  --use-service-account-credentials=true \
  --v=2
Restart=on-failure
RestartSec=5

[Install]
WantedBy=multi-user.target
root@master3:~# 
root@master3:~# 
root@master3:~# ls -l /etc/systemd/system/kube-controller-manager.service
-rw-r--r-- 1 root root 754 Jan 24 17:14 /etc/systemd/system/kube-controller-manager.service
root@master3:~# 
root@master3:~# 
root@master3:~# ls -l /etc/systemd/system/kube-controller-manager.service*
-rw-r--r-- 1 root root 1564 Jan 24 17:10 /etc/systemd/system/kube-apiserver.service
-rw-r--r-- 1 root root  754 Jan 24 17:14 /etc/systemd/system/kube-controller-manager.service
-rw-r--r-- 1 root root  337 Jan 24 17:14 /etc/systemd/system/kube-scheduler.service
root@master3:~# systemctl daemon-reload
root@master3:~# logout
Connection to master3 closed.
root@master1:~/keys# ssh master32
ssh: Could not resolve hostname master32: Name or service not known
root@master1:~/keys# ssh master322
Welcome to Ubuntu 16.04.6 LTS (GNU/Linux 4.4.0-1099-aws x86_64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/advantage

 * Overheard at KubeCon: "microk8s.status just blew my mind".

     https://microk8s.io/docs/commands#microk8s.status

  Get cloud support with Ubuntu Advantage Cloud Guest:
    http://www.ubuntu.com/business/services/cloud

15 packages can be updated.
0 updates are security updates.

New release '18.04.3 LTS' available.
Run 'do-release-upgrade' to upgrade to it.


*** System restart required ***
Last login: Fri Jan 24 17:13:35 2020 from 172.31.122.25
root@master2:~# systemctl daemon-reload
root@master2:~# logout
Connection to master2 closed.
root@master1:~/keys# 
root@master1:~/keys# 
root@master1:~/keys# ssh master2322ystemctl daemon-reloadEOFsystemctl daemon-reloadsh master2322(reverse-i-search)`':s': ssh master2sh^C
root@master1:~/keys# (reverse-i-search)`':f': Restart=on-failureo': for instance in master2 master3; do scp kube-scheduler.kubeconfig $instance:/var/lib/kubernetes/;done r': for instance in master2 master3; do scp kube-scheduler.kubeconfig $instance:/var/lib/kubernetes/;doneeroot@master1:~/keys# for instance in master2 master3; do scp kube-scheduler.kubeconfig $instance:/var/lib/kubernetes/;done
masmaster2 master3; do scp kube-scheduler.kubeconfig $instance:/var/lib/kubernetes/;done root@master1:~/keys# tmaster2 master3; do scp kube-scheduler.kubeconfig $instance:/var/lib/kubernetes/;doneeroot@master1:~/keys# emaster2 master3; do scp kube-scheduler.kubeconfig $instance:/var/lib/kubernetes/;doneroot@master1:~/keys# rmaster2 master3; do scp kube-scheduler.kubeconfig $instance:/var/lib/kubernetes/;doneroot@master1:~/keys# 1master2 master3; do scp kube-scheduler.kubeconfig $instance:/var/lib/kubernetes/;doneroot@master1:~/keys#  master2 master3; do scp kube-scheduler.kubeconfig $instance:/var/lib/kubernetes/;doneroot@master1:~/keys# 
;done
;done;dones;dones;doneh;done ;done$;donei;donen;dones;donea;done;donet;donea;donen;donec;donee;done ;done";dones;doney;dones;donet;donee;donem;donec;donet;donel;done ;donee;donen;donea;doneb;donel;donee;done ;donek;doneu;doneb;donee;done-;donea;donep;donei;dones;donee;doner;donev;donee;doner;done ;donek;doneu;doneb;donee;done-;donec;doneo;donen;done root@master1:~/keys# t;doneeroot@master1:~/keys# r;doneroot@master1:~/keys# o;doneroot@master1:~/keys# l;doneroot@master1:~/keys# l;donee;doner;done-;donem;donea;donen;donea;doneg;donee;doner;done ;donek;doneu;doneb;donee;done-;dones;donec;doneh;donee;doned;doneu;donel;donee;doner;done";done
Created symlink from /etc/systemd/system/multi-user.target.wants/kube-apiserver.service to /etc/systemd/system/kube-apiserver.service.
Created symlink from /etc/systemd/system/multi-user.target.wants/kube-controller-manager.service to /etc/systemd/system/kube-controller-manager.service.
Created symlink from /etc/systemd/system/multi-user.target.wants/kube-scheduler.service to /etc/systemd/system/kube-scheduler.service.
Created symlink from /etc/systemd/system/multi-user.target.wants/kube-apiserver.service to /etc/systemd/system/kube-apiserver.service.
Created symlink from /etc/systemd/system/multi-user.target.wants/kube-controller-manager.service to /etc/systemd/system/kube-controller-manager.service.
Created symlink from /etc/systemd/system/multi-user.target.wants/kube-scheduler.service to /etc/systemd/system/kube-scheduler.service.
Created symlink from /etc/systemd/system/multi-user.target.wants/kube-apiserver.service to /etc/systemd/system/kube-apiserver.service.
Created symlink from /etc/systemd/system/multi-user.target.wants/kube-controller-manager.service to /etc/systemd/system/kube-controller-manager.service.
Created symlink from /etc/systemd/system/multi-user.target.wants/kube-scheduler.service to /etc/systemd/system/kube-scheduler.service.
root@master1:~/keys# 
root@master1:~/keys# for instance in master1 master2 master3; do ssh $instance "systemctl enable kube-apiserver kube-controlleer-manager kube-scheduler";done kube-apiserver kube-controller-manaroot@master1:~/keys# s kube-apiserver kube-controller-manaroot@master1:~/keys# t kube-apiserver kube-controller-manroot@master1:~/keys# a kube-apiserver kube-controller-maroot@master1:~/keys# r kube-apiserver kube-controller-mroot@master1:~/keys# t kube-apiserver kube-controller-root@master1:~/keys# 

root@master1:~/keys# for instance in master1 master2 master3; do ssh $instance "systemctl start kube-apiserver kube-controllerr-manager kube-scheduler";donekube-apiserver kube-controller-managroot@master1:~/keys# skube-apiserver kube-controller-managroot@master1:~/keys# tkube-apiserver kube-controller-manaroot@master1:~/keys# akube-apiserver kube-controller-manroot@master1:~/keys# tkube-apiserver kube-controller-maroot@master1:~/keys# ukube-apiserver kube-controller-mroot@master1:~/keys# skube-apiserver kube-controller-root@master1:~/keys#  kube-apiserver kube-controllerroot@master1:~/keys# 

 kube-apiserver.service - Kubernetes API Server
   Loaded: loaded (/etc/systemd/system/kube-apiserver.service; enabled; vendor preset: enabled)
   Active: active (running) since Fri 2020-01-24 17:16:36 UTC; 11s ago
     Docs: https://github.com/kubernetes/kubernetes
 Main PID: 4039 (kube-apiserver)
    Tasks: 11
   Memory: 273.6M
      CPU: 9.464s
   CGroup: /system.slice/kube-apiserver.service
           4039 /usr/local/bin/kube-apiserver --advertise-address=172.31.122.25 --allow-privileged=true --apiserver-count=3 --audit-log-maxage=30 --audit-log-maxbackup=3 --audit-log-maxsize=100 --audit-log-path=/var/log/audit.log --authorization-mode=Node,RBAC --bind-address=0.0.0.0 --client-ca-file=/var/lib/kubernetes/ca.crt --enable-admission-plugins=NodeRestriction,ServiceAccount --enable-swagger-ui=true --enable-bootstrap-token-auth=true --etcd-cafile=/var/lib/kubernetes/ca.crt --etcd-certfile=/var/lib/kubernetes/etcd-server.crt --etcd-keyfile=/var/lib/kubernetes/etcd-server.key --etcd-servers=https://172.31.122.25:2379,https://172.31.125.181:2379,https://172.31.115.2:2379 --event-ttl=1h --encryption-provider-config=/var/lib/kubernetes/encryption-config.yaml --kubelet-certificate-authority=/var/lib/kubernetes/ca.crt --kubelet-client-certificate=/var/lib/kubernetes/kube-apiserver.crt --kubelet-client-key=/var/lib/kubernetes/kube-apiserver.key --kubelet-https=true --runtime-config=api/all --service-account-key-file=/var/lib/kubernetes/service-account.crt --service-cluster-ip-range=10.96.0.0/24 --service-node-port-range=30000-32767 --tls-cert-file=/var/lib/kubernetes/kube-apiserver.crt --tls-private-key-file=/var/lib/kubernetes/kube-apiserver.key --v=2

Jan 24 17:16:47 master1 kube-apiserver[4039]: I0124 17:16:47.552009    4039 storage_rbac.go:187] created clusterrole.rbac.authorization.k8s.io/system:controller:ttl-controller
Jan 24 17:16:47 master1 kube-apiserver[4039]: I0124 17:16:47.559184    4039 storage_rbac.go:187] created clusterrole.rbac.authorization.k8s.io/system:controller:certificate-controller
Jan 24 17:16:47 master1 kube-apiserver[4039]: I0124 17:16:47.565891    4039 storage_rbac.go:187] created clusterrole.rbac.authorization.k8s.io/system:controller:pvc-protection-controller
Jan 24 17:16:47 master1 kube-apiserver[4039]: I0124 17:16:47.572552    4039 storage_rbac.go:187] created clusterrole.rbac.authorization.k8s.io/system:controller:pv-protection-controller
Jan 24 17:16:47 master1 kube-apiserver[4039]: I0124 17:16:47.601087    4039 storage_rbac.go:215] created clusterrolebinding.rbac.authorization.k8s.io/cluster-admin
Jan 24 17:16:47 master1 kube-apiserver[4039]: I0124 17:16:47.644058    4039 storage_rbac.go:215] created clusterrolebinding.rbac.authorization.k8s.io/system:discovery
Jan 24 17:16:47 master1 kube-apiserver[4039]: I0124 17:16:47.681679    4039 storage_rbac.go:215] created clusterrolebinding.rbac.authorization.k8s.io/system:basic-user
Jan 24 17:16:47 master1 kube-apiserver[4039]: I0124 17:16:47.722568    4039 storage_rbac.go:215] created clusterrolebinding.rbac.authorization.k8s.io/system:node-proxier
Jan 24 17:16:47 master1 kube-apiserver[4039]: I0124 17:16:47.765111    4039 storage_rbac.go:215] created clusterrolebinding.rbac.authorization.k8s.io/system:kube-controller-manager
Jan 24 17:16:47 master1 kube-apiserver[4039]: I0124 17:16:47.800012    4039 storage_rbac.go:215] created clusterrolebinding.rbac.authorization.k8s.io/system:kube-dns

 kube-controller-manager.service - Kubernetes Controller Manager
   Loaded: loaded (/etc/systemd/system/kube-controller-manager.service; enabled; vendor preset: enabled)
   Active: active (running) since Fri 2020-01-24 17:16:36 UTC; 11s ago
     Docs: https://github.com/kubernetes/kubernetes
 Main PID: 4044 (kube-controller)
    Tasks: 6
   Memory: 12.5M
      CPU: 1.832s
   CGroup: /system.slice/kube-controller-manager.service
           4044 /usr/local/bin/kube-controller-manager --address=0.0.0.0 --cluster-cidr=172.31.0.0/20 --cluster-name=kubernetes --cluster-signing-cert-file=/var/lib/kubernetes/ca.crt --cluster-signing-key-file=/var/lib/kubernetes/ca.key --kubeconfig=/var/lib/kubernetes/kube-controller-manager.kubeconfig --leader-elect=true --root-ca-file=/var/lib/kubernetes/ca.crt --service-account-private-key-file=/var/lib/kubernetes/service-account.key --service-cluster-ip-range=10.96.0.0/24 --use-service-account-credentials=true --v=2

Jan 24 17:16:36 master1 kube-controller-manager[4044]: I0124 17:16:36.682698    4044 flags.go:33] FLAG: --vmodule=""
Jan 24 17:16:38 master1 kube-controller-manager[4044]: I0124 17:16:38.284247    4044 serving.go:318] Generated self-signed cert in-memory
Jan 24 17:16:39 master1 kube-controller-manager[4044]: W0124 17:16:39.017316    4044 authentication.go:235] No authentication-kubeconfig provided in order to lookup client-ca-file in configmap/extension-apiserver-authentication in kube-system, so client certificate authentication won't work.
Jan 24 17:16:39 master1 kube-controller-manager[4044]: W0124 17:16:39.017344    4044 authentication.go:238] No authentication-kubeconfig provided in order to lookup requestheader-client-ca-file in configmap/extension-apiserver-authentication in kube-system, so request-header client certificate authentication won't work.
Jan 24 17:16:39 master1 kube-controller-manager[4044]: W0124 17:16:39.017357    4044 authorization.go:146] No authorization-kubeconfig provided, so SubjectAccessReview of authorization tokens won't work.
Jan 24 17:16:39 master1 kube-controller-manager[4044]: I0124 17:16:39.017377    4044 controllermanager.go:151] Version: v1.13.0
Jan 24 17:16:39 master1 kube-controller-manager[4044]: I0124 17:16:39.017924    4044 secure_serving.go:116] Serving securely on [::]:10257
Jan 24 17:16:39 master1 kube-controller-manager[4044]: I0124 17:16:39.018490    4044 deprecated_insecure_serving.go:51] Serving insecurely on [::]:10252
Jan 24 17:16:39 master1 kube-controller-manager[4044]: I0124 17:16:39.018573    4044 leaderelection.go:205] attempting to acquire leader lease  kube-system/kube-controller-manager...
Jan 24 17:16:46 master1 kube-controller-manager[4044]: E0124 17:16:46.287982    4044 leaderelection.go:270] error retrieving resource lock kube-system/kube-controller-manager: endpoints "kube-controller-manager" is forbidden: User "system:kube-controller-manager" cannot get resource "endpoints" in API group "" in the namespace "kube-system"

 kube-scheduler.service - Kubernetes Scheduler
   Loaded: loaded (/etc/systemd/system/kube-scheduler.service; enabled; vendor preset: enabled)
   Active: active (running) since Fri 2020-01-24 17:16:36 UTC; 11s ago
     Docs: https://github.com/kubernetes/kubernetes
 Main PID: 4043 (kube-scheduler)
    Tasks: 10
   Memory: 8.0M
      CPU: 1.722s
   CGroup: /system.slice/kube-scheduler.service
           4043 /usr/local/bin/kube-scheduler --kubeconfig=/var/lib/kubernetes/kube-scheduler.kubeconfig --address=127.0.0.1 --leader-elect=true --v=2

Jan 24 17:16:47 master1 kube-scheduler[4043]: E0124 17:16:47.342749    4043 reflector.go:134] k8s.io/client-go/informers/factory.go:132: Failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
Jan 24 17:16:47 master1 kube-scheduler[4043]: E0124 17:16:47.346841    4043 reflector.go:134] k8s.io/kubernetes/cmd/kube-scheduler/app/server.go:232: Failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
Jan 24 17:16:47 master1 kube-scheduler[4043]: E0124 17:16:47.350027    4043 reflector.go:134] k8s.io/client-go/informers/factory.go:132: Failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
Jan 24 17:16:47 master1 kube-scheduler[4043]: E0124 17:16:47.351053    4043 reflector.go:134] k8s.io/client-go/informers/factory.go:132: Failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
Jan 24 17:16:47 master1 kube-scheduler[4043]: E0124 17:16:47.352107    4043 reflector.go:134] k8s.io/client-go/informers/factory.go:132: Failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumes" in API group "" at the cluster scope
Jan 24 17:16:47 master1 kube-scheduler[4043]: E0124 17:16:47.353688    4043 reflector.go:134] k8s.io/client-go/informers/factory.go:132: Failed to list *v1beta1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User "system:kube-scheduler" cannot list resource "poddisruptionbudgets" in API group "policy" at the cluster scope
Jan 24 17:16:47 master1 kube-scheduler[4043]: E0124 17:16:47.354952    4043 reflector.go:134] k8s.io/client-go/informers/factory.go:132: Failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
Jan 24 17:16:47 master1 kube-scheduler[4043]: E0124 17:16:47.355924    4043 reflector.go:134] k8s.io/client-go/informers/factory.go:132: Failed to list *v1.Node: nodes is forbidden: User "system:kube-scheduler" cannot list resource "nodes" in API group "" at the cluster scope
Jan 24 17:16:47 master1 kube-scheduler[4043]: E0124 17:16:47.357164    4043 reflector.go:134] k8s.io/client-go/informers/factory.go:132: Failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
Jan 24 17:16:47 master1 kube-scheduler[4043]: E0124 17:16:47.358527    4043 reflector.go:134] k8s.io/client-go/informers/factory.go:132: Failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
 kube-apiserver.service - Kubernetes API Server
   Loaded: loaded (/etc/systemd/system/kube-apiserver.service; enabled; vendor preset: enabled)
   Active: active (running) since Fri 2020-01-24 17:16:37 UTC; 11s ago
     Docs: https://github.com/kubernetes/kubernetes
 Main PID: 30549 (kube-apiserver)
    Tasks: 12
   Memory: 298.1M
      CPU: 8.790s
   CGroup: /system.slice/kube-apiserver.service
           30549 /usr/local/bin/kube-apiserver --advertise-address=172.31.125.181 --allow-privileged=true --apiserver-count=3 --audit-log-maxage=30 --audit-log-maxbackup=3 --audit-log-maxsize=100 --audit-log-path=/var/log/audit.log --authorization-mode=Node,RBAC --bind-address=0.0.0.0 --client-ca-file=/var/lib/kubernetes/ca.crt --enable-admission-plugins=NodeRestriction,ServiceAccount --enable-swagger-ui=true --enable-bootstrap-token-auth=true --etcd-cafile=/var/lib/kubernetes/ca.crt --etcd-certfile=/var/lib/kubernetes/etcd-server.crt --etcd-keyfile=/var/lib/kubernetes/etcd-server.key --etcd-servers=https://172.31.122.25:2379,https://172.31.125.181:2379,https://172.31.115.2:2379 --event-ttl=1h --encryption-provider-config=/var/lib/kubernetes/encryption-config.yaml --kubelet-certificate-authority=/var/lib/kubernetes/ca.crt --kubelet-client-certificate=/var/lib/kubernetes/kube-apiserver.crt --kubelet-client-key=/var/lib/kubernetes/kube-apiserver.key --kubelet-https=true --runtime-config=api/all --service-account-key-file=/var/lib/kubernetes/service-account.crt --service-cluster-ip-range=10.96.0.0/24 --service-node-port-range=30000-32767 --tls-cert-file=/var/lib/kubernetes/kube-apiserver.crt --tls-private-key-file=/var/lib/kubernetes/kube-apiserver.key --v=2

Jan 24 17:16:48 master2 kube-apiserver[30549]: I0124 17:16:48.701703   30549 storage_rbac.go:246] created role.rbac.authorization.k8s.io/system::leader-locking-kube-controller-manager in kube-system
Jan 24 17:16:48 master2 kube-apiserver[30549]: I0124 17:16:48.741083   30549 storage_rbac.go:246] created role.rbac.authorization.k8s.io/system::leader-locking-kube-scheduler in kube-system
Jan 24 17:16:48 master2 kube-apiserver[30549]: I0124 17:16:48.782795   30549 storage_rbac.go:246] created role.rbac.authorization.k8s.io/system:controller:bootstrap-signer in kube-public
Jan 24 17:16:48 master2 kube-apiserver[30549]: I0124 17:16:48.818149   30549 controller.go:608] quota admission added evaluator for: rolebindings.rbac.authorization.k8s.io
Jan 24 17:16:48 master2 kube-apiserver[30549]: I0124 17:16:48.820738   30549 storage_rbac.go:276] created rolebinding.rbac.authorization.k8s.io/system::leader-locking-kube-controller-manager in kube-system
Jan 24 17:16:48 master2 kube-apiserver[30549]: I0124 17:16:48.875560   30549 storage_rbac.go:276] created rolebinding.rbac.authorization.k8s.io/system::leader-locking-kube-scheduler in kube-system
Jan 24 17:16:48 master2 kube-apiserver[30549]: I0124 17:16:48.901661   30549 storage_rbac.go:276] created rolebinding.rbac.authorization.k8s.io/system:controller:bootstrap-signer in kube-system
Jan 24 17:16:48 master2 kube-apiserver[30549]: I0124 17:16:48.941045   30549 storage_rbac.go:276] created rolebinding.rbac.authorization.k8s.io/system:controller:cloud-provider in kube-system
Jan 24 17:16:48 master2 kube-apiserver[30549]: I0124 17:16:48.982103   30549 storage_rbac.go:276] created rolebinding.rbac.authorization.k8s.io/system:controller:token-cleaner in kube-system
Jan 24 17:16:49 master2 kube-apiserver[30549]: I0124 17:16:49.020483   30549 storage_rbac.go:276] created rolebinding.rbac.authorization.k8s.io/system:controller:bootstrap-signer in kube-public

 kube-controller-manager.service - Kubernetes Controller Manager
   Loaded: loaded (/etc/systemd/system/kube-controller-manager.service; enabled; vendor preset: enabled)
   Active: active (running) since Fri 2020-01-24 17:16:38 UTC; 11s ago
     Docs: https://github.com/kubernetes/kubernetes
 Main PID: 30551 (kube-controller)
    Tasks: 8
   Memory: 12.1M
      CPU: 1.265s
   CGroup: /system.slice/kube-controller-manager.service
           30551 /usr/local/bin/kube-controller-manager --address=0.0.0.0 --cluster-cidr=172.31.0.0/20 --cluster-name=kubernetes --cluster-signing-cert-file=/var/lib/kubernetes/ca.crt --cluster-signing-key-file=/var/lib/kubernetes/ca.key --kubeconfig=/var/lib/kubernetes/kube-controller-manager.kubeconfig --leader-elect=true --root-ca-file=/var/lib/kubernetes/ca.crt --service-account-private-key-file=/var/lib/kubernetes/service-account.key --service-cluster-ip-range=10.96.0.0/24 --use-service-account-credentials=true --v=2

Jan 24 17:16:39 master2 kube-controller-manager[30551]: I0124 17:16:39.288053   30551 serving.go:318] Generated self-signed cert in-memory
Jan 24 17:16:39 master2 kube-controller-manager[30551]: W0124 17:16:39.560430   30551 authentication.go:235] No authentication-kubeconfig provided in order to lookup client-ca-file in configmap/extension-apiserver-authentication in kube-system, so client certificate authentication won't work.
Jan 24 17:16:39 master2 kube-controller-manager[30551]: W0124 17:16:39.560452   30551 authentication.go:238] No authentication-kubeconfig provided in order to lookup requestheader-client-ca-file in configmap/extension-apiserver-authentication in kube-system, so request-header client certificate authentication won't work.
Jan 24 17:16:39 master2 kube-controller-manager[30551]: W0124 17:16:39.560467   30551 authorization.go:146] No authorization-kubeconfig provided, so SubjectAccessReview of authorization tokens won't work.
Jan 24 17:16:39 master2 kube-controller-manager[30551]: I0124 17:16:39.560488   30551 controllermanager.go:151] Version: v1.13.0
Jan 24 17:16:39 master2 kube-controller-manager[30551]: I0124 17:16:39.561168   30551 secure_serving.go:116] Serving securely on [::]:10257
Jan 24 17:16:39 master2 kube-controller-manager[30551]: I0124 17:16:39.561784   30551 deprecated_insecure_serving.go:51] Serving insecurely on [::]:10252
Jan 24 17:16:39 master2 kube-controller-manager[30551]: I0124 17:16:39.561925   30551 leaderelection.go:205] attempting to acquire leader lease  kube-system/kube-controller-manager...
Jan 24 17:16:39 master2 kube-controller-manager[30551]: E0124 17:16:39.562362   30551 leaderelection.go:270] error retrieving resource lock kube-system/kube-controller-manager: Get https://127.0.0.1:6443/api/v1/namespaces/kube-system/endpoints/kube-controller-manager?timeout=10s: dial tcp 127.0.0.1:6443: connect: connection refused
Jan 24 17:16:47 master2 kube-controller-manager[30551]: E0124 17:16:47.342538   30551 leaderelection.go:270] error retrieving resource lock kube-system/kube-controller-manager: endpoints "kube-controller-manager" is forbidden: User "system:kube-controller-manager" cannot get resource "endpoints" in API group "" in the namespace "kube-system"

 kube-scheduler.service - Kubernetes Scheduler
   Loaded: loaded (/etc/systemd/system/kube-scheduler.service; enabled; vendor preset: enabled)
   Active: active (running) since Fri 2020-01-24 17:16:38 UTC; 11s ago
     Docs: https://github.com/kubernetes/kubernetes
 Main PID: 30553 (kube-scheduler)
    Tasks: 10
   Memory: 8.6M
      CPU: 1.030s
   CGroup: /system.slice/kube-scheduler.service
           30553 /usr/local/bin/kube-scheduler --kubeconfig=/var/lib/kubernetes/kube-scheduler.kubeconfig --address=127.0.0.1 --leader-elect=true --v=2

Jan 24 17:16:47 master2 kube-scheduler[30553]: E0124 17:16:47.336700   30553 reflector.go:134] k8s.io/kubernetes/cmd/kube-scheduler/app/server.go:232: Failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
Jan 24 17:16:47 master2 kube-scheduler[30553]: E0124 17:16:47.336733   30553 reflector.go:134] k8s.io/client-go/informers/factory.go:132: Failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
Jan 24 17:16:47 master2 kube-scheduler[30553]: E0124 17:16:47.341515   30553 reflector.go:134] k8s.io/client-go/informers/factory.go:132: Failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumes" in API group "" at the cluster scope
Jan 24 17:16:47 master2 kube-scheduler[30553]: E0124 17:16:47.341610   30553 reflector.go:134] k8s.io/client-go/informers/factory.go:132: Failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
Jan 24 17:16:47 master2 kube-scheduler[30553]: E0124 17:16:47.341652   30553 reflector.go:134] k8s.io/client-go/informers/factory.go:132: Failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
Jan 24 17:16:47 master2 kube-scheduler[30553]: E0124 17:16:47.341701   30553 reflector.go:134] k8s.io/client-go/informers/factory.go:132: Failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
Jan 24 17:16:49 master2 kube-scheduler[30553]: I0124 17:16:49.156221   30553 controller_utils.go:1027] Waiting for caches to sync for scheduler controller
Jan 24 17:16:49 master2 kube-scheduler[30553]: I0124 17:16:49.256355   30553 controller_utils.go:1034] Caches are synced for scheduler controller
Jan 24 17:16:49 master2 kube-scheduler[30553]: I0124 17:16:49.256426   30553 leaderelection.go:205] attempting to acquire leader lease  kube-system/kube-scheduler...
Jan 24 17:16:49 master2 kube-scheduler[30553]: I0124 17:16:49.264142   30553 leaderelection.go:214] successfully acquired lease kube-system/kube-scheduler
 kube-apiserver.service - Kubernetes API Server
   Loaded: loaded (/etc/systemd/system/kube-apiserver.service; enabled; vendor preset: enabled)
   Active: active (running) since Fri 2020-01-24 17:16:40 UTC; 12s ago
     Docs: https://github.com/kubernetes/kubernetes
 Main PID: 30231 (kube-apiserver)
    Tasks: 10
   Memory: 302.7M
      CPU: 9.459s
   CGroup: /system.slice/kube-apiserver.service
           30231 /usr/local/bin/kube-apiserver --advertise-address=172.31.115.2 --allow-privileged=true --apiserver-count=3 --audit-log-maxage=30 --audit-log-maxbackup=3 --audit-log-maxsize=100 --audit-log-path=/var/log/audit.log --authorization-mode=Node,RBAC --bind-address=0.0.0.0 --client-ca-file=/var/lib/kubernetes/ca.crt --enable-admission-plugins=NodeRestriction,ServiceAccount --enable-swagger-ui=true --enable-bootstrap-token-auth=true --etcd-cafile=/var/lib/kubernetes/ca.crt --etcd-certfile=/var/lib/kubernetes/etcd-server.crt --etcd-keyfile=/var/lib/kubernetes/etcd-server.key --etcd-servers=https://172.31.122.25:2379,https://172.31.125.181:2379,https://172.31.115.2:2379 --event-ttl=1h --encryption-provider-config=/var/lib/kubernetes/encryption-config.yaml --kubelet-certificate-authority=/var/lib/kubernetes/ca.crt --kubelet-client-certificate=/var/lib/kubernetes/kube-apiserver.crt --kubelet-client-key=/var/lib/kubernetes/kube-apiserver.key --kubelet-https=true --runtime-config=api/all --service-account-key-file=/var/lib/kubernetes/service-account.crt --service-cluster-ip-range=10.96.0.0/24 --service-node-port-range=30000-32767 --tls-cert-file=/var/lib/kubernetes/kube-apiserver.crt --tls-private-key-file=/var/lib/kubernetes/kube-apiserver.key --v=2

Jan 24 17:16:50 master3 kube-apiserver[30231]: I0124 17:16:50.832480   30231 cacher.go:598] cacher (*core.Secret): 1 objects queued in incoming channel.
Jan 24 17:16:50 master3 kube-apiserver[30231]: I0124 17:16:50.832505   30231 cacher.go:598] cacher (*core.Secret): 2 objects queued in incoming channel.
Jan 24 17:16:50 master3 kube-apiserver[30231]: I0124 17:16:50.840017   30231 cacher.go:598] cacher (*core.ServiceAccount): 1 objects queued in incoming channel.
Jan 24 17:16:50 master3 kube-apiserver[30231]: I0124 17:16:50.865129   30231 cache.go:39] Caches are synced for APIServiceRegistrationController controller
Jan 24 17:16:50 master3 kube-apiserver[30231]: I0124 17:16:50.872882   30231 cache.go:39] Caches are synced for AvailableConditionController controller
Jan 24 17:16:50 master3 kube-apiserver[30231]: I0124 17:16:50.873264   30231 controller_utils.go:1034] Caches are synced for crd-autoregister controller
Jan 24 17:16:50 master3 kube-apiserver[30231]: W0124 17:16:50.874325   30231 lease.go:222] Resetting endpoints for master service "kubernetes" to [172.31.115.2 172.31.122.25 172.31.125.181]
Jan 24 17:16:50 master3 kube-apiserver[30231]: I0124 17:16:50.878506   30231 controller.go:608] quota admission added evaluator for: endpoints
Jan 24 17:16:50 master3 kube-apiserver[30231]: I0124 17:16:50.910372   30231 cache.go:39] Caches are synced for autoregister controller
Jan 24 17:16:51 master3 kube-apiserver[30231]: I0124 17:16:51.578300   30231 storage_scheduling.go:100] all system priority classes are created successfully or already exist.

 kube-controller-manager.service - Kubernetes Controller Manager
   Loaded: loaded (/etc/systemd/system/kube-controller-manager.service; enabled; vendor preset: enabled)
   Active: active (running) since Fri 2020-01-24 17:16:40 UTC; 12s ago
     Docs: https://github.com/kubernetes/kubernetes
 Main PID: 30233 (kube-controller)
    Tasks: 9
   Memory: 12.5M
      CPU: 1.749s
   CGroup: /system.slice/kube-controller-manager.service
           30233 /usr/local/bin/kube-controller-manager --address=0.0.0.0 --cluster-cidr=172.31.0.0/20 --cluster-name=kubernetes --cluster-signing-cert-file=/var/lib/kubernetes/ca.crt --cluster-signing-key-file=/var/lib/kubernetes/ca.key --kubeconfig=/var/lib/kubernetes/kube-controller-manager.kubeconfig --leader-elect=true --root-ca-file=/var/lib/kubernetes/ca.crt --service-account-private-key-file=/var/lib/kubernetes/service-account.key --service-cluster-ip-range=10.96.0.0/24 --use-service-account-credentials=true --v=2

Jan 24 17:16:40 master3 kube-controller-manager[30233]: I0124 17:16:40.753254   30233 flags.go:33] FLAG: --vmodule=""
Jan 24 17:16:41 master3 kube-controller-manager[30233]: I0124 17:16:41.970221   30233 serving.go:318] Generated self-signed cert in-memory
Jan 24 17:16:42 master3 kube-controller-manager[30233]: W0124 17:16:42.948855   30233 authentication.go:235] No authentication-kubeconfig provided in order to lookup client-ca-file in configmap/extension-apiserver-authentication in kube-system, so client certificate authentication won't work.
Jan 24 17:16:42 master3 kube-controller-manager[30233]: W0124 17:16:42.949274   30233 authentication.go:238] No authentication-kubeconfig provided in order to lookup requestheader-client-ca-file in configmap/extension-apiserver-authentication in kube-system, so request-header client certificate authentication won't work.
Jan 24 17:16:42 master3 kube-controller-manager[30233]: W0124 17:16:42.949538   30233 authorization.go:146] No authorization-kubeconfig provided, so SubjectAccessReview of authorization tokens won't work.
Jan 24 17:16:42 master3 kube-controller-manager[30233]: I0124 17:16:42.949794   30233 controllermanager.go:151] Version: v1.13.0
Jan 24 17:16:42 master3 kube-controller-manager[30233]: I0124 17:16:42.967845   30233 secure_serving.go:116] Serving securely on [::]:10257
Jan 24 17:16:42 master3 kube-controller-manager[30233]: I0124 17:16:42.968965   30233 deprecated_insecure_serving.go:51] Serving insecurely on [::]:10252
Jan 24 17:16:42 master3 kube-controller-manager[30233]: I0124 17:16:42.969537   30233 leaderelection.go:205] attempting to acquire leader lease  kube-system/kube-controller-manager...
Jan 24 17:16:50 master3 kube-controller-manager[30233]: E0124 17:16:50.677114   30233 leaderelection.go:270] error retrieving resource lock kube-system/kube-controller-manager: endpoints "kube-controller-manager" is forbidden: User "system:kube-controller-manager" cannot get resource "endpoints" in API group "" in the namespace "kube-system"

 kube-scheduler.service - Kubernetes Scheduler
   Loaded: loaded (/etc/systemd/system/kube-scheduler.service; enabled; vendor preset: enabled)
   Active: active (running) since Fri 2020-01-24 17:16:40 UTC; 12s ago
     Docs: https://github.com/kubernetes/kubernetes
 Main PID: 30235 (kube-scheduler)
    Tasks: 9
   Memory: 8.7M
      CPU: 1.892s
   CGroup: /system.slice/kube-scheduler.service
           30235 /usr/local/bin/kube-scheduler --kubeconfig=/var/lib/kubernetes/kube-scheduler.kubeconfig --address=127.0.0.1 --leader-elect=true --v=2

Jan 24 17:16:50 master3 kube-scheduler[30235]: E0124 17:16:50.657208   30235 reflector.go:134] k8s.io/client-go/informers/factory.go:132: Failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
Jan 24 17:16:50 master3 kube-scheduler[30235]: E0124 17:16:50.657255   30235 reflector.go:134] k8s.io/kubernetes/cmd/kube-scheduler/app/server.go:232: Failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
Jan 24 17:16:50 master3 kube-scheduler[30235]: E0124 17:16:50.657303   30235 reflector.go:134] k8s.io/client-go/informers/factory.go:132: Failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
Jan 24 17:16:50 master3 kube-scheduler[30235]: E0124 17:16:50.657340   30235 reflector.go:134] k8s.io/client-go/informers/factory.go:132: Failed to list *v1beta1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User "system:kube-scheduler" cannot list resource "poddisruptionbudgets" in API group "policy" at the cluster scope
Jan 24 17:16:50 master3 kube-scheduler[30235]: E0124 17:16:50.678919   30235 reflector.go:134] k8s.io/client-go/informers/factory.go:132: Failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumes" in API group "" at the cluster scope
Jan 24 17:16:50 master3 kube-scheduler[30235]: E0124 17:16:50.678981   30235 reflector.go:134] k8s.io/client-go/informers/factory.go:132: Failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
Jan 24 17:16:50 master3 kube-scheduler[30235]: E0124 17:16:50.679038   30235 reflector.go:134] k8s.io/client-go/informers/factory.go:132: Failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
Jan 24 17:16:52 master3 kube-scheduler[30235]: I0124 17:16:52.505063   30235 controller_utils.go:1027] Waiting for caches to sync for scheduler controller
Jan 24 17:16:52 master3 kube-scheduler[30235]: I0124 17:16:52.605182   30235 controller_utils.go:1034] Caches are synced for scheduler controller
Jan 24 17:16:52 master3 kube-scheduler[30235]: I0124 17:16:52.605260   30235 leaderelection.go:205] attempting to acquire leader lease  kube-system/kube-scheduler...
root@master1:~/keys# 
root@master1:~/keys# 
root@master1:~/keys# 
root@master1:~/keys# 
root@master1:~/keys# 
root@master1:~/keys# 
root@master1:~/keys# 
root@master1:~/keys# 
root@master1:~/keys# kubectl get componentstatuses --kubeconfig admin.kubeconfig
NAME                 STATUS    MESSAGE             ERROR
controller-manager   Healthy   ok                  
scheduler            Healthy   ok                  
etcd-1               Healthy   {"health":"true"}   
etcd-0               Healthy   {"health":"true"}   
etcd-2               Healthy   {"health":"true"}   
root@master1:~/keys# 
root@master1:~/keys# 
root@master1:~/keys# cd
root@master1:~# 
root@master1:~# ssh loadbalancer
Welcome to Ubuntu 16.04.6 LTS (GNU/Linux 4.4.0-1099-aws x86_64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/advantage

 * Overheard at KubeCon: "microk8s.status just blew my mind".

     https://microk8s.io/docs/commands#microk8s.status

  Get cloud support with Ubuntu Advantage Cloud Guest:
    http://www.ubuntu.com/business/services/cloud

15 packages can be updated.
0 updates are security updates.

New release '18.04.3 LTS' available.
Run 'do-release-upgrade' to upgrade to it.


*** System restart required ***
Last login: Fri Jan 24 12:49:15 2020 from 172.31.122.25
root@loadbalancer:~# 
root@loadbalancer:~# apt-get update && sudo apt-get install -y haproxy
0% [Working]            Hit:1 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial InRelease
0% [Connecting to security.ubuntu.com (2001:67c:1560:8001::11)]                                                               Get:2 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial-updates InRelease [109 kB]
                                                               Get:3 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial-backports InRelease [107 kB]
0% [Connecting to security.ubuntu.com (2001:67c:1560:8001::11)]0% [1 InRelease gpgv 247 kB] [Connecting to security.ubuntu.com (2001:67c:1560:8001::11)]                                                                                         0% [Connecting to security.ubuntu.com (2001:67c:1560:8001::11)]                                                               0% [2 InRelease gpgv 109 kB] [Waiting for headers]                                                  0% [Waiting for headers]0% [3 InRelease gpgv 107 kB] [Waiting for headers] [Waiting for headers]                                                                        Get:4 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial-updates/main amd64 DEP-11 Metadata [322 kB]
0% [3 InRelease gpgv 107 kB] [4 Components-amd64 23.0 kB/322 kB 7%] [Waiting for headers]                                                                                         0% [3 InRelease gpgv 107 kB] [Waiting for headers]                                                  Get:5 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial-updates/main DEP-11 64x64 Icons [241 kB]
0% [4 Components-amd64 store 0 B] [3 InRelease gpgv 107 kB] [5 icons-64x64 25.9 kB/241 kB 11%] [Waiting for headers]                                                                                                                    0% [4 Components-amd64 store 0 B] [3 InRelease gpgv 107 kB] [Waiting for headers]                                                                                 Get:6 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial-updates/universe amd64 DEP-11 Metadata [274 kB]
0% [4 Components-amd64 store 0 B] [3 InRelease gpgv 107 kB] [6 Components-amd64 5,387 B/274 kB 2%] [Waiting for headers]                                                                                                                        0% [4 Components-amd64 store 0 B] [3 InRelease gpgv 107 kB] [Waiting for headers]                                                                                 Get:7 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial-updates/universe DEP-11 64x64 Icons [411 kB]
0% [4 Components-amd64 store 0 B] [3 InRelease gpgv 107 kB] [7 icons-64x64 59.0 kB/411 kB 14%] [Waiting for headers]                                                                                                                    0% [4 Components-amd64 store 0 B] [3 InRelease gpgv 107 kB] [Waiting for headers]                                                                                 Get:8 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial-updates/multiverse amd64 DEP-11 Metadata [5,968 B]
0% [4 Components-amd64 store 0 B] [3 InRelease gpgv 107 kB] [Waiting for headers]                                                                                 Get:9 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial-updates/multiverse DEP-11 64x64 Icons [14.3 kB]
0% [4 Components-amd64 store 0 B] [3 InRelease gpgv 107 kB] [9 icons-64x64 14.3 kB/14.3 kB 100%] [Waiting for headers]                                                                                                                      0% [4 Components-amd64 store 0 B] [3 InRelease gpgv 107 kB] [Waiting for headers]                                                                                 Get:10 http://security.ubuntu.com/ubuntu xenial-security InRelease [109 kB]
0% [4 Components-amd64 store 0 B] [3 InRelease gpgv 107 kB] [10 InRelease 2,545 B/109 kB 2%]                                                                                            0% [4 Components-amd64 store 0 B] [10 InRelease 5,401 B/109 kB 5%]                                                                  Get:11 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial-backports/main amd64 DEP-11 Metadata [3,324 B]
0% [4 Components-amd64 store 0 B] [10 InRelease 5,401 B/109 kB 5%]                                                                  Get:12 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial-backports/universe amd64 DEP-11 Metadata [5,324 B]
0% [4 Components-amd64 store 0 B] [10 InRelease 5,401 B/109 kB 5%]                                                                  0% [10 InRelease 14.0 kB/109 kB 13%]0% [5 icons-64x64 store 0 B] [10 InRelease 14.0 kB/109 kB 13%]                                                              0% [10 InRelease 14.0 kB/109 kB 13%]0% [6 Components-amd64 store 0 B] [10 InRelease 14.0 kB/109 kB 13%]                                                                   0% [10 InRelease 14.0 kB/109 kB 13%]0% [7 icons-64x64 store 0 B] [10 InRelease 14.0 kB/109 kB 13%]                                                              0% [10 InRelease 14.0 kB/109 kB 13%]0% [8 Components-amd64 store 0 B] [10 InRelease 14.0 kB/109 kB 13%]                                                                   0% [10 InRelease 14.0 kB/109 kB 13%]0% [9 icons-64x64 store 0 B] [10 InRelease 14.0 kB/109 kB 13%]                                                              0% [10 InRelease 14.0 kB/109 kB 13%]0% [11 Components-amd64 store 0 B] [10 InRelease 14.0 kB/109 kB 13%]                                                                    0% [10 InRelease 14.0 kB/109 kB 13%]0% [12 Components-amd64 store 0 B] [10 InRelease 14.0 kB/109 kB 13%]                                                                    0% [10 InRelease 14.0 kB/109 kB 13%]                                    0% [Working]0% [10 InRelease gpgv 109 kB]                             81% [Working]             Get:13 http://security.ubuntu.com/ubuntu xenial-security/main amd64 DEP-11 Metadata [74.8 kB]
81% [13 Components-amd64 2,648 B/74.8 kB 4%]                                            83% [Working]83% [13 Components-amd64 store 0 B] [Waiting for headers]                                                         84% [Waiting for headers]                         Get:14 http://security.ubuntu.com/ubuntu xenial-security/main DEP-11 64x64 Icons [83.8 kB]
84% [14 icons-64x64 2,648 B/83.8 kB 3%]                                       87% [Waiting for headers]                         Get:15 http://security.ubuntu.com/ubuntu xenial-security/universe amd64 DEP-11 Metadata [124 kB]
87% [15 Components-amd64 32 B/124 kB 0%]87% [14 icons-64x64 store 0 B] [15 Components-amd64 32 B/124 kB 0%]                                                                   87% [15 Components-amd64 32 B/124 kB 0%]                                        92% [Waiting for headers]                         Get:16 http://security.ubuntu.com/ubuntu xenial-security/universe DEP-11 64x64 Icons [194 kB]
92% [16 icons-64x64 67 B/194 kB 0%]92% [15 Components-amd64 store 0 B] [16 icons-64x64 67 B/194 kB 0%]                                                                   93% [16 icons-64x64 32.9 kB/194 kB 17%]                                       100% [Waiting for headers]                          Get:17 http://security.ubuntu.com/ubuntu xenial-security/multiverse amd64 DEP-11 Metadata [2,464 B]
100% [17 Components-amd64 1,919 B/2,464 B 78%]100% [16 icons-64x64 store 0 B] [17 Components-amd64 1,919 B/2,464 B 78%]                                                                         100% [16 icons-64x64 store 0 B]                               100% [Working]100% [17 Components-amd64 store 0 B]                                    100% [Working]              Fetched 2,081 kB in 1s (1,279 kB/s)
Reading package lists... 0%Reading package lists... 0%Reading package lists... 1%Reading package lists... 6%Reading package lists... 6%Reading package lists... 9%Reading package lists... 9%Reading package lists... 9%Reading package lists... 9%Reading package lists... 9%Reading package lists... 9%Reading package lists... 14%Reading package lists... 28%Reading package lists... 44%Reading package lists... 44%Reading package lists... 56%Reading package lists... 64%Reading package lists... 64%Reading package lists... 64%Reading package lists... 64%Reading package lists... 65%Reading package lists... 65%Reading package lists... 71%Reading package lists... 71%Reading package lists... 77%Reading package lists... 77%Reading package lists... 77%Reading package lists... 77%Reading package lists... 77%Reading package lists... 77%Reading package lists... 81%Reading package lists... 81%Reading package lists... 83%Reading package lists... 83%Reading package lists... 84%Reading package lists... 84%Reading package lists... 84%Reading package lists... 84%Reading package lists... 84%Reading package lists... 84%Reading package lists... 84%Reading package lists... 84%Reading package lists... 84%Reading package lists... 84%Reading package lists... 84%Reading package lists... 84%Reading package lists... 88%Reading package lists... 88%Reading package lists... 93%Reading package lists... 93%Reading package lists... 93%Reading package lists... 93%Reading package lists... 93%Reading package lists... 93%Reading package lists... 96%Reading package lists... 96%Reading package lists... 98%Reading package lists... 98%Reading package lists... 98%Reading package lists... 98%Reading package lists... 98%Reading package lists... 98%Reading package lists... Done
Reading package lists... 0%Reading package lists... 100%Reading package lists... Done
Building dependency tree... 0%Building dependency tree... 0%Building dependency tree... 50%Building dependency tree... 50%Building dependency tree       
Reading state information... 0%Reading state information... 0%Reading state information... Done
The following packages were automatically installed and are no longer required:
  linux-aws-headers-4.4.0-1095 linux-headers-4.4.0-1095-aws linux-headers-4.4.0-170 linux-headers-4.4.0-170-generic
  linux-image-4.4.0-1095-aws linux-image-4.4.0-170-generic linux-modules-4.4.0-1095-aws linux-modules-4.4.0-170-generic
Use 'sudo apt autoremove' to remove them.
The following additional packages will be installed:
  liblua5.3-0
Suggested packages:
  vim-haproxy haproxy-doc
The following NEW packages will be installed:
  haproxy liblua5.3-0
0 upgraded, 2 newly installed, 0 to remove and 15 not upgraded.
Need to get 873 kB of archives.
After this operation, 1,997 kB of additional disk space will be used.
0% [Working]            Get:1 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial-updates/main amd64 liblua5.3-0 amd64 5.3.1-1ubuntu2.1 [116 kB]
1% [1 liblua5.3-0 14.1 kB/116 kB 12%]                                     21% [Working]             Get:2 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial-updates/main amd64 haproxy amd64 1.6.3-1ubuntu0.3 [757 kB]
22% [2 haproxy 14.2 kB/757 kB 2%]                                 100% [Working]              Fetched 873 kB in 0s (36.1 MB/s)
Selecting previously unselected package liblua5.3-0:amd64.
(Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 303104 files and directories currently installed.)
Preparing to unpack .../liblua5.3-0_5.3.1-1ubuntu2.1_amd64.deb ...
Unpacking liblua5.3-0:amd64 (5.3.1-1ubuntu2.1) ...
Selecting previously unselected package haproxy.
Preparing to unpack .../haproxy_1.6.3-1ubuntu0.3_amd64.deb ...
Unpacking haproxy (1.6.3-1ubuntu0.3) ...
Processing triggers for libc-bin (2.23-0ubuntu11) ...
Processing triggers for systemd (229-4ubuntu21.22) ...
Processing triggers for ureadahead (0.100.0-19.1) ...
Processing triggers for man-db (2.7.5-1) ...
Setting up liblua5.3-0:amd64 (5.3.1-1ubuntu2.1) ...
Setting up haproxy (1.6.3-1ubuntu0.3) ...
Processing triggers for libc-bin (2.23-0ubuntu11) ...
Processing triggers for systemd (229-4ubuntu21.22) ...
Processing triggers for ureadahead (0.100.0-19.1) ...
root@loadbalancer:~# 
root@loadbalancer:~# 
root@loadbalancer:~# 
root@loadbalancer:~# cat /etc/hosts
127.0.0.1 localhost

# The following lines are desirable for IPv6 capable hosts
::1 ip6-localhost ip6-loopback
fe00::0 ip6-localnet
ff00::0 ip6-mcastprefix
ff02::1 ip6-allnodes
ff02::2 ip6-allrouters
ff02::3 ip6-allhosts
# Cloud Server Hostname mapping
172.31.123.142   rameshhms5c.mylabserver.com
172.31.123.142 loadbalancer
root@loadbalancer:~# logout
Connection to loadbalancer closed.
root@master1:~# cat /etc/osts
cat: /etc/osts: No such file or directory
root@master1:~# cat /etc/ostshosts
127.0.0.1 localhost

# The following lines are desirable for IPv6 capable hosts
::1 ip6-localhost ip6-loopback
fe00::0 ip6-localnet
ff00::0 ip6-mcastprefix
ff02::1 ip6-allnodes
ff02::2 ip6-allrouters
ff02::3 ip6-allhosts
# Cloud Server Hostname mapping
172.31.122.25   rameshhms1c.mylabserver.com
172.31.122.25master1
172.31.125.181master2
172.31.115.2master3
172.31.122.147worker1
172.31.123.142loadbalancer
root@master1:~# cat /etc/hostsostsssh loadbalancer
Welcome to Ubuntu 16.04.6 LTS (GNU/Linux 4.4.0-1099-aws x86_64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/advantage

 * Overheard at KubeCon: "microk8s.status just blew my mind".

     https://microk8s.io/docs/commands#microk8s.status

  Get cloud support with Ubuntu Advantage Cloud Guest:
    http://www.ubuntu.com/business/services/cloud

15 packages can be updated.
0 updates are security updates.

New release '18.04.3 LTS' available.
Run 'do-release-upgrade' to upgrade to it.


*** System restart required ***
Last login: Fri Jan 24 17:17:27 2020 from 172.31.122.25
root@loadbalancer:~# cat <<EOF | sudo tee /etc/haproxy/haproxy.cfg 
> frontend kubernetes
>     bind 172.31.123.142:6443
>     option tcplog
>     mode tcp
>     default_backend kubernetes-master-nodes
> 
> backend kubernetes-master-nodes
>     mode tcp
>     balance roundrobin
>     option tcp-check
>     server master1 172.31.122.25:6443 check fall 3 rise 2
>     server master2 172.31.125.181:6443 check fall 3 rise 2
>     server master3 172.31.115.2:6443 check fall 3 rise 2
> EOF
frontend kubernetes
    bind 172.31.123.142:6443
    option tcplog
    mode tcp
    default_backend kubernetes-master-nodes

backend kubernetes-master-nodes
    mode tcp
    balance roundrobin
    option tcp-check
    server master1 172.31.122.25:6443 check fall 3 rise 2
    server master2 172.31.125.181:6443 check fall 3 rise 2
    server master3 172.31.115.2:6443 check fall 3 rise 2
root@loadbalancer:~# cat /etc/haproxy/haproxy.cfg
frontend kubernetes
    bind 172.31.123.142:6443
    option tcplog
    mode tcp
    default_backend kubernetes-master-nodes

backend kubernetes-master-nodes
    mode tcp
    balance roundrobin
    option tcp-check
    server master1 172.31.122.25:6443 check fall 3 rise 2
    server master2 172.31.125.181:6443 check fall 3 rise 2
    server master3 172.31.115.2:6443 check fall 3 rise 2
root@loadbalancer:~# 
root@loadbalancer:~# 
root@loadbalancer:~# 
root@loadbalancer:~# 
root@loadbalancer:~# 
root@loadbalancer:~# 
root@loadbalancer:~# 
root@loadbalancer:~# 
root@loadbalancer:~# 
root@loadbalancer:~# service haproxy restart
root@loadbalancer:~# curl  https://172.31.123.142:6443/version -k
{
  "major": "1",
  "minor": "13",
  "gitVersion": "v1.13.0",
  "gitCommit": "ddf47ac13c1a9483ea035a79cd7c10005ff21a6d",
  "gitTreeState": "clean",
  "buildDate": "2018-12-03T20:56:12Z",
  "goVersion": "go1.11.2",
  "compiler": "gc",
  "platform": "linux/amd64"
}root@loadbalancer:~# 
root@loadbalancer:~# 
root@loadbalancer:~# logout
Connection to loadbalancer closed.
root@master1:~# ssh worker1
Welcome to Ubuntu 16.04.6 LTS (GNU/Linux 4.4.0-1099-aws x86_64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/advantage

 * Overheard at KubeCon: "microk8s.status just blew my mind".

     https://microk8s.io/docs/commands#microk8s.status

  Get cloud support with Ubuntu Advantage Cloud Guest:
    http://www.ubuntu.com/business/services/cloud

15 packages can be updated.
0 updates are security updates.

New release '18.04.3 LTS' available.
Run 'do-release-upgrade' to upgrade to it.


*** System restart required ***
Last login: Fri Jan 24 13:04:29 2020 from 172.31.122.25
root@worker1:~# cd package/
root@worker1:~/package# wget -q --show-progress --https-only --timestamping \
>   https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kubectl \
>   https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kube-proxy \
>   https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kubelet
kubectl                           0%[                                                     ]       0  --.-KB/s               kubectl                          75%[======================================>              ]  28.16M   141MB/s               kubectl                         100%[====================================================>]  37.40M   153MB/s    in 0.2s    
kube-proxy                        0%[                                                     ]       0  --.-KB/s               kube-proxy                       24%[===========>                                         ]   8.01M  36.5MB/s               kube-proxy                       90%[===============================================>     ]  30.10M  71.7MB/s               kube-proxy                      100%[====================================================>]  33.19M  76.5MB/s    in 0.4s    
kubelet                           0%[                                                     ]       0  --.-KB/s               kubelet                          23%[===========>                                         ]  25.44M   127MB/s               kubelet                          59%[==============================>                      ]  64.28M   161MB/s               kubelet                          98%[==================================================>  ] 105.68M   176MB/s               kubelet                         100%[====================================================>] 107.72M   177MB/s    in 0.6s    
root@worker1:~/package# mkdir -p  /etc/cni/net.d   /opt/cni/bin   /var/lib/kubelet   /var/lib/kube-proxy   /var/lib/kubernete s   /var/run/kubernetes
root@worker1:~/package# chmod +x kubectl kube-proxy kubelet
root@worker1:~/package# mv kubectl kube-proxy kubelet /usr/local/bin/
root@worker1:~/package# cd ../keys/
root@worker1:~/keys# ls -l
total 28
-rw-r--r-- 1 root root  989 Jan 24 13:14 ca.crt
-rw------- 1 root root 5248 Jan 24 13:15 kube-proxy.kubeconfig
-rw-r--r-- 1 root root 1147 Jan 24 13:14 worker1.crt
-rw-r--r-- 1 root root 1679 Jan 24 13:14 worker1.key
-rw------- 1 root root 5460 Jan 24 13:14 worker1.kubeconfig
root@worker1:~/keys# hostname
worker1
root@worker1:~/keys# echo $HOSTNAME
worker1
root@worker1:~/keys# cp ${HOSTNAME}.key ${HOSTNAME}.crt /var/lib/kubelet/
root@worker1:~/keys# cp ${HOSTNAME}.kubeconfig /var/lib/kubelet/kubeconfig
root@worker1:~/keys# cp ca.crt /var/lib/kubernetes/
root@worker1:~/keys# ls -l /run/systemd/resolve/resolv.conf
ls: cannot access '/run/systemd/resolve/resolv.conf': No such file or directory
root@worker1:~/keys# systemctl status res
rescue.service      rescue.target       resolvconf.service  
root@worker1:~/keys# systemctl status res
rescue.service      rescue.target       resolvconf.service  
root@worker1:~/keys# systemctl status resolvconf.service 
 resolvconf.service - Nameserver information manager
   Loaded: loaded (/lib/systemd/system/resolvconf.service; enabled; vendor preset: enabled)
   Active: active (exited) since Fri 2020-01-24 12:05:12 UTC; 5h 17min ago
     Docs: man:resolvconf(8)
 Main PID: 501 (code=exited, status=0/SUCCESS)
    Tasks: 0
   Memory: 0B
      CPU: 0
   CGroup: /system.slice/resolvconf.service

Jan 24 12:05:12 haydenstanko2c.mylabserver.com systemd[1]: Starting Nameserver information manager...
Jan 24 12:05:12 haydenstanko2c.mylabserver.com systemd[1]: Started Nameserver information manager.
root@worker1:~/keys# 
root@worker1:~/keys# cat <<EOF | sudo tee /var/lib/kubelet/kubelet-config.yaml
> kind: KubeletConfiguration
> apiVersion: kubelet.config.k8s.io/v1beta1
> authentication:
>   anonymous:
>     enabled: false
>   webhook:
>     enabled: true
>   x509:
>     clientCAFile: "/var/lib/kubernetes/ca.crt"
> authorization:
>   mode: Webhook
> clusterDomain: "cluster.local"
> clusterDNS:
>   - "10.96.0.10"
> resolvConf: "/run/systemd/resolve/resolv.conf"
> runtimeRequestTimeout: "15m"
> EOF
kind: KubeletConfiguration
apiVersion: kubelet.config.k8s.io/v1beta1
authentication:
  anonymous:
    enabled: false
  webhook:
    enabled: true
  x509:
    clientCAFile: "/var/lib/kubernetes/ca.crt"
authorization:
  mode: Webhook
clusterDomain: "cluster.local"
clusterDNS:
  - "10.96.0.10"
resolvConf: "/run/systemd/resolve/resolv.conf"
runtimeRequestTimeout: "15m"
root@worker1:~/keys# 
root@worker1:~/keys# 
root@worker1:~/keys# cat <<EOF | sudo tee /etc/systemd/system/kubelet.service
> [Unit]
> Description=Kubernetes Kubelet
> Documentation=https://github.com/kubernetes/kubernetes
> After=docker.service
> Requires=docker.service
> 
> [Service]
> ExecStart=/usr/local/bin/kubelet \\
>   --config=/var/lib/kubelet/kubelet-config.yaml \\
>   --image-pull-progress-deadline=2m \\
>   --kubeconfig=/var/lib/kubelet/kubeconfig \\
>   --tls-cert-file=/var/lib/kubelet/${HOSTNAME}.crt \\
>   --tls-private-key-file=/var/lib/kubelet/${HOSTNAME}.key \\
>   --network-plugin=cni \\
>   --register-node=true \\
>   --v=2
> Restart=on-failure
> RestartSec=5
> 
> [Install]
> WantedBy=multi-user.target
> EOF
[Unit]
Description=Kubernetes Kubelet
Documentation=https://github.com/kubernetes/kubernetes
After=docker.service
Requires=docker.service

[Service]
ExecStart=/usr/local/bin/kubelet \
  --config=/var/lib/kubelet/kubelet-config.yaml \
  --image-pull-progress-deadline=2m \
  --kubeconfig=/var/lib/kubelet/kubeconfig \
  --tls-cert-file=/var/lib/kubelet/worker1.crt \
  --tls-private-key-file=/var/lib/kubelet/worker1.key \
  --network-plugin=cni \
  --register-node=true \
  --v=2
Restart=on-failure
RestartSec=5

[Install]
WantedBy=multi-user.target
root@worker1:~/keys# cp kube-proxy.kubeconfig /var/lib/kube-proxy/kubeconfig
root@worker1:~/keys# ls -l /var/lib/kube-proxy/kubeconfig
-rw------- 1 root root 5248 Jan 24 17:23 /var/lib/kube-proxy/kubeconfig
root@worker1:~/keys# 
root@worker1:~/keys# 
root@worker1:~/keys# cat <<EOF | sudo tee /var/lib/kube-proxy/kube-proxy-config.yaml
> kind: KubeProxyConfiguration
> apiVersion: kubeproxy.config.k8s.io/v1alpha1
> clientConnection:
>   kubeconfig: "/var/lib/kube-proxy/kubeconfig"
> mode: "iptables"
> clusterCIDR: "172.31.0.0/20"
> EOF
kind: KubeProxyConfiguration
apiVersion: kubeproxy.config.k8s.io/v1alpha1
clientConnection:
  kubeconfig: "/var/lib/kube-proxy/kubeconfig"
mode: "iptables"
clusterCIDR: "172.31.0.0/20"
root@worker1:~/keys# 
root@worker1:~/keys# 
root@worker1:~/keys# 
root@worker1:~/keys# cat <<EOF | sudo tee /etc/systemd/system/kube-proxy.service
> [Unit]
> Description=Kubernetes Kube Proxy
> Documentation=https://github.com/kubernetes/kubernetes
> 
> [Service]
> ExecStart=/usr/local/bin/kube-proxy \\
>   --config=/var/lib/kube-proxy/kube-proxy-config.yaml
> Restart=on-failure
> RestartSec=5
> 
> [Install]
> WantedBy=multi-user.target
> EOF
[Unit]
Description=Kubernetes Kube Proxy
Documentation=https://github.com/kubernetes/kubernetes

[Service]
ExecStart=/usr/local/bin/kube-proxy \
  --config=/var/lib/kube-proxy/kube-proxy-config.yaml
Restart=on-failure
RestartSec=5

[Install]
WantedBy=multi-user.target
root@worker1:~/keys# ls -l /var/lib/kube-proxy/kube-proxy-config.yaml
-rw-r--r-- 1 root root 185 Jan 24 17:23 /var/lib/kube-proxy/kube-proxy-config.yaml
root@worker1:~/keys# ls -l /usr/local/bin/kube-proxy
-rwxr-xr-x 1 root root 34804064 Dec  3  2018 /usr/local/bin/kube-proxy
root@worker1:~/keys# apt-get update
0% [Working]            Hit:1 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial InRelease
0% [Connecting to security.ubuntu.com (2001:67c:1560:8001::14)]                                                               Get:2 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial-updates InRelease [109 kB]
                                                               Get:3 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial-backports InRelease [107 kB]
0% [Connecting to security.ubuntu.com (2001:67c:1560:8001::14)]0% [1 InRelease gpgv 247 kB] [Connecting to security.ubuntu.com (2001:67c:1560:8001::14)]                                                                                         0% [Waiting for headers]0% [2 InRelease gpgv 109 kB] [Waiting for headers]                                                  0% [Waiting for headers]0% [3 InRelease gpgv 107 kB] [Waiting for headers] [Waiting for headers]                                                                        Get:4 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial-updates/main amd64 DEP-11 Metadata [322 kB]
0% [3 InRelease gpgv 107 kB] [4 Components-amd64 18.6 kB/322 kB 6%] [Waiting for headers]                                                                                         0% [3 InRelease gpgv 107 kB] [Waiting for headers]                                                  Get:5 http://security.ubuntu.com/ubuntu xenial-security InRelease [109 kB]
0% [3 InRelease gpgv 107 kB] [5 InRelease 2,545 B/109 kB 2%]                                                            Get:6 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial-updates/main DEP-11 64x64 Icons [241 kB]
                                                            Get:7 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial-updates/universe amd64 DEP-11 Metadata [274 kB]
0% [3 InRelease gpgv 107 kB] [7 Components-amd64 65.5 kB/274 kB 24%] [5 InRelease 5,401 B/109 kB 5%]0% [4 Components-amd64 store 0 B] [3 InRelease gpgv 107 kB] [7 Components-amd64 65.5 kB/274 kB 24%] [5 InRelease 5,401 B/109                                                                                                                            0% [4 Components-amd64 store 0 B] [3 InRelease gpgv 107 kB] [5 InRelease 8,257 B/109 kB 8%]                                                                                           Get:8 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial-updates/universe DEP-11 64x64 Icons [411 kB]
0% [4 Components-amd64 store 0 B] [3 InRelease gpgv 107 kB] [8 icons-64x64 0 B/411 kB 0%] [5 InRelease 8,257 B/109 kB 8%]                                                                                                                         0% [4 Components-amd64 store 0 B] [3 InRelease gpgv 107 kB] [5 InRelease 14.0 kB/109 kB 13%]                                                                                            Get:9 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial-updates/multiverse amd64 DEP-11 Metadata [5,968 B]
0% [4 Components-amd64 store 0 B] [3 InRelease gpgv 107 kB] [9 Components-amd64 0 B/5,968 B 0%] [5 InRelease 14.0 kB/109 kB                                                                                                                             0% [4 Components-amd64 store 0 B] [3 InRelease gpgv 107 kB] [5 InRelease 14.0 kB/109 kB 13%]                                                                                            Get:10 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial-updates/multiverse DEP-11 64x64 Icons [14.3 kB]
0% [4 Components-amd64 store 0 B] [3 InRelease gpgv 107 kB] [10 icons-64x64 0 B/14.3 kB 0%] [5 InRelease 14.0 kB/109 kB 13%]                                                                                                                            0% [4 Components-amd64 store 0 B] [3 InRelease gpgv 107 kB] [5 InRelease 14.0 kB/109 kB 13%]                                                                                            0% [4 Components-amd64 store 0 B] [5 InRelease 14.0 kB/109 kB 13%]                                                                  Get:11 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial-backports/main amd64 DEP-11 Metadata [3,324 B]
0% [4 Components-amd64 store 0 B] [5 InRelease 14.0 kB/109 kB 13%]                                                                  Get:12 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial-backports/universe amd64 DEP-11 Metadata [5,324 B]
0% [4 Components-amd64 store 0 B] [5 InRelease 14.0 kB/109 kB 13%]                                                                  0% [5 InRelease 18.3 kB/109 kB 17%]0% [6 icons-64x64 store 0 B] [5 InRelease 18.3 kB/109 kB 17%]                                                             0% [5 InRelease 18.3 kB/109 kB 17%]0% [7 Components-amd64 store 0 B] [5 InRelease 18.3 kB/109 kB 17%]                                                                  0% [5 InRelease 42.5 kB/109 kB 39%]0% [8 icons-64x64 store 0 B] [5 InRelease 42.5 kB/109 kB 39%]                                                             0% [5 InRelease 42.5 kB/109 kB 39%]0% [9 Components-amd64 store 0 B] [5 InRelease 42.5 kB/109 kB 39%]                                                                  0% [5 InRelease 42.5 kB/109 kB 39%]0% [10 icons-64x64 store 0 B] [5 InRelease 42.5 kB/109 kB 39%]                                                              0% [5 InRelease 42.5 kB/109 kB 39%]0% [11 Components-amd64 store 0 B] [5 InRelease 42.5 kB/109 kB 39%]                                                                   0% [5 InRelease 42.5 kB/109 kB 39%]0% [12 Components-amd64 store 0 B] [5 InRelease 42.5 kB/109 kB 39%]                                                                   0% [5 InRelease 45.4 kB/109 kB 42%]                                   0% [Working]0% [5 InRelease gpgv 109 kB]                            81% [Working]             Get:13 http://security.ubuntu.com/ubuntu xenial-security/main amd64 DEP-11 Metadata [74.8 kB]
81% [13 Components-amd64 2,648 B/74.8 kB 4%]                                            83% [Working]83% [13 Components-amd64 store 0 B] [Waiting for headers]                                                         84% [Waiting for headers]                         Get:14 http://security.ubuntu.com/ubuntu xenial-security/main DEP-11 64x64 Icons [83.8 kB]
84% [14 icons-64x64 2,648 B/83.8 kB 3%]                                       87% [Waiting for headers]                         Get:15 http://security.ubuntu.com/ubuntu xenial-security/universe amd64 DEP-11 Metadata [124 kB]
87% [15 Components-amd64 32 B/124 kB 0%]87% [14 icons-64x64 store 0 B] [15 Components-amd64 32 B/124 kB 0%]                                                                   87% [15 Components-amd64 32 B/124 kB 0%]                                        92% [Waiting for headers]                         Get:16 http://security.ubuntu.com/ubuntu xenial-security/universe DEP-11 64x64 Icons [194 kB]
92% [16 icons-64x64 67 B/194 kB 0%]92% [15 Components-amd64 store 0 B] [16 icons-64x64 67 B/194 kB 0%]                                                                   93% [16 icons-64x64 32.9 kB/194 kB 17%]                                       100% [Waiting for headers]                          Get:17 http://security.ubuntu.com/ubuntu xenial-security/multiverse amd64 DEP-11 Metadata [2,464 B]
100% [17 Components-amd64 1,919 B/2,464 B 78%]100% [16 icons-64x64 store 0 B] [17 Components-amd64 1,919 B/2,464 B 78%]                                                                         100% [16 icons-64x64 store 0 B]                               100% [Working]100% [17 Components-amd64 store 0 B]                                    100% [Working]              Fetched 2,081 kB in 1s (1,186 kB/s)
Reading package lists... 0%Reading package lists... 0%Reading package lists... 1%Reading package lists... 6%Reading package lists... 6%Reading package lists... 9%Reading package lists... 9%Reading package lists... 9%Reading package lists... 9%Reading package lists... 9%Reading package lists... 9%Reading package lists... 44%Reading package lists... 44%apt-get install     apt-transport-https     ca-certificates     curl     gnupg-agent     software-properties-commonReading package lists... 64%Reading package lists... 64%Reading package lists... 64%Reading package lists... 64%Reading package lists... 65%Reading package lists... 65%Reading package lists... 71%Reading package lists... 71%Reading package lists... 77%Reading package lists... 77%Reading package lists... 77%Reading package lists... 77%Reading package lists... 77%Reading package lists... 77%Reading package lists... 79%Reading package lists... 81%Reading package lists... 81%Reading package lists... 83%Reading package lists... 83%Reading package lists... 84%Reading package lists... 84%Reading package lists... 84%Reading package lists... 84%Reading package lists... 84%Reading package lists... 84%Reading package lists... 84%Reading package lists... 84%Reading package lists... 84%Reading package lists... 84%Reading package lists... 84%Reading package lists... 84%Reading package lists... 88%Reading package lists... 88%Reading package lists... 93%Reading package lists... 93%Reading package lists... 93%Reading package lists... 93%Reading package lists... 93%Reading package lists... 93%Reading package lists... 96%Reading package lists... 96%Reading package lists... 98%Reading package lists... 98%Reading package lists... 98%Reading package lists... 98%Reading package lists... 98%Reading package lists... 98%Reading package lists... Done
root@worker1:~/keys# apt-get install     apt-transport-https     ca-certificates     curl     gnupg-agent     software-proper ties-common
Reading package lists... 0%Reading package lists... 100%Reading package lists... Done
Building dependency tree... 0%Building dependency tree... 0%Building dependency tree... 50%Building dependency tree... 50%Building dependency tree       
Reading state information... 0%Reading state information... 0%Reading state information... Done
apt-transport-https is already the newest version (1.2.32).
ca-certificates is already the newest version (20170717~16.04.2).
curl is already the newest version (7.47.0-1ubuntu2.14).
gnupg-agent is already the newest version (2.1.11-6ubuntu2.1).
gnupg-agent set to manually installed.
software-properties-common is already the newest version (0.96.20.9).
The following packages were automatically installed and are no longer required:
  linux-aws-headers-4.4.0-1095 linux-headers-4.4.0-1095-aws linux-headers-4.4.0-170 linux-headers-4.4.0-170-generic
  linux-image-4.4.0-1095-aws linux-image-4.4.0-170-generic linux-modules-4.4.0-1095-aws linux-modules-4.4.0-170-generic
Use 'apt autoremove' to remove them.
0 upgraded, 0 newly installed, 0 to remove and 15 not upgraded.
root@worker1:~/keys# curl -fsSL https://download.docker.com/linux/ubuntu/gpg | apt-key add -
OK
root@worker1:~/keys# apt-key fingerprint 0EBFCD88
pub   4096R/0EBFCD88 2017-02-22
      Key fingerprint = 9DC8 5822 9FC7 DD38 854A  E2D8 8D81 803C 0EBF CD88
uid                  Docker Release (CE deb) <docker@docker.com>
sub   4096R/F273FCD8 2017-02-22

root@worker1:~/keys# add-apt-repository    "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) 122      stable"
root@worker1:~/keys# apt-get update
0% [Working]            Get:1 https://download.docker.com/linux/ubuntu xenial InRelease [66.2 kB]
0% [Connecting to us-west-2.ec2.archive.ubuntu.com] [Connecting to security.ubuntu.com (2001:67c:1360:8001::21)] [1 InReleas                                                                                                                            0% [Connecting to us-west-2.ec2.archive.ubuntu.com] [Connecting to security.ubuntu.com (2001:67c:1360:8001::21)]0% [1 InRelease gpgv 66.2 kB] [Connecting to us-west-2.ec2.archive.ubuntu.com] [Connecting to security.ubuntu.com (2001:67c:                                                                                                                            Hit:2 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial InRelease
                                                                                                                            0% [1 InRelease gpgv 66.2 kB] [Waiting for headers] [Connecting to security.ubuntu.com (2001:67c:1360:8001::21)]                                                                                                                Hit:3 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial-updates InRelease
                                                                                                                0% [1 InRelease gpgv 66.2 kB] [Waiting for headers]                                                   Hit:4 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial-backports InRelease
0% [1 InRelease gpgv 66.2 kB] [Waiting for headers]                                                   0% [Waiting for headers]0% [2 InRelease gpgv 247 kB] [Waiting for headers]                                                  Get:5 https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages [12.0 kB]
0% [2 InRelease gpgv 247 kB] [Waiting for headers] [5 Packages 8,192 B/12.0 kB 68%]                                                                                   0% [2 InRelease gpgv 247 kB] [Waiting for headers]0% [5 Packages store 0 B] [2 InRelease gpgv 247 kB] [Waiting for headers]                                                                         0% [2 InRelease gpgv 247 kB] [Waiting for headers]                                                  0% [Waiting for headers]0% [3 InRelease gpgv 109 kB] [Waiting for headers]                                                  Hit:6 http://security.ubuntu.com/ubuntu xenial-security InRelease
                                                  0% [3 InRelease gpgv 109 kB]                            0% [Working]0% [4 InRelease gpgv 107 kB]                            0% [Working]0% [6 InRelease gpgv 109 kB]                            100% [Working]              Fetched 78.2 kB in 0s (144 kB/s)
Reading package lists... 0%Reading package lists... 0%Reading package lists... 1%Reading package lists... 6%Reading package lists... 6%Reading package lists... 9%Reading package lists... 9%Reading package lists... 9%Reading package lists... 9%Reading package lists... 9%Reading package lists... 9%Reading package lists... 44%Reading package lists... 44%Reading package lists... 64%Reading package lists... 64%Reading package lists... 64%Reading package lists... 64%Reading package lists... 65%Reading package lists... 65%Reading package lists... 71%Reading package lists... 71%Reading package lists... 77%Reading package lists... 77%Reading package lists... 77%Reading package lists... 77%Reading package lists... 77%Reading package lists... 77%Reading package lists... 77%Reading package lists... 81%Reading package lists... 81%Reading package lists... 83%Reading package lists... 83%Reading package lists... 83%Reading package lists... 83%Reading package lists... 84%Reading package lists... 84%Reading package lists... 84%Reading package lists... 84%Reading package lists... 84%Reading package lists... 84%Reading package lists... 84%Reading package lists... 84%Reading package lists... 84%Reading package lists... 84%Reading package lists... 88%Reading package lists... 88%Reading package lists... 93%Reading package lists... 93%Reading package lists... 93%Reading package lists... 93%Reading package lists... 93%Reading package lists... 93%Reading package lists... 96%Reading package lists... 96%Reading package lists... 98%Reading package lists... 98%Reading package lists... 98%Reading package lists... 98%Reading package lists... 98%Reading package lists... 98%Reading package lists... 98%Reading package lists... 98%Reading package lists... Done
root@worker1:~/keys# apt-get install docker-ce docker-ce-cli containerd.io
Reading package lists... 0%Reading package lists... 100%Reading package lists... Done
Building dependency tree... 0%Building dependency tree... 0%Building dependency tree... 50%Building dependency tree... 50%Building dependency tree       
Reading state information... 0%Reading state information... 0%Reading state information... Done
The following packages were automatically installed and are no longer required:
  linux-aws-headers-4.4.0-1095 linux-headers-4.4.0-1095-aws linux-headers-4.4.0-170 linux-headers-4.4.0-170-generic
  linux-image-4.4.0-1095-aws linux-image-4.4.0-170-generic linux-modules-4.4.0-1095-aws linux-modules-4.4.0-170-generic
Use 'apt autoremove' to remove them.
The following additional packages will be installed:
  aufs-tools cgroupfs-mount pigz
The following NEW packages will be installed:
  aufs-tools cgroupfs-mount containerd.io docker-ce docker-ce-cli pigz
0 upgraded, 6 newly installed, 0 to remove and 15 not upgraded.
Need to get 85.3 MB of archives.
After this operation, 384 MB of additional disk space will be used.
Do you want to continue? [Y/n] y
0% [Working]            Get:1 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial/universe amd64 pigz amd64 2.3.1-2 [61.1 kB]
0% [1 pigz 43.0 kB/61.1 kB 70%]                               3% [Working]            Get:2 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial/universe amd64 aufs-tools amd64 1:3.2+20130722-1.1ubuntu1 [92.9 kB]
3% [2 aufs-tools 24.2 kB/92.9 kB 26%]                                     7% [Waiting for headers]                        Get:3 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial/universe amd64 cgroupfs-mount all 1.2 [4,970 B]
                        10% [Working]             Get:4 https://download.docker.com/linux/ubuntu xenial/stable amd64 containerd.io amd64 1.2.10-3 [19.9 MB]
10% [4 containerd.io 0 B/19.9 MB 0%]                                    32% [Working]             Get:5 https://download.docker.com/linux/ubuntu xenial/stable amd64 docker-ce-cli amd64 5:19.03.5~3-0~ubuntu-xenial [42.4 MB]
32% [5 docker-ce-cli 0 B/42.4 MB 0%]63% [5 docker-ce-cli 32.8 MB/42.4 MB 77%]                                         75% [Working]             Get:6 https://download.docker.com/linux/ubuntu xenial/stable amd64 docker-ce amd64 5:19.03.5~3-0~ubuntu-xenial [22.8 MB]
75% [6 docker-ce 0 B/22.8 MB 0%]                                100% [Working]              Fetched 85.3 MB in 1s (52.1 MB/s)
Selecting previously unselected package pigz.
(Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 303104 files and directories currently installed.)
Preparing to unpack .../pigz_2.3.1-2_amd64.deb ...
Unpacking pigz (2.3.1-2) ...
Selecting previously unselected package aufs-tools.
Preparing to unpack .../aufs-tools_1%3a3.2+20130722-1.1ubuntu1_amd64.deb ...
Unpacking aufs-tools (1:3.2+20130722-1.1ubuntu1) ...
Selecting previously unselected package cgroupfs-mount.
Preparing to unpack .../cgroupfs-mount_1.2_all.deb ...
Unpacking cgroupfs-mount (1.2) ...
Selecting previously unselected package containerd.io.
Preparing to unpack .../containerd.io_1.2.10-3_amd64.deb ...
Unpacking containerd.io (1.2.10-3) ...
Selecting previously unselected package docker-ce-cli.
Preparing to unpack .../docker-ce-cli_5%3a19.03.5~3-0~ubuntu-xenial_amd64.deb ...
Unpacking docker-ce-cli (5:19.03.5~3-0~ubuntu-xenial) ...
Selecting previously unselected package docker-ce.
Preparing to unpack .../docker-ce_5%3a19.03.5~3-0~ubuntu-xenial_amd64.deb ...
Unpacking docker-ce (5:19.03.5~3-0~ubuntu-xenial) ...
Processing triggers for man-db (2.7.5-1) ...
Processing triggers for libc-bin (2.23-0ubuntu11) ...
Processing triggers for ureadahead (0.100.0-19.1) ...
Processing triggers for systemd (229-4ubuntu21.22) ...
Setting up pigz (2.3.1-2) ...
Setting up aufs-tools (1:3.2+20130722-1.1ubuntu1) ...
Setting up cgroupfs-mount (1.2) ...
Setting up containerd.io (1.2.10-3) ...
Setting up docker-ce-cli (5:19.03.5~3-0~ubuntu-xenial) ...
Setting up docker-ce (5:19.03.5~3-0~ubuntu-xenial) ...
Processing triggers for libc-bin (2.23-0ubuntu11) ...
Processing triggers for systemd (229-4ubuntu21.22) ...
Processing triggers for ureadahead (0.100.0-19.1) ...
root@worker1:~/keys# apt-cache madison docker-ce
 docker-ce | 5:19.03.5~3-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages
 docker-ce | 5:19.03.4~3-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages
 docker-ce | 5:19.03.3~3-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages
 docker-ce | 5:19.03.2~3-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages
 docker-ce | 5:19.03.1~3-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages
 docker-ce | 5:19.03.0~3-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages
 docker-ce | 5:18.09.9~3-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages
 docker-ce | 5:18.09.8~3-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages
 docker-ce | 5:18.09.7~3-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages
 docker-ce | 5:18.09.6~3-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages
 docker-ce | 5:18.09.5~3-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages
 docker-ce | 5:18.09.4~3-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages
 docker-ce | 5:18.09.3~3-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages
 docker-ce | 5:18.09.2~3-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages
 docker-ce | 5:18.09.1~3-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages
 docker-ce | 5:18.09.0~3-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages
 docker-ce | 18.06.3~ce~3-0~ubuntu | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages
 docker-ce | 18.06.2~ce~3-0~ubuntu | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages
 docker-ce | 18.06.1~ce~3-0~ubuntu | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages
 docker-ce | 18.06.0~ce~3-0~ubuntu | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages
 docker-ce | 18.03.1~ce-0~ubuntu | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages
 docker-ce | 18.03.0~ce-0~ubuntu | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages
 docker-ce | 17.12.1~ce-0~ubuntu | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages
 docker-ce | 17.12.0~ce-0~ubuntu | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages
 docker-ce | 17.09.1~ce-0~ubuntu | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages
 docker-ce | 17.09.0~ce-0~ubuntu | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages
 docker-ce | 17.06.2~ce-0~ubuntu | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages
 docker-ce | 17.06.1~ce-0~ubuntu | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages
 docker-ce | 17.06.0~ce-0~ubuntu | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages
 docker-ce | 17.03.3~ce-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages
 docker-ce | 17.03.2~ce-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages
 docker-ce | 17.03.1~ce-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages
 docker-ce | 17.03.0~ce-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages
root@worker1:~/keys# rpm q-aq-qa | grep i- docker
grep: docker: No such file or directory
^C
root@worker1:~/keys# rpm -qa | grep i- docker docker- dockeri docker
The program 'rpm' is currently not installed. You can install it by typing:
apt install rpm
root@worker1:~/keys# 
root@worker1:~/keys# apt-get list | grep -i docker
E: Invalid operation list
root@worker1:~/keys# apt-get list | grep -i dockerapt
root@worker1:~/keys# currently not installed. You can install it by typing:
currently: command not found
root@worker1:~/keys# a^C
root@worker1:~/keys#  currently not installed. You can install it by typing:
currently: command not found
root@worker1:~/keys# a^C
root@worker1:~/keys# apt install rpm
Reading package lists... 0%Reading package lists... 100%Reading package lists... Done
Building dependency tree... 0%Building dependency tree... 0%Building dependency tree... 50%Building dependency tree... 50%Building dependency tree       
Reading state information... 0%Reading state information... 0%Reading state information... Done
The following packages were automatically installed and are no longer required:
  linux-aws-headers-4.4.0-1095 linux-headers-4.4.0-1095-aws linux-headers-4.4.0-170 linux-headers-4.4.0-170-generic
  linux-image-4.4.0-1095-aws linux-image-4.4.0-170-generic linux-modules-4.4.0-1095-aws linux-modules-4.4.0-170-generic
Use 'apt autoremove' to remove them.
The following additional packages will be installed:
  debugedit librpm3 librpmbuild3 librpmio3 librpmsign3 rpm-common rpm2cpio
Suggested packages:
  rpm-i18n alien elfutils rpmlint rpm2html
The following NEW packages will be installed:
  debugedit librpm3 librpmbuild3 librpmio3 librpmsign3 rpm rpm-common rpm2cpio
0 upgraded, 8 newly installed, 0 to remove and 15 not upgraded.
Need to get 453 kB of archives.
After this operation, 1,820 kB of additional disk space will be used.
Do you want to continue? [Y/n] y
0% [Working]            Get:1 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial/universe amd64 librpmio3 amd64 4.12.0.1+dfsg1-3build3 [68.7 kB]
2% [1 librpmio3 14.1 kB/68.7 kB 20%]                                    15% [Working]             Get:2 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial/universe amd64 debugedit amd64 4.12.0.1+dfsg1-3build3 [15.5 kB]
17% [2 debugedit 15.5 kB/15.5 kB 100%]                                      20% [Working]             Get:3 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial/universe amd64 librpm3 amd64 4.12.0.1+dfsg1-3build3 [155 kB]
24% [3 librpm3 24.6 kB/155 kB 16%]                                  50% [Working]             Get:4 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial/universe amd64 librpmbuild3 amd64 4.12.0.1+dfsg1-3build3 [58.0 kB]
53% [4 librpmbuild3 21.4 kB/58.0 kB 37%]                                        62% [Working]             Get:5 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial/universe amd64 librpmsign3 amd64 4.12.0.1+dfsg1-3build3 [8,192 B]
64% [5 librpmsign3 8,192 B/8,192 B 100%]                                        66% [Working]             Get:6 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial/universe amd64 rpm-common amd64 4.12.0.1+dfsg1-3build3 [25.7 kB]
70% [6 rpm-common 20.0 kB/25.7 kB 78%]                                      73% [Working]             Get:7 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial/universe amd64 rpm2cpio amd64 4.12.0.1+dfsg1-3build3 [7,756 B]
75% [7 rpm2cpio 7,756 B/7,756 B 100%]                                     77% [Working]             Get:8 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial/universe amd64 rpm amd64 4.12.0.1+dfsg1-3build3 [114 kB]
78% [8 rpm 4,096 B/114 kB 4%]                             100% [Working]              Fetched 453 kB in 0s (4,669 kB/s)

Selecting previously unselected package librpmio3.
(Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 303401 files and directories currently installed.)
Preparing to unpack .../librpmio3_4.12.0.1+dfsg1-3build3_amd64.deb ...
Progress: [  0%] [.......................................................................................................] Progress: [  2%] [###....................................................................................................] Unpacking librpmio3 (4.12.0.1+dfsg1-3build3) ...
Progress: [  4%] [######.................................................................................................] Progress: [  7%] [########...............................................................................................] Selecting previously unselected package debugedit.
Preparing to unpack .../debugedit_4.12.0.1+dfsg1-3build3_amd64.deb ...
Progress: [  9%] [###########............................................................................................] Unpacking debugedit (4.12.0.1+dfsg1-3build3) ...
Progress: [ 12%] [#############..........................................................................................] Progress: [ 14%] [################.......................................................................................] Selecting previously unselected package librpm3.
Preparing to unpack .../librpm3_4.12.0.1+dfsg1-3build3_amd64.deb ...
Progress: [ 17%] [##################.....................................................................................] Unpacking librpm3 (4.12.0.1+dfsg1-3build3) ...
Progress: [ 19%] [#####################..................................................................................] Progress: [ 21%] [#######################................................................................................] Selecting previously unselected package librpmbuild3.
Preparing to unpack .../librpmbuild3_4.12.0.1+dfsg1-3build3_amd64.deb ...
Progress: [ 24%] [##########################.............................................................................] Unpacking librpmbuild3 (4.12.0.1+dfsg1-3build3) ...
Progress: [ 26%] [############################...........................................................................] Progress: [ 29%] [###############################........................................................................] Selecting previously unselected package librpmsign3.
Preparing to unpack .../librpmsign3_4.12.0.1+dfsg1-3build3_amd64.deb ...
Progress: [ 31%] [#################################......................................................................] Unpacking librpmsign3 (4.12.0.1+dfsg1-3build3) ...
Progress: [ 34%] [####################################...................................................................] Progress: [ 36%] [######################################.................................................................] Selecting previously unselected package rpm-common.
Preparing to unpack .../rpm-common_4.12.0.1+dfsg1-3build3_amd64.deb ...
Progress: [ 39%] [#########################################..............................................................] Unpacking rpm-common (4.12.0.1+dfsg1-3build3) ...
Progress: [ 41%] [###########################################............................................................] Progress: [ 43%] [##############################################.........................................................] Selecting previously unselected package rpm2cpio.
Preparing to unpack .../rpm2cpio_4.12.0.1+dfsg1-3build3_amd64.deb ...
Progress: [ 46%] [################################################.......................................................] Unpacking rpm2cpio (4.12.0.1+dfsg1-3build3) ...
Progress: [ 48%] [###################################################....................................................] Progress: [ 51%] [#####################################################..................................................] Selecting previously unselected package rpm.
Preparing to unpack .../rpm_4.12.0.1+dfsg1-3build3_amd64.deb ...
Progress: [ 53%] [########################################################...............................................] Unpacking rpm (4.12.0.1+dfsg1-3build3) ...
Progress: [ 56%] [##########################################################.............................................] Progress: [ 58%] [#############################################################..........................................] Processing triggers for libc-bin (2.23-0ubuntu11) ...
Processing triggers for man-db (2.7.5-1) ...
Setting up librpmio3 (4.12.0.1+dfsg1-3build3) ...
Progress: [ 60%] [###############################################################........................................] Progress: [ 63%] [##################################################################.....................................] Setting up debugedit (4.12.0.1+dfsg1-3build3) ...
Progress: [ 65%] [####################################################################...................................] Progress: [ 68%] [#######################################################################................................] Setting up librpm3 (4.12.0.1+dfsg1-3build3) ...
Progress: [ 70%] [#########################################################################..............................] Progress: [ 73%] [############################################################################...........................] Setting up librpmbuild3 (4.12.0.1+dfsg1-3build3) ...
Progress: [ 75%] [##############################################################################.........................] Progress: [ 78%] [#################################################################################......................] Setting up librpmsign3 (4.12.0.1+dfsg1-3build3) ...
Progress: [ 80%] [###################################################################################....................] Progress: [ 82%] [######################################################################################.................] Setting up rpm-common (4.12.0.1+dfsg1-3build3) ...
Progress: [ 85%] [########################################################################################...............] Progress: [ 87%] [###########################################################################################............] Setting up rpm2cpio (4.12.0.1+dfsg1-3build3) ...
Progress: [ 90%] [#############################################################################################..........] Progress: [ 92%] [################################################################################################.......] Setting up rpm (4.12.0.1+dfsg1-3build3) ...
Progress: [ 95%] [##################################################################################################.....] Progress: [ 97%] [#####################################################################################################..] Processing triggers for libc-bin (2.23-0ubuntu11) ...

root@worker1:~/keys# apt install rpm currently not installed. You can install it by typing:apt-get list | grep -i dockerrpm -qai--i
root@worker1:~/keys# docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
root@worker1:~/keys# 
root@worker1:~/keys# 
root@worker1:~/keys# systemctl daemon-reload
root@worker1:~/keys# systemctl enable kubelet kube-proxy
Created symlink from /etc/systemd/system/multi-user.target.wants/kubelet.service to /etc/systemd/system/kubelet.service.
Created symlink from /etc/systemd/system/multi-user.target.wants/kube-proxy.service to /etc/systemd/system/kube-proxy.service.
root@worker1:~/keys# systemctl start kubelet kube-proxy
root@worker1:~/keys# systemctl status kubelet kube-proxy
 kubelet.service - Kubernetes Kubelet
   Loaded: loaded (/etc/systemd/system/kubelet.service; enabled; vendor preset: enabled)
   Active: active (running) since Fri 2020-01-24 17:26:15 UTC; 6s ago
     Docs: https://github.com/kubernetes/kubernetes
 Main PID: 32494 (kubelet)
    Tasks: 14
   Memory: 80.9M
      CPU: 479ms
   CGroup: /system.slice/kubelet.service
           32494 /usr/local/bin/kubelet --config=/var/lib/kubelet/kubelet-config.yaml --image-pull-progress-deadline=2m --k

Jan 24 17:26:19 worker1 kubelet[32494]: I0124 17:26:19.104168   32494 container_manager_linux.go:376] Updating kernel flag: v
Jan 24 17:26:19 worker1 kubelet[32494]: I0124 17:26:19.104229   32494 container_manager_linux.go:376] Updating kernel flag: k
Jan 24 17:26:19 worker1 kubelet[32494]: I0124 17:26:19.104264   32494 container_manager_linux.go:376] Updating kernel flag: k
Jan 24 17:26:19 worker1 kubelet[32494]: I0124 17:26:19.114070   32494 manager.go:196] Starting Device Plugin manager
Jan 24 17:26:19 worker1 kubelet[32494]: W0124 17:26:19.114123   32494 manager.go:528] Failed to retrieve checkpoint for "kube
Jan 24 17:26:19 worker1 kubelet[32494]: I0124 17:26:19.114247   32494 manager.go:231] Serving device plugin registration serv
Jan 24 17:26:19 worker1 kubelet[32494]: I0124 17:26:19.133792   32494 container_manager_linux.go:434] [ContainerManager]: Dis
Jan 24 17:26:19 worker1 kubelet[32494]: I0124 17:26:19.259718   32494 plugin_watcher.go:90] Plugin Watcher Start at /var/lib/
Jan 24 17:26:19 worker1 kubelet[32494]: I0124 17:26:19.260122   32494 kubelet.go:1908] SyncLoop (ADD, "api"): ""
Jan 24 17:26:19 worker1 kubelet[32494]: I0124 17:26:19.360669   32494 reconciler.go:154] Reconciler: start to sync state

 kube-proxy.service - Kubernetes Kube Proxy
   Loaded: loaded (/etc/systemd/system/kube-proxy.service; enabled; vendor preset: enabled)
   Active: active (running) since Fri 2020-01-24 17:26:15 UTC; 6s ago
     Docs: https://github.com/kubernetes/kubernetes
 Main PID: 32496 (kube-proxy)
    Tasks: 0
   Memory: 28.7M
      CPU: 128ms
   CGroup: /system.slice/kube-proxy.service
            32496 /usr/local/bin/kube-proxy --config=/var/lib/kube-proxy/kube-proxy-config.yaml

Jan 24 17:26:16 worker1 kube-proxy[32496]: I0124 17:26:16.644128   32496 conntrack.go:52] Setting nf_conntrack_max to 131072
Jan 24 17:26:16 worker1 kube-proxy[32496]: I0124 17:26:16.691415   32496 conntrack.go:83] Setting conntrack hashsize to 32768
Jan 24 17:26:16 worker1 kube-proxy[32496]: I0124 17:26:16.691670   32496 conntrack.go:100] Set sysctl 'net/netfilter/nf_connt
Jan 24 17:26:16 worker1 kube-proxy[32496]: I0124 17:26:16.691733   32496 conntrack.go:100] Set sysctl 'net/netfilter/nf_connt
Jan 24 17:26:16 worker1 kube-proxy[32496]: I0124 17:26:16.691869   32496 config.go:102] Starting endpoints config controller
Jan 24 17:26:16 worker1 kube-proxy[32496]: I0124 17:26:16.691877   32496 controller_utils.go:1027] Waiting for caches to sync
Jan 24 17:26:16 worker1 kube-proxy[32496]: I0124 17:26:16.691898   32496 config.go:202] Starting service config controller
Jan 24 17:26:16 worker1 kube-proxy[32496]: I0124 17:26:16.691903   32496 controller_utils.go:1027] Waiting for caches to sync
Jan 24 17:26:16 worker1 kube-proxy[32496]: I0124 17:26:16.792014   32496 controller_utils.go:1034] Caches are synced for endp
Jan 24 17:26:16 worker1 kube-proxy[32496]: I0124 17:26:16.792038   32496 controller_utils.go:1034] Caches are synced for serv
lines 1-43lines 1-43/43 (END)root@worker1:~/keys# kubectl get nodes --kubeconfig admin.kubeconfig
error: stat admin.kubeconfig: no such file or directory
root@worker1:~/keys# ls -l
total 28
-rw-r--r-- 1 root root  989 Jan 24 13:14 ca.crt
-rw------- 1 root root 5248 Jan 24 13:15 kube-proxy.kubeconfig
-rw-r--r-- 1 root root 1147 Jan 24 13:14 worker1.crt
-rw-r--r-- 1 root root 1679 Jan 24 13:14 worker1.key
-rw------- 1 root root 5460 Jan 24 13:14 worker1.kubeconfig
root@worker1:~/keys# logout
Connection to worker1 closed.
root@master1:~# lcd keys/
root@master1:~/keys# ls l-l admin.ck
admin.key         admin.kubeconfig  
root@master1:~/keys# ls -l admin.k
admin.key         admin.kubeconfig  
root@master1:~/keys# ls -l admin.kubeconfig 
-rw------- 1 root root 5243 Jan 24 13:13 admin.kubeconfig
root@master1:~/keys# scp admin.kubeconfig worker1:/keys/
scp: /keys/: Is a directory
root@master1:~/keys# scp admin.kubeconfig worker1:/keys//keys/r/keys/o/keys/o/keys/t/keys//keys/keys/
admin.kubeconfig                                                                             0%    0     0.0KB/s   --:-- ETAadmin.kubeconfig                                                                           100% 5243     5.1KB/s   00:00    
root@master1:~/keys# ssh worker1
Welcome to Ubuntu 16.04.6 LTS (GNU/Linux 4.4.0-1099-aws x86_64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/advantage

 * Overheard at KubeCon: "microk8s.status just blew my mind".

     https://microk8s.io/docs/commands#microk8s.status

  Get cloud support with Ubuntu Advantage Cloud Guest:
    http://www.ubuntu.com/business/services/cloud

15 packages can be updated.
0 updates are security updates.

New release '18.04.3 LTS' available.
Run 'do-release-upgrade' to upgrade to it.


*** System restart required ***
Last login: Fri Jan 24 17:19:52 2020 from 172.31.122.25
root@worker1:~# cd keys/
root@worker1:~/keys# ls -l
total 36
-rw------- 1 root root 5243 Jan 24 17:27 admin.kubeconfig
-rw-r--r-- 1 root root  989 Jan 24 13:14 ca.crt
-rw------- 1 root root 5248 Jan 24 13:15 kube-proxy.kubeconfig
-rw-r--r-- 1 root root 1147 Jan 24 13:14 worker1.crt
-rw-r--r-- 1 root root 1679 Jan 24 13:14 worker1.key
-rw------- 1 root root 5460 Jan 24 13:14 worker1.kubeconfig
root@worker1:~/keys# ls -lcd keys/ls -lkubectl get nodes --kubeconfig admin.kubeconfig
The connection to the server 127.0.0.1:6443 was refused - did you specify the right host or port?
root@worker1:~/keys# 
root@worker1:~/keys# 
root@worker1:~/keys# kubectl get nodes --kubeconfig admin.kubeconfigls -lcd keys/ls -lkubectl get nodes --kubeconfig admin.kubeconfigsystemctl status kubelet kube-proxyrttus
 kubelet.service - Kubernetes Kubelet
   Loaded: loaded (/etc/systemd/system/kubelet.service; enabled; vendor preset: enabled)
   Active: active (running) since Fri 2020-01-24 17:26:15 UTC; 1min 36s ago
     Docs: https://github.com/kubernetes/kubernetes
 Main PID: 32494 (kubelet)
    Tasks: 14
   Memory: 82.0M
      CPU: 1.832s
   CGroup: /system.slice/kubelet.service
           32494 /usr/local/bin/kubelet --config=/var/lib/kubelet/kubelet-config.yaml --image-pull-progress-deadline=2m --k

Jan 24 17:27:29 worker1 kubelet[32494]: W0124 17:27:29.403646   32494 cni.go:203] Unable to update cni config: No networks fo
Jan 24 17:27:29 worker1 kubelet[32494]: E0124 17:27:29.403795   32494 kubelet.go:2192] Container runtime network not ready: N
Jan 24 17:27:34 worker1 kubelet[32494]: W0124 17:27:34.411475   32494 cni.go:203] Unable to update cni config: No networks fo
Jan 24 17:27:34 worker1 kubelet[32494]: E0124 17:27:34.411619   32494 kubelet.go:2192] Container runtime network not ready: N
Jan 24 17:27:39 worker1 kubelet[32494]: W0124 17:27:39.423102   32494 cni.go:203] Unable to update cni config: No networks fo
Jan 24 17:27:39 worker1 kubelet[32494]: E0124 17:27:39.423305   32494 kubelet.go:2192] Container runtime network not ready: N
Jan 24 17:27:44 worker1 kubelet[32494]: W0124 17:27:44.431366   32494 cni.go:203] Unable to update cni config: No networks fo
Jan 24 17:27:44 worker1 kubelet[32494]: E0124 17:27:44.431861   32494 kubelet.go:2192] Container runtime network not ready: N
Jan 24 17:27:49 worker1 kubelet[32494]: W0124 17:27:49.440332   32494 cni.go:203] Unable to update cni config: No networks fo
Jan 24 17:27:49 worker1 kubelet[32494]: E0124 17:27:49.440594   32494 kubelet.go:2192] Container runtime network not ready: N

 kube-proxy.service - Kubernetes Kube Proxy
   Loaded: loaded (/etc/systemd/system/kube-proxy.service; enabled; vendor preset: enabled)
   Active: active (running) since Fri 2020-01-24 17:26:15 UTC; 1min 36s ago
     Docs: https://github.com/kubernetes/kubernetes
 Main PID: 32496 (kube-proxy)
    Tasks: 0
   Memory: 28.7M
      CPU: 128ms
   CGroup: /system.slice/kube-proxy.service
            32496 /usr/local/bin/kube-proxy --config=/var/lib/kube-proxy/kube-proxy-config.yaml

Jan 24 17:26:16 worker1 kube-proxy[32496]: I0124 17:26:16.644128   32496 conntrack.go:52] Setting nf_conntrack_max to 131072
Jan 24 17:26:16 worker1 kube-proxy[32496]: I0124 17:26:16.691415   32496 conntrack.go:83] Setting conntrack hashsize to 32768
Jan 24 17:26:16 worker1 kube-proxy[32496]: I0124 17:26:16.691670   32496 conntrack.go:100] Set sysctl 'net/netfilter/nf_connt
Jan 24 17:26:16 worker1 kube-proxy[32496]: I0124 17:26:16.691733   32496 conntrack.go:100] Set sysctl 'net/netfilter/nf_connt
Jan 24 17:26:16 worker1 kube-proxy[32496]: I0124 17:26:16.691869   32496 config.go:102] Starting endpoints config controller
Jan 24 17:26:16 worker1 kube-proxy[32496]: I0124 17:26:16.691877   32496 controller_utils.go:1027] Waiting for caches to sync
Jan 24 17:26:16 worker1 kube-proxy[32496]: I0124 17:26:16.691898   32496 config.go:202] Starting service config controller
Jan 24 17:26:16 worker1 kube-proxy[32496]: I0124 17:26:16.691903   32496 controller_utils.go:1027] Waiting for caches to sync
Jan 24 17:26:16 worker1 kube-proxy[32496]: I0124 17:26:16.792014   32496 controller_utils.go:1034] Caches are synced for endp
Jan 24 17:26:16 worker1 kube-proxy[32496]: I0124 17:26:16.792038   32496 controller_utils.go:1034] Caches are synced for serv
lines 1-43root@worker1:~/keys# kubectl get nodes --kubeconfig admin.kubeconfig
The connection to the server 127.0.0.1:6443 was refused - did you specify the right host or port?
root@worker1:~/keys# 
root@worker1:~/keys# 
root@worker1:~/keys# logout
Connection to worker1 closed.
root@master1:~/keys# 
root@master1:~/keys# kubectl get nodes --kubeconfig admin.kubeconfig
NAME      STATUS     ROLES    AGE    VERSION
worker1   NotReady   <none>   108s   v1.13.0
root@master1:~/keys# 
root@master1:~/keys# 
root@master1:~/keys# kubectl get nodes --kubeconfig admin.kubeconfig
NAME      STATUS     ROLES    AGE     VERSION
worker1   NotReady   <none>   2m42s   v1.13.0
root@master1:~/keys# 
root@master1:~/keys# 
root@master1:~/keys# kubectl get nodes --kubeconfig admin.kubeconfig -o wide
NAME      STATUS     ROLES    AGE     VERSION   INTERNAL-IP      EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION   CONTAINER-RUNTIME
worker1   NotReady   <none>   2m49s   v1.13.0   172.31.122.147   <none>        Ubuntu 16.04.6 LTS   4.4.0-1099-aws   docker://19.3.5
root@master1:~/keys# kubectl get nodes -o wide
NAME      STATUS     ROLES    AGE     VERSION   INTERNAL-IP      EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION   CONTAINER-RUNTIME
worker1   NotReady   <none>   2m55s   v1.13.0   172.31.122.147   <none>        Ubuntu 16.04.6 LTS   4.4.0-1099-aws   docker://19.3.5
root@master1:~/keys# 
root@master1:~/keys# 
root@master1:~/keys# kubectl get componentstatuses
NAME                 STATUS    MESSAGE             ERROR
scheduler            Healthy   ok                  
controller-manager   Healthy   ok                  
etcd-2               Healthy   {"health":"true"}   
etcd-1               Healthy   {"health":"true"}   
etcd-0               Healthy   {"health":"true"}   
root@master1:~/keys# systemctl status systemd-resolved.service
 systemd-resolved.service - Network Name Resolution
   Loaded: loaded (/lib/systemd/system/systemd-resolved.service; disabled; vendor preset: enabled)
  Drop-In: /lib/systemd/system/systemd-resolved.service.d
           resolvconf.conf
   Active: inactive (dead)
     Docs: man:systemd-resolved.service(8)
root@master1:~/keys# sssh worker1
Welcome to Ubuntu 16.04.6 LTS (GNU/Linux 4.4.0-1099-aws x86_64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/advantage

 * Overheard at KubeCon: "microk8s.status just blew my mind".

     https://microk8s.io/docs/commands#microk8s.status

  Get cloud support with Ubuntu Advantage Cloud Guest:
    http://www.ubuntu.com/business/services/cloud

15 packages can be updated.
0 updates are security updates.

New release '18.04.3 LTS' available.
Run 'do-release-upgrade' to upgrade to it.


*** System restart required ***
Last login: Fri Jan 24 17:27:32 2020 from 172.31.122.25
root@worker1:~# systemctl status systemd-resolved.service
 systemd-resolved.service - Network Name Resolution
   Loaded: loaded (/lib/systemd/system/systemd-resolved.service; disabled; vendor preset: enabled)
  Drop-In: /lib/systemd/system/systemd-resolved.service.d
           resolvconf.conf
   Active: inactive (dead)
     Docs: man:systemd-resolved.service(8)
root@worker1:~# cat /etc/hosts
127.0.0.1 localhost

# The following lines are desirable for IPv6 capable hosts
::1 ip6-localhost ip6-loopback
fe00::0 ip6-localnet
ff00::0 ip6-mcastprefix
ff02::1 ip6-allnodes
ff02::2 ip6-allrouters
ff02::3 ip6-allhosts
# Cloud Server Hostname mapping
172.31.122.147   rameshhms4c.mylabserver.com
172.31.122.147 worker1
root@worker1:~# logout
Connection to worker1 closed.
root@master1:~/keys# cat .et/etc/hosts
127.0.0.1 localhost

# The following lines are desirable for IPv6 capable hosts
::1 ip6-localhost ip6-loopback
fe00::0 ip6-localnet
ff00::0 ip6-mcastprefix
ff02::1 ip6-allnodes
ff02::2 ip6-allrouters
ff02::3 ip6-allhosts
# Cloud Server Hostname mapping
172.31.122.25   rameshhms1c.mylabserver.com
172.31.122.25master1
172.31.125.181master2
172.31.115.2master3
172.31.122.147worker1
172.31.123.142loadbalancer
root@master1:~/keys# KUBERNETES_LB_ADDRESS=172.31.123.142
root@master1:~/keys#   kubectl config set-cluster kubernetes \
>     --certificate-authority=ca.crt \
>     --embed-certs=true \
>     --server=https://${KUBERNETES_LB_ADDRESS}:6443
    --cluster=kubernetes-the-hard-way \
    --user=admin

  kubectl config use-context kubernetesCluster "kubernetes" set.
root@master1:~/keys# 
root@master1:~/keys#   kubectl config set-credentials admin \
>     --client-certificate=admin.crt \
>     --client-key=admin.key
User "admin" set.
root@master1:~/keys# 
root@master1:~/keys#   kubectl config set-context kubernetes \
>     --cluster=kubernetes-the-hard-way \
>     --user=admin
Context "kubernetes" created.
root@master1:~/keys# 
root@master1:~/keys#   kubectl config use-context kubernetes
Switched to context "kubernetes".
root@master1:~/keys# 
root@master1:~/keys# kubectl get nmooodes
NAME      STATUS     ROLES    AGE     VERSION
worker1   NotReady   <none>   5m50s   v1.13.0
root@master1:~/keys# kubectl get nodespods
No resources found.
root@master1:~/keys# ssh worker1
Welcome to Ubuntu 16.04.6 LTS (GNU/Linux 4.4.0-1099-aws x86_64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/advantage

 * Overheard at KubeCon: "microk8s.status just blew my mind".

     https://microk8s.io/docs/commands#microk8s.status

  Get cloud support with Ubuntu Advantage Cloud Guest:
    http://www.ubuntu.com/business/services/cloud

15 packages can be updated.
0 updates are security updates.

New release '18.04.3 LTS' available.
Run 'do-release-upgrade' to upgrade to it.


*** System restart required ***
Last login: Fri Jan 24 17:30:46 2020 from 172.31.122.25
root@worker1:~# cd package/
root@worker1:~/package# wget https://github.com/containernetworking/plugins/releases/download/v0.7.5/cni-plugins-amd64-v0.7.5 .tgz
--2020-01-24 17:32:34--  https://github.com/containernetworking/plugins/releases/download/v0.7.5/cni-plugins-amd64-v0.7.5.tgz
Resolving github.com (github.com)... 192.30.255.113
Connecting to github.com (github.com)|192.30.255.113|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/84575398/131b7380-4751-11e9-8db3-7b96b6a634f3?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200124%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200124T173236Z&X-Amz-Expires=300&X-Amz-Signature=e0ee2c3252b2256873c6fdcc3a8ea60af62631043198dd1fab829808b6c0cc47&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dcni-plugins-amd64-v0.7.5.tgz&response-content-type=application%2Foctet-stream [following]
--2020-01-24 17:32:35--  https://github-production-release-asset-2e65be.s3.amazonaws.com/84575398/131b7380-4751-11e9-8db3-7b96b6a634f3?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200124%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200124T173236Z&X-Amz-Expires=300&X-Amz-Signature=e0ee2c3252b2256873c6fdcc3a8ea60af62631043198dd1fab829808b6c0cc47&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dcni-plugins-amd64-v0.7.5.tgz&response-content-type=application%2Foctet-stream
Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.179.67
Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.179.67|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 17109361 (16M) [application/octet-stream]
Saving to: cni-plugins-amd64-v0.7.5.tgz

cni-plugins-amd64-v0.7.5.tgz      0%[                                                     ]       0  --.-KB/s               cni-plugins-amd64-v0.7.5.tgz      0%[                                                     ] 126.56K   609KB/s               cni-plugins-amd64-v0.7.5.tgz      6%[==>                                                  ]   1.12M  2.69MB/s               cni-plugins-amd64-v0.7.5.tgz     32%[================>                                    ]   5.24M  8.37MB/s               cni-plugins-amd64-v0.7.5.tgz     59%[==============================>                      ]   9.76M  11.7MB/s               cni-plugins-amd64-v0.7.5.tgz     87%[=============================================>       ]  14.28M  13.7MB/s               cni-plugins-amd64-v0.7.5.tgz    100%[====================================================>]  16.32M  14.6MB/s    in 1.1s    

2020-01-24 17:32:36 (14.6 MB/s) - cni-plugins-amd64-v0.7.5.tgz saved [17109361/17109361]

root@worker1:~/package# ls -l dd /opt/cni/bin/
drwxr-xr-x 2 root root 4096 Jan 24 17:20 /opt/cni/bin/
root@worker1:~/package# ls -l /opt/cni/bin/
total 0
root@worker1:~/package# tar -xzf cni-plugins-amd64-v0.7.5.tgz --directory /opt/cni/bin/
root@worker1:~/package# logout
Connection to worker1 closed.
root@master1:~/keys# 
root@master1:~/keys# 
root@master1:~/keys# 
root@master1:~/keys# cd pa../package/
root@master1:~/package# kubectl apply -f "https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\ n')"
serviceaccount/weave-net created
clusterrole.rbac.authorization.k8s.io/weave-net created
clusterrolebinding.rbac.authorization.k8s.io/weave-net created
role.rbac.authorization.k8s.io/weave-net created
rolebinding.rbac.authorization.k8s.io/weave-net created
daemonset.apps/weave-net created
root@master1:~/package# serviceaccount/weave-net created
-bash: serviceaccount/weave-net: No such file or directory
root@master1:~/package# clusterrole.rbac.authorization.k8s.io/weave-net created
-bash: clusterrole.rbac.authorization.k8s.io/weave-net: No such file or directory
root@master1:~/package# clusterrolebinding.rbac.authorization.k8s.io/weave-net created
-bash: clusterrolebinding.rbac.authorization.k8s.io/weave-net: No such file or directory
root@master1:~/package# role.rbac.authorization.k8s.io/weave-net created
-bash: role.rbac.authorization.k8s.io/weave-net: No such file or directory
root@master1:~/package# rolebinding.rbac.authorization.k8s.io/weave-net created
-bash: rolebinding.rbac.authorization.k8s.io/weave-net: No such file or directory
root@master1:~/package# daemonset.apps/weave-net created^C
root@master1:~/package# 
root@master1:~/package# rolebinding.rbac.authorization.k8s.io/weave-net createdclusterrolebindingserviceaccountkubectl apply -f "https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\nn')"root@master1:~/package# cd ../package/
ssh worker1kubectl get pods
No resources found.
root@master1:~/package# kubectl get podsnodes
NAME      STATUS     ROLES    AGE     VERSION
worker1   NotReady   <none>   7m54s   v1.13.0
root@master1:~/package# kubectl get nodes -o wide
NAME      STATUS     ROLES    AGE     VERSION   INTERNAL-IP      EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION   CONTAINER-RUNTIME
worker1   NotReady   <none>   7m57s   v1.13.0   172.31.122.147   <none>        Ubuntu 16.04.6 LTS   4.4.0-1099-aws   docker://19.3.5
root@master1:~/package# 
root@master1:~/package# 
root@master1:~/package# cd
root@master1:~# 
root@master1:~# ls -l /var/lib/kubernetes/
total 52
-rw-r--r-- 1 root root  989 Jan 24 17:05 ca.crt
-rw-r--r-- 1 root root 1679 Jan 24 17:05 ca.key
-rw-r--r-- 1 root root  240 Jan 24 17:05 encryption-config.yaml
-rw-r--r-- 1 root root 1078 Jan 24 17:05 etcd-server.crt
-rw-r--r-- 1 root root 1679 Jan 24 17:05 etcd-server.key
-rw-r--r-- 1 root root 1489 Jan 24 17:05 kube-apiserver.crt
-rw-r--r-- 1 root root 1675 Jan 24 17:05 kube-apiserver.key
-rw------- 1 root root 5289 Jan 24 17:11 kube-controller-manager.kubeconfig
-rw------- 1 root root 5259 Jan 24 17:12 kube-scheduler.kubeconfig
-rw-r--r-- 1 root root  993 Jan 24 17:05 service-account.crt
-rw-r--r-- 1 root root 1675 Jan 24 17:05 service-account.key
root@master1:~# cat > bootstrap-token-07401b.yaml <<EOF
> apiVersion: v1
> kind: Secret
> metadata:
>   # Name MUST be of form "bootstrap-token-<token id>"
>   name: bootstrap-token-07401b
>   namespace: kube-system
> 
> # Type MUST be 'bootstrap.kubernetes.io/token'
> type: bootstrap.kubernetes.io/token
> stringData:
>   # Human readable description. Optional.
>   description: "The default bootstrap token generated by 'kubeadm init'."
> 
>   # Token ID and secret. Required.
>   token-id: 07401b
>   token-secret: f395accd246ae52d
> 
>   # Expiration. Optional.
>   expiration: 2021-03-10T03:22:11Z
> 
>   # Allowed usages.
>   usage-bootstrap-authentication: "true"
>   usage-bootstrap-signing: "true"
> 
>   # Extra groups to authenticate the token as. Must start with "system:bootstrappers:"
>   auth-extra-groups: system:bootstrappers:worker
> EOF^C
root@master1:~# cd package/
root@master1:~/package# ls -l
total 322440
drwxr-xr-x 3 ubuntu ubuntu      4096 Jul 24  2018 etcd-v3.3.9-linux-amd64
-rw-r--r-- 1 root   root    11254519 Jul 24  2018 etcd-v3.3.9-linux-amd64.tar.gz
-rwxr-xr-x 1 root   root   138570976 Dec  3  2018 kube-apiserver
-rwxr-xr-x 1 root   root   103856032 Dec  3  2018 kube-controller-manager
-rwxr-xr-x 1 root   root    39214560 Dec  3  2018 kubectl
-rwxr-xr-x 1 root   root    37263616 Dec  3  2018 kube-scheduler
root@master1:~/package# cat > bootstrap-token-07401b.yaml <<EOF
> apiVersion: v1
> kind: Secret
> metadata:
>   # Name MUST be of form "bootstrap-token-<token id>"
>   name: bootstrap-token-07401b
>   namespace: kube-system
> 
> # Type MUST be 'bootstrap.kubernetes.io/token'
> type: bootstrap.kubernetes.io/token
> stringData:
>   # Human readable description. Optional.
>   description: "The default bootstrap token generated by 'kubeadm init'."
> 
>   # Token ID and secret. Required.
>   token-id: 07401b
>   token-secret: f395accd246ae52d
> 
>   # Expiration. Optional.
>   expiration: 2021-03-10T03:22:11Z
> 
>   # Allowed usages.
>   usage-bootstrap-authentication: "true"
>   usage-bootstrap-signing: "true"
> 
>   # Extra groups to authenticate the token as. Must start with "system:bootstrappers:"
>   auth-extra-groups: system:bootstrappers:worker
> EOF
root@master1:~/package# ls -l
total 322444
-rw-r--r-- 1 root   root         743 Jan 24 17:36 bootstrap-token-07401b.yaml
drwxr-xr-x 3 ubuntu ubuntu      4096 Jul 24  2018 etcd-v3.3.9-linux-amd64
-rw-r--r-- 1 root   root    11254519 Jul 24  2018 etcd-v3.3.9-linux-amd64.tar.gz
-rwxr-xr-x 1 root   root   138570976 Dec  3  2018 kube-apiserver
-rwxr-xr-x 1 root   root   103856032 Dec  3  2018 kube-controller-manager
-rwxr-xr-x 1 root   root    39214560 Dec  3  2018 kubectl
-rwxr-xr-x 1 root   root    37263616 Dec  3  2018 kube-scheduler
root@master1:~/package# kubectl create -f bootstrap-token-07401b.yaml
secret/bootstrap-token-07401b created
root@master1:~/package# kubectl create clusterrolebinding create-csrs-for-bootstrapping --clusterrole=system:node-bootstrappe r --group=system:bootstrappers
clusterrolebinding.rbac.authorization.k8s.io/create-csrs-for-bootstrapping created
root@master1:~/package# 
root@master1:~/package# kubectl create clusterrolebinding auto-approve-csrs-for-group --clusterrole=system:certificates.k8s.i o:certificatesigningrequests:nodeclient --group=system:bootstrappers
clusterrolebinding.rbac.authorization.k8s.io/auto-approve-csrs-for-group created
root@master1:~/package# 
root@master1:~/package# kubectl create clusterrolebinding auto-approve-renewals-for-nodes --clusterrole=system:certificates.k 8s.io:certificatesigningrequests:selfnodeclient --group=system:nodes
clusterrolebinding.rbac.authorization.k8s.io/auto-approve-renewals-for-nodes created
root@master1:~/package# 
root@master1:~/package# kubectl get nodes
NAME      STATUS     ROLES    AGE   VERSION
worker1   NotReady   <none>   12m   v1.13.0
root@master1:~/package# 
root@master1:~/package# 
root@master1:~/package# ssh master3
Welcome to Ubuntu 16.04.6 LTS (GNU/Linux 4.4.0-1099-aws x86_64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/advantage

 * Overheard at KubeCon: "microk8s.status just blew my mind".

     https://microk8s.io/docs/commands#microk8s.status

  Get cloud support with Ubuntu Advantage Cloud Guest:
    http://www.ubuntu.com/business/services/cloud

15 packages can be updated.
0 updates are security updates.

New release '18.04.3 LTS' available.
Run 'do-release-upgrade' to upgrade to it.


*** System restart required ***
Last login: Fri Jan 24 17:14:33 2020 from 172.31.122.25
root@master3:~# 
root@master3:~# cd package/
root@master3:~/package# l;sls -l
total 0
root@master3:~/package# wget -q --show-progress --https-only --timestamping \
>   https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kubectl \
>   https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kube-proxy \
>   https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kubelet
kubectl                           0%[                                                     ]       0  --.-KB/s               kubectl                          39%[====================>                                ]  14.87M  74.3MB/s               kubectl                          73%[=====================================>               ]  27.50M  68.5MB/s               kubectl                         100%[====================================================>]  37.40M  78.2MB/s    in 0.5s    
kube-proxy                        0%[                                                     ]       0  --.-KB/s               kube-proxy                       24%[===========>                                         ]   8.01M  39.5MB/s               kube-proxy                      100%[====================================================>]  33.19M  89.9MB/s    in 0.4s    
kubelet                           0%[                                                     ]       0  --.-KB/s               kubelet                          14%[======>                                              ]  16.01M  64.9MB/s               kubelet                          32%[================>                                    ]  35.14M  78.7MB/s               kubelet                          43%[======================>                              ]  47.35M  73.2MB/s               kubelet                          67%[==================================>                  ]  73.12M  86.4MB/s               kubelet                          87%[=============================================>       ]  94.59M  90.2MB/s               kubelet                         100%[====================================================>] 107.72M  95.9MB/s    in 1.1s    
root@master3:~/package# chmod +x kubectl kube-proxy kubelet
root@master3:~/package# cp kubectl kube-proxy kubelet /usr/local/bin/
root@master3:~/package# mkdir -p  /etc/cni/net.d   /opt/cni/bin   /var/lib/kubelet   /var/lib/kube-proxy   /var/lib/kubernete s   /var/run/kubernetes
root@master3:~/package# apt-get update
0% [Working]            Hit:1 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial InRelease
0% [Waiting for headers]                        Get:2 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial-updates InRelease [109 kB]
                        Get:3 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial-backports InRelease [107 kB]
0% [Waiting for headers]                        Get:4 http://security.ubuntu.com/ubuntu xenial-security InRelease [109 kB]
0% [1 InRelease gpgv 247 kB] [4 InRelease 14.0 kB/109 kB 13%]                                                             0% [4 InRelease 71.1 kB/109 kB 65%]0% [2 InRelease gpgv 109 kB] [4 InRelease 71.1 kB/109 kB 65%]                                                             0% [2 InRelease gpgv 109 kB]                            0% [Working]0% [3 InRelease gpgv 107 kB] [Waiting for headers]                                                  Get:5 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial-updates/main amd64 DEP-11 Metadata [322 kB]
0% [3 InRelease gpgv 107 kB] [5 Components-amd64 26.6 kB/322 kB 8%]                                                                   0% [3 InRelease gpgv 107 kB]                            Get:6 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial-updates/main DEP-11 64x64 Icons [241 kB]
0% [5 Components-amd64 store 0 B] [3 InRelease gpgv 107 kB] [6 icons-64x64 181 kB/241 kB 75%]                                                                                             0% [5 Components-amd64 store 0 B] [3 InRelease gpgv 107 kB]                                                           Get:7 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial-updates/universe amd64 DEP-11 Metadata [274 kB]
0% [5 Components-amd64 store 0 B] [3 InRelease gpgv 107 kB] [7 Components-amd64 0 B/274 kB 0%]                                                                                              0% [5 Components-amd64 store 0 B] [3 InRelease gpgv 107 kB]                                                           Get:8 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial-updates/universe DEP-11 64x64 Icons [411 kB]
0% [5 Components-amd64 store 0 B] [3 InRelease gpgv 107 kB] [8 icons-64x64 0 B/411 kB 0%]                                                                                         0% [5 Components-amd64 store 0 B] [3 InRelease gpgv 107 kB]                                                           Get:9 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial-updates/multiverse amd64 DEP-11 Metadata [5,968 B]
0% [5 Components-amd64 store 0 B] [3 InRelease gpgv 107 kB] [9 Components-amd64 0 B/5,968 B 0%]                                                                                               0% [5 Components-amd64 store 0 B] [3 InRelease gpgv 107 kB]                                                           Get:10 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial-updates/multiverse DEP-11 64x64 Icons [14.3 kB]
0% [5 Components-amd64 store 0 B] [3 InRelease gpgv 107 kB] [10 icons-64x64 0 B/14.3 kB 0%]                                                                                           0% [5 Components-amd64 store 0 B] [3 InRelease gpgv 107 kB]                                                           0% [5 Components-amd64 store 0 B]0% [5 Components-amd64 store 0 B] [4 InRelease gpgv 109 kB] [Waiting for headers]                                                                                 Get:11 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial-backports/main amd64 DEP-11 Metadata [3,324 B]
                                                                                 0% [5 Components-amd64 store 0 B] [4 InRelease gpgv 109 kB]                                                           Get:12 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial-backports/universe amd64 DEP-11 Metadata [5,324 B]
0% [5 Components-amd64 store 0 B] [4 InRelease gpgv 109 kB]                                                           0% [4 InRelease gpgv 109 kB]0% [6 icons-64x64 store 0 B] [4 InRelease gpgv 109 kB]                                                      0% [4 InRelease gpgv 109 kB]0% [7 Components-amd64 store 0 B] [4 InRelease gpgv 109 kB]                                                           79% [7 Components-amd64 store 0 B]                                  Get:13 http://security.ubuntu.com/ubuntu xenial-security/main amd64 DEP-11 Metadata [74.8 kB]
80% [7 Components-amd64 store 0 B] [13 Components-amd64 2,648 B/74.8 kB 4%]                                                                           82% [7 Components-amd64 store 0 B]                                  Get:14 http://security.ubuntu.com/ubuntu xenial-security/main DEP-11 64x64 Icons [83.8 kB]
82% [7 Components-amd64 store 0 B] [14 icons-64x64 0 B/83.8 kB 0%]                                                                  85% [14 icons-64x64 62.6 kB/83.8 kB 75%]85% [8 icons-64x64 store 0 B] [14 icons-64x64 62.6 kB/83.8 kB 75%]                                                                  86% [8 icons-64x64 store 0 B]                             Get:15 http://security.ubuntu.com/ubuntu xenial-security/universe amd64 DEP-11 Metadata [124 kB]
86% [8 icons-64x64 store 0 B] [15 Components-amd64 0 B/124 kB 0%]                                                                 88% [15 Components-amd64 54.3 kB/124 kB 44%]88% [9 Components-amd64 store 0 B] [15 Components-amd64 55.7 kB/124 kB 45%]                                                                           89% [15 Components-amd64 67.1 kB/124 kB 54%]89% [10 icons-64x64 store 0 B] [15 Components-amd64 72.9 kB/124 kB 59%]                                                                       89% [15 Components-amd64 75.7 kB/124 kB 61%]89% [11 Components-amd64 store 0 B] [15 Components-amd64 81.4 kB/124 kB 66%]                                                                            90% [15 Components-amd64 87.1 kB/124 kB 70%]90% [12 Components-amd64 store 0 B] [15 Components-amd64 90.0 kB/124 kB 73%]                                                                            91% [15 Components-amd64 101 kB/124 kB 82%]91% [13 Components-amd64 store 0 B] [15 Components-amd64 101 kB/124 kB 82%]                                                                           Get:16 http://security.ubuntu.com/ubuntu xenial-security/universe DEP-11 64x64 Icons [194 kB]
                                                                           92% [13 Components-amd64 store 0 B] [16 icons-64x64 5,779 B/194 kB 3%]                                                                      99% [13 Components-amd64 store 0 B]                                   Get:17 http://security.ubuntu.com/ubuntu xenial-security/multiverse amd64 DEP-11 Metadata [2,464 B]
99% [13 Components-amd64 store 0 B] [17 Components-amd64 0 B/2,464 B 0%]                                                                        99% [13 Components-amd64 store 0 B]                                   99% [Working]99% [14 icons-64x64 store 0 B]                              99% [Working]99% [15 Components-amd64 store 0 B]                                   100% [Working]100% [16 icons-64x64 store 0 B]                               100% [Working]100% [17 Components-amd64 store 0 B]                                    100% [Working]              Fetched 2,081 kB in 1s (1,781 kB/s)
Reading package lists... 0%Reading package lists... 0%Reading package lists... 1%Reading package lists... 6%Reading package lists... 6%Reading package lists... 9%Reading package lists... 9%Reading package lists... 9%Reading package lists... 9%Reading package lists... 9%Reading package lists... 9%Reading package lists... 44%Reading package lists... 44%Reading package lists... 59%Reading package lists... 64%Reading package lists... 64%Reading package lists... 64%Reading package lists... 64%Reading package lists... 65%Reading package lists... 65%Reading package lists... 71%Reading package lists... 71%Reading package lists... 77%Reading package lists... 77%Reading package lists... 77%Reading package lists... 77%Reading package lists... 77%Reading package lists... 77%Reading package lists... 81%Reading package lists... 81%Reading package lists... 83%Reading package lists... 83%Reading package lists... 84%Reading package lists... 84%Reading package lists... 84%Reading package lists... 84%Reading package lists... 84%Reading package lists... 84%Reading package lists... 84%Reading package lists... 84%Reading package lists... 84%Reading package lists... 84%Reading package lists... 84%Reading package lists... 84%Reading package lists... 88%Reading package lists... 88%Reading package lists... 93%Reading package lists... 93%Reading package lists... 93%Reading package lists... 93%Reading package lists... 93%Reading package lists... 93%Reading package lists... 96%Reading package lists... 96%Reading package lists... 98%Reading package lists... 98%Reading package lists... 98%Reading package lists... 98%Reading package lists... 98%Reading package lists... 98%Reading package lists... Done
root@master3:~/package# apt-get install     apt-transport-https     ca-certificates     curl     gnupg-agent     software-pro perties-common
Reading package lists... 0%Reading package lists... 100%Reading package lists... Done
Building dependency tree... 0%Building dependency tree... 0%Building dependency tree... 50%Building dependency tree... 50%Building dependency tree       
Reading state information... 0%Reading state information... 0%Reading state information... Done
apt-transport-https is already the newest version (1.2.32).
ca-certificates is already the newest version (20170717~16.04.2).
curl is already the newest version (7.47.0-1ubuntu2.14).
gnupg-agent is already the newest version (2.1.11-6ubuntu2.1).
gnupg-agent set to manually installed.
software-properties-common is already the newest version (0.96.20.9).
The following packages were automatically installed and are no longer required:
  linux-aws-headers-4.4.0-1095 linux-headers-4.4.0-1095-aws linux-headers-4.4.0-170 linux-headers-4.4.0-170-generic
  linux-image-4.4.0-1095-aws linux-image-4.4.0-170-generic linux-modules-4.4.0-1095-aws linux-modules-4.4.0-170-generic
Use 'apt autoremove' to remove them.
0 upgraded, 0 newly installed, 0 to remove and 15 not upgraded.
root@master3:~/package# curl -fsSL https://download.docker.com/linux/ubuntu/gpg | apt-key add -
OK
root@master3:~/package# apt-key fingerprint 0EBFCD88
pub   4096R/0EBFCD88 2017-02-22
      Key fingerprint = 9DC8 5822 9FC7 DD38 854A  E2D8 8D81 803C 0EBF CD88
uid                  Docker Release (CE deb) <docker@docker.com>
sub   4096R/F273FCD8 2017-02-22

root@master3:~/package# add-apt-repository    "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) 1 22     stable"

root@master3:~/package# apt-get update
0% [Working]            Hit:1 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial InRelease
0% [Connecting to security.ubuntu.com (2001:67c:1562::19)]                                                          Hit:2 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial-updates InRelease
                                                          Hit:3 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial-backports InRelease
0% [Connecting to security.ubuntu.com (2001:67c:1562::19)]0% [1 InRelease gpgv 247 kB] [Connecting to security.ubuntu.com (2001:67c:1562::19)]                                                                                    Get:4 https://download.docker.com/linux/ubuntu xenial InRelease [66.2 kB]
                                                                                    0% [1 InRelease gpgv 247 kB] [Waiting for headers] [4 InRelease 0 B/66.2 kB 0%]                                                                               0% [1 InRelease gpgv 247 kB] [Waiting for headers]                                                  Hit:5 http://security.ubuntu.com/ubuntu xenial-security InRelease
                                                  0% [1 InRelease gpgv 247 kB]                            0% [Working]0% [2 InRelease gpgv 109 kB]                            0% [Working]0% [3 InRelease gpgv 107 kB]                            0% [Working]0% [4 InRelease gpgv 66.2 kB]                             0% [Working]0% [5 InRelease gpgv 109 kB]                            Get:6 https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages [12.0 kB]
0% [5 InRelease gpgv 109 kB] [6 Packages 12.0 kB/12.0 kB 100%]                                                              0% [5 InRelease gpgv 109 kB]0% [6 Packages store 0 B] [5 InRelease gpgv 109 kB]                                                   0% [5 InRelease gpgv 109 kB]                            100% [Working]              Fetched 78.2 kB in 0s (100 kB/s)
Reading package lists... 0%Reading package lists... 0%Reading package lists... 1%Reading package lists... 6%Reading package lists... 6%Reading package lists... 9%Reading package lists... 9%Reading package lists... 9%Reading package lists... 9%Reading package lists... 9%Reading package lists... 9%Reading package lists... 42%Reading package lists... 44%Reading package lists... 44%Reading package lists... 64%Reading package lists... 64%Reading package lists... 64%Reading package lists... 64%Reading package lists... 65%Reading package lists... 65%Reading package lists... 71%Reading package lists... 71%Reading package lists... 77%Reading package lists... 77%Reading package lists... 77%Reading package lists... 77%Reading package lists... 77%Reading package lists... 77%Reading package lists... 81%Reading package lists... 81%Reading package lists... 83%Reading package lists... 83%Reading package lists... 83%Reading package lists... 83%Reading package lists... 84%Reading package lists... 84%Reading package lists... 84%Reading package lists... 84%Reading package lists... 84%Reading package lists... 84%Reading package lists... 84%Reading package lists... 84%Reading package lists... 84%Reading package lists... 84%Reading package lists... 88%Reading package lists... 88%Reading package lists... 93%Reading package lists... 93%Reading package lists... 93%Reading package lists... 93%Reading package lists... 93%Reading package lists... 93%Reading package lists... 96%Reading package lists... 96%Reading package lists... 98%Reading package lists... 98%Reading package lists... 98%Reading package lists... 98%Reading package lists... 98%Reading package lists... 98%Reading package lists... 98%Reading package lists... 98%Reading package lists... Done
root@master3:~/package# apt-get install docker-ce docker-ce-cli containerd.io
Reading package lists... 0%Reading package lists... 100%Reading package lists... Done
Building dependency tree... 0%Building dependency tree... 0%Building dependency tree... 50%Building dependency tree... 50%Building dependency tree       
Reading state information... 0%Reading state information... 0%Reading state information... Done
The following packages were automatically installed and are no longer required:
  linux-aws-headers-4.4.0-1095 linux-headers-4.4.0-1095-aws linux-headers-4.4.0-170 linux-headers-4.4.0-170-generic
  linux-image-4.4.0-1095-aws linux-image-4.4.0-170-generic linux-modules-4.4.0-1095-aws linux-modules-4.4.0-170-generic
Use 'apt autoremove' to remove them.
The following additional packages will be installed:
  aufs-tools cgroupfs-mount pigz
The following NEW packages will be installed:
  aufs-tools cgroupfs-mount containerd.io docker-ce docker-ce-cli pigz
0 upgraded, 6 newly installed, 0 to remove and 15 not upgraded.
Need to get 85.3 MB of archives.
After this operation, 384 MB of additional disk space will be used.
Do you want to continue? [Y/n] y
0% [Working]            Get:1 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial/universe amd64 pigz amd64 2.3.1-2 [61.1 kB]
0% [1 pigz 14.1 kB/61.1 kB 23%]                               3% [Working]            Get:2 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial/universe amd64 aufs-tools amd64 1:3.2+20130722-1.1ubuntu1 [92.9 kB]
3% [2 aufs-tools 0 B/92.9 kB 0%]                                7% [Working]            Get:3 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial/universe amd64 cgroupfs-mount all 1.2 [4,970 B]
7% [3 cgroupfs-mount 0 B/4,970 B 0%]                                    10% [Working]             Get:4 https://download.docker.com/linux/ubuntu xenial/stable amd64 containerd.io amd64 1.2.10-3 [19.9 MB]
10% [4 containerd.io 0 B/19.9 MB 0%]24% [4 containerd.io 14.7 MB/19.9 MB 74%]                                         32% [Working]             Get:5 https://download.docker.com/linux/ubuntu xenial/stable amd64 docker-ce-cli amd64 5:19.03.5~3-0~ubuntu-xenial [42.4 MB]
32% [5 docker-ce-cli 16.4 kB/42.4 MB 0%]46% [5 docker-ce-cli 14.8 MB/42.4 MB 35%]72% [5 docker-ce-cli 42.4 MB/42.4 MB 100%]                                          75% [Working]             Get:6 https://download.docker.com/linux/ubuntu xenial/stable amd64 docker-ce amd64 5:19.03.5~3-0~ubuntu-xenial [22.8 MB]
75% [6 docker-ce 15.9 kB/22.8 MB 0%]                                    100% [Working]              Fetched 85.3 MB in 2s (34.8 MB/s)
Selecting previously unselected package pigz.
(Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 303104 files and directories currently installed.)
Preparing to unpack .../pigz_2.3.1-2_amd64.deb ...
Unpacking pigz (2.3.1-2) ...
Selecting previously unselected package aufs-tools.
Preparing to unpack .../aufs-tools_1%3a3.2+20130722-1.1ubuntu1_amd64.deb ...
Unpacking aufs-tools (1:3.2+20130722-1.1ubuntu1) ...
Selecting previously unselected package cgroupfs-mount.
Preparing to unpack .../cgroupfs-mount_1.2_all.deb ...
Unpacking cgroupfs-mount (1.2) ...
Selecting previously unselected package containerd.io.
Preparing to unpack .../containerd.io_1.2.10-3_amd64.deb ...
Unpacking containerd.io (1.2.10-3) ...
Selecting previously unselected package docker-ce-cli.
Preparing to unpack .../docker-ce-cli_5%3a19.03.5~3-0~ubuntu-xenial_amd64.deb ...
Unpacking docker-ce-cli (5:19.03.5~3-0~ubuntu-xenial) ...
Selecting previously unselected package docker-ce.
Preparing to unpack .../docker-ce_5%3a19.03.5~3-0~ubuntu-xenial_amd64.deb ...
Unpacking docker-ce (5:19.03.5~3-0~ubuntu-xenial) ...
Processing triggers for man-db (2.7.5-1) ...
Processing triggers for libc-bin (2.23-0ubuntu11) ...
Processing triggers for ureadahead (0.100.0-19.1) ...
Processing triggers for systemd (229-4ubuntu21.22) ...
Setting up pigz (2.3.1-2) ...
Setting up aufs-tools (1:3.2+20130722-1.1ubuntu1) ...
Setting up cgroupfs-mount (1.2) ...
Setting up containerd.io (1.2.10-3) ...
Setting up docker-ce-cli (5:19.03.5~3-0~ubuntu-xenial) ...
Setting up docker-ce (5:19.03.5~3-0~ubuntu-xenial) ...
Processing triggers for libc-bin (2.23-0ubuntu11) ...
Processing triggers for systemd (229-4ubuntu21.22) ...
Processing triggers for ureadahead (0.100.0-19.1) ...
root@master3:~/package# kubectl config --kubeconfig=/var/lib/kubelet/bootstrap-kubeconfig set-cluster bootstrap --server='htt ps://172.31.123.142:6443' --certificate-authority=/var/lib/kubernetes/ca.crt
Cluster "bootstrap" set.
root@master3:~/package# ls- l /var/lib/kubelet/bootstrap-kubeconfigls -l /var/lib/kubelet/bootstrap-kubeconfig
-rw------- 1 root root 220 Jan 24 17:41 /var/lib/kubelet/bootstrap-kubeconfig
root@master3:~/package# 
root@master3:~/package# kubectl config --kubeconfig=/var/lib/kubelet/bootstrap-kubeconfig set-credentials kubelet-bootstrap - -token=07401b.f395accd246ae52d
User "kubelet-bootstrap" set.
root@master3:~/package# kubectl config --kubeconfig=/var/lib/kubelet/bootstrap-kubeconfig set-context bootstrap --user=kubele t-bootstrap --cluster=bootstrap
Context "bootstrap" created.
root@master3:~/package# kubectl config --kubeconfig=/var/lib/kubelet/bootstrap-kubeconfig use-context bootstrap
Switched to context "bootstrap".
root@master3:~/package# systemctl status systemd-resolved.service
 systemd-resolved.service - Network Name Resolution
   Loaded: loaded (/lib/systemd/system/systemd-resolved.service; disabled; vendor preset: enabled)
  Drop-In: /lib/systemd/system/systemd-resolved.service.d
           resolvconf.conf
   Active: inactive (dead)
     Docs: man:systemd-resolved.service(8)
root@master3:~/package# systemctl start systemd-resolved.service
root@master3:~/package# systemctl enable systemd-resolved.service
Created symlink from /etc/systemd/system/multi-user.target.wants/systemd-resolved.service to /lib/systemd/system/systemd-resolved.service.
root@master3:~/package# systemctl enable systemd-resolved.servicestarttus
 systemd-resolved.service - Network Name Resolution
   Loaded: loaded (/lib/systemd/system/systemd-resolved.service; enabled; vendor preset: enabled)
  Drop-In: /lib/systemd/system/systemd-resolved.service.d
           resolvconf.conf
   Active: active (running) since Fri 2020-01-24 17:42:28 UTC; 9s ago
     Docs: man:systemd-resolved.service(8)
 Main PID: 899 (systemd-resolve)
   Status: "Processing requests..."
   CGroup: /system.slice/systemd-resolved.service
           899 /lib/systemd/systemd-resolved

Jan 24 17:42:28 master3 systemd[1]: Starting Network Name Resolution...
Jan 24 17:42:28 master3 systemd-resolved[899]: Positive Trust Anchors:
Jan 24 17:42:28 master3 systemd-resolved[899]: . IN DS    19036 8 2 49aac11d7b6f6446702e54a1607371607a1a41855200fd2ce1cdde32f
Jan 24 17:42:28 master3 systemd-resolved[899]: Negative trust anchors: 10.in-addr.arpa 16.172.in-addr.arpa 17.172.in-addr.arp
Jan 24 17:42:28 master3 systemd-resolved[899]: Using system hostname 'master3'.
Jan 24 17:42:28 master3 systemd-resolved[899]: Switching to system DNS server 172.31.0.2.
Jan 24 17:42:28 master3 systemd[1]: Started Network Name Resolution.
lines 1-18/18 (END)lines 1-18/18 (END)root@master3:~/package# 
root@master3:~/package# cat <<EOF | sudo tee /var/lib/kubelet/kubelet-config.yaml
> kind: KubeletConfiguration
> apiVersion: kubelet.config.k8s.io/v1beta1
> authentication:
>   anonymous:
>     enabled: false
>   webhook:
>     enabled: true
>   x509:
>     clientCAFile: "/var/lib/kubernetes/ca.crt"
> authorization:
>   mode: Webhook
> clusterDomain: "cluster.local"
> clusterDNS:
>   - "10.96.0.10"
> resolvConf: "/run/systemd/resolve/resolv.conf"
> runtimeRequestTimeout: "15m"
> EOF
kind: KubeletConfiguration
apiVersion: kubelet.config.k8s.io/v1beta1
authentication:
  anonymous:
    enabled: false
  webhook:
    enabled: true
  x509:
    clientCAFile: "/var/lib/kubernetes/ca.crt"
authorization:
  mode: Webhook
clusterDomain: "cluster.local"
clusterDNS:
  - "10.96.0.10"
resolvConf: "/run/systemd/resolve/resolv.conf"
runtimeRequestTimeout: "15m"
root@master3:~/package# 
root@master3:~/package# 
root@master3:~/package# cat <<EOF | sudo tee /etc/systemd/system/kubelet.service
> [Unit]
> Description=Kubernetes Kubelet
> Documentation=https://github.com/kubernetes/kubernetes
> After=docker.service
> Requires=docker.service
> 
> [Service]
> ExecStart=/usr/local/bin/kubelet \\
>   --bootstrap-kubeconfig="/var/lib/kubelet/bootstrap-kubeconfig" \\
>   --config=/var/lib/kubelet/kubelet-config.yaml \\
>   --image-pull-progress-deadline=2m \\
>   --kubeconfig=/var/lib/kubelet/kubeconfig \\
>   --cert-dir=/var/lib/kubelet/pki/ \\
>   --rotate-certificates=true \\
>   --rotate-server-certificates=true \\
>   --network-plugin=cni \\
>   --register-node=true \\
>   --v=2
> Restart=on-failure
> RestartSec=5
> 
> [Install]
> WantedBy=multi-user.target
> EOF
[Unit]
Description=Kubernetes Kubelet
Documentation=https://github.com/kubernetes/kubernetes
After=docker.service
Requires=docker.service

[Service]
ExecStart=/usr/local/bin/kubelet \
  --bootstrap-kubeconfig="/var/lib/kubelet/bootstrap-kubeconfig" \
  --config=/var/lib/kubelet/kubelet-config.yaml \
  --image-pull-progress-deadline=2m \
  --kubeconfig=/var/lib/kubelet/kubeconfig \
  --cert-dir=/var/lib/kubelet/pki/ \
  --rotate-certificates=true \
  --rotate-server-certificates=true \
  --network-plugin=cni \
  --register-node=true \
  --v=2
Restart=on-failure
RestartSec=5

[Install]
WantedBy=multi-user.target
root@master3:~/package# 
root@master3:~/package# 
root@master3:~/package# scp -r rameshhms1c.mylabserver.com:/root/keys/kube-proxy.kubeconfig /var/lib/kube-proxy/kubeconfig
The authenticity of host 'rameshhms1c.mylabserver.com (52.88.164.193)' can't be established.
ECDSA key fingerprint is SHA256:ign2aYXHCLv1vVIHtJ47ngf+PZlmZdUDexkYCmS2NUs.
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added 'rameshhms1c.mylabserver.com,52.88.164.193' (ECDSA) to the list of known hosts.
kube-proxy.kubeconfig                                                                        0%    0     0.0KB/s   --:-- ETAkube-proxy.kubeconfig                                                                      100% 5248     5.1KB/s   00:00    
root@master3:~/package# ls -l /var/lib/kube-proxy/kubeconfig
-rw------- 1 root root 5248 Jan 24 17:43 /var/lib/kube-proxy/kubeconfig
root@master3:~/package# ls -l /var/lib/kube-proxy/kubeconfig\xy/
total 8
-rw------- 1 root root 5248 Jan 24 17:43 kubeconfig
root@master3:~/package# 
root@master3:~/package# 
root@master3:~/package# cat <<EOF | sudo tee /var/lib/kube-proxy/kube-proxy-config.yaml
> kind: KubeProxyConfiguration
> apiVersion: kubeproxy.config.k8s.io/v1alpha1
> clientConnection:
>   kubeconfig: "/var/lib/kube-proxy/kubeconfig"
> mode: "iptables"
> clusterCIDR: "172.31.0.0/20"
> EOF
kind: KubeProxyConfiguration
apiVersion: kubeproxy.config.k8s.io/v1alpha1
clientConnection:
  kubeconfig: "/var/lib/kube-proxy/kubeconfig"
mode: "iptables"
clusterCIDR: "172.31.0.0/20"
root@master3:~/package# cat <<EOF | sudo tee /etc/systemd/system/kube-proxy.service
> [Unit]
> Description=Kubernetes Kube Proxy
> Documentation=https://github.com/kubernetes/kubernetes
> 
> [Service]
> ExecStart=/usr/local/bin/kube-proxy \\
>   --config=/var/lib/kube-proxy/kube-proxy-config.yaml
> Restart=on-failure
> RestartSec=5
> 
> [Install]
> WantedBy=multi-user.target
> EOF
[Unit]
Description=Kubernetes Kube Proxy
Documentation=https://github.com/kubernetes/kubernetes

[Service]
ExecStart=/usr/local/bin/kube-proxy \
  --config=/var/lib/kube-proxy/kube-proxy-config.yaml
Restart=on-failure
RestartSec=5

[Install]
WantedBy=multi-user.target
root@master3:~/package# 
root@master3:~/package# ls -l /var/lib/kube-proxy/kube-proxy-config.yaml
-rw-r--r-- 1 root root 185 Jan 24 17:44 /var/lib/kube-proxy/kube-proxy-config.yaml
root@master3:~/package# 
root@master3:~/package# wget https://github.com/containernetworking/plugins/releases/download/v0.7.5/cni-plugins-amd64-v0.7.5 .tgz
--2020-01-24 17:44:42--  https://github.com/containernetworking/plugins/releases/download/v0.7.5/cni-plugins-amd64-v0.7.5.tgz
Resolving github.com (github.com)... 192.30.255.113
Connecting to github.com (github.com)|192.30.255.113|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/84575398/131b7380-4751-11e9-8db3-7b96b6a634f3?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200124%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200124T174442Z&X-Amz-Expires=300&X-Amz-Signature=69629fc61ec748c238fa6b97960b1edff8be301a506c0bcdbb7883cb0664c6f8&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dcni-plugins-amd64-v0.7.5.tgz&response-content-type=application%2Foctet-stream [following]
--2020-01-24 17:44:42--  https://github-production-release-asset-2e65be.s3.amazonaws.com/84575398/131b7380-4751-11e9-8db3-7b96b6a634f3?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200124%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200124T174442Z&X-Amz-Expires=300&X-Amz-Signature=69629fc61ec748c238fa6b97960b1edff8be301a506c0bcdbb7883cb0664c6f8&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dcni-plugins-amd64-v0.7.5.tgz&response-content-type=application%2Foctet-stream
Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.110.19
Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.110.19|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 17109361 (16M) [application/octet-stream]
Saving to: cni-plugins-amd64-v0.7.5.tgz

cni-plugins-amd64-v0.7.5.tgz      0%[                                                     ]       0  --.-KB/s               cni-plugins-amd64-v0.7.5.tgz      0%[                                                     ] 126.56K   549KB/s               cni-plugins-amd64-v0.7.5.tgz      6%[==>                                                  ]   1.12M  2.44MB/s               cni-plugins-amd64-v0.7.5.tgz     32%[================>                                    ]   5.25M  7.66MB/s               cni-plugins-amd64-v0.7.5.tgz     59%[==============================>                      ]   9.75M  10.7MB/s               cni-plugins-amd64-v0.7.5.tgz     87%[=============================================>       ]  14.25M  12.5MB/s               cni-plugins-amd64-v0.7.5.tgz    100%[====================================================>]  16.32M  13.3MB/s    in 1.2s    

2020-01-24 17:44:44 (13.3 MB/s) - cni-plugins-amd64-v0.7.5.tgz saved [17109361/17109361]

root@master3:~/package# tar -xzf cni-plugins-amd64-v0.7.5.tgz --directory /opt/cni/bin/
root@master3:~/package# systemctl daemon-reload
root@master3:~/package# systemctl status kubelet kube-proxy
 kubelet.service - Kubernetes Kubelet
   Loaded: loaded (/etc/systemd/system/kubelet.service; disabled; vendor preset: enabled)
   Active: inactive (dead)
     Docs: https://github.com/kubernetes/kubernetes

 kube-proxy.service - Kubernetes Kube Proxy
   Loaded: loaded (/etc/systemd/system/kube-proxy.service; disabled; vendor preset: enabled)
   Active: inactive (dead)
     Docs: https://github.com/kubernetes/kubernetes
root@master3:~/package# 
root@master3:~/package# 
root@master3:~/package# systemctl enable kubelet kube-proxy
Created symlink from /etc/systemd/system/multi-user.target.wants/kubelet.service to /etc/systemd/system/kubelet.service.
Created symlink from /etc/systemd/system/multi-user.target.wants/kube-proxy.service to /etc/systemd/system/kube-proxy.service.
root@master3:~/package# systemctl start kubelet kube-proxy
root@master3:~/package# systemctl start kubelet kube-proxyenable
root@master3:~/package# systemctl enable kubelet kube-proxystartenablestatus
 kubelet.service - Kubernetes Kubelet
   Loaded: loaded (/etc/systemd/system/kubelet.service; enabled; vendor preset: enabled)
   Active: active (running) since Fri 2020-01-24 17:45:13 UTC; 5s ago
     Docs: https://github.com/kubernetes/kubernetes
 Main PID: 1012 (kubelet)
    Tasks: 14
   Memory: 87.2M
      CPU: 627ms
   CGroup: /system.slice/kubelet.service
           1012 /usr/local/bin/kubelet --bootstrap-kubeconfig=/var/lib/kubelet/bootstrap-kubeconfig --config=/var/lib/kubel

Jan 24 17:45:18 master3 kubelet[1012]: I0124 17:45:18.678430    1012 reconciler.go:252] operationExecutor.MountVolume started
Jan 24 17:45:18 master3 kubelet[1012]: I0124 17:45:18.678502    1012 operation_generator.go:567] MountVolume.SetUp succeeded 
Jan 24 17:45:18 master3 kubelet[1012]: I0124 17:45:18.678530    1012 operation_generator.go:567] MountVolume.SetUp succeeded 
Jan 24 17:45:18 master3 kubelet[1012]: I0124 17:45:18.678554    1012 operation_generator.go:567] MountVolume.SetUp succeeded 
Jan 24 17:45:18 master3 kubelet[1012]: I0124 17:45:18.678621    1012 operation_generator.go:567] MountVolume.SetUp succeeded 
Jan 24 17:45:18 master3 kubelet[1012]: I0124 17:45:18.678754    1012 operation_generator.go:567] MountVolume.SetUp succeeded 
Jan 24 17:45:18 master3 kubelet[1012]: I0124 17:45:18.678786    1012 operation_generator.go:567] MountVolume.SetUp succeeded 
Jan 24 17:45:18 master3 kubelet[1012]: I0124 17:45:18.700087    1012 operation_generator.go:567] MountVolume.SetUp succeeded 
Jan 24 17:45:18 master3 kubelet[1012]: I0124 17:45:18.844828    1012 kuberuntime_manager.go:397] No sandbox for pod "weave-ne
Jan 24 17:45:18 master3 kubelet[1012]: I0124 17:45:18.853286    1012 provider.go:116] Refreshing cache for provider: *credent

 kube-proxy.service - Kubernetes Kube Proxy
   Loaded: loaded (/etc/systemd/system/kube-proxy.service; enabled; vendor preset: enabled)
   Active: active (running) since Fri 2020-01-24 17:45:13 UTC; 5s ago
     Docs: https://github.com/kubernetes/kubernetes
 Main PID: 1014 (kube-proxy)
    Tasks: 0
   Memory: 30.5M
      CPU: 245ms
   CGroup: /system.slice/kube-proxy.service
            1014 /usr/local/bin/kube-proxy --config=/var/lib/kube-proxy/kube-proxy-config.yaml

Jan 24 17:45:15 master3 kube-proxy[1014]: I0124 17:45:15.655443    1014 conntrack.go:52] Setting nf_conntrack_max to 131072
Jan 24 17:45:15 master3 kube-proxy[1014]: I0124 17:45:15.702929    1014 conntrack.go:83] Setting conntrack hashsize to 32768
Jan 24 17:45:15 master3 kube-proxy[1014]: I0124 17:45:15.703170    1014 conntrack.go:100] Set sysctl 'net/netfilter/nf_conntr
Jan 24 17:45:15 master3 kube-proxy[1014]: I0124 17:45:15.703208    1014 conntrack.go:100] Set sysctl 'net/netfilter/nf_conntr
Jan 24 17:45:15 master3 kube-proxy[1014]: I0124 17:45:15.703465    1014 config.go:102] Starting endpoints config controller
Jan 24 17:45:15 master3 kube-proxy[1014]: I0124 17:45:15.703477    1014 controller_utils.go:1027] Waiting for caches to sync 
Jan 24 17:45:15 master3 kube-proxy[1014]: I0124 17:45:15.703500    1014 config.go:202] Starting service config controller
Jan 24 17:45:15 master3 kube-proxy[1014]: I0124 17:45:15.703513    1014 controller_utils.go:1027] Waiting for caches to sync 
Jan 24 17:45:15 master3 kube-proxy[1014]: I0124 17:45:15.903876    1014 controller_utils.go:1034] Caches are synced for servi
Jan 24 17:45:15 master3 kube-proxy[1014]: I0124 17:45:15.903964    1014 controller_utils.go:1034] Caches are synced for endpo
lines 1-43lines 1-43/43 (END)root@master3:~/package# kubectl get nodes
NAME      STATUS     ROLES    AGE   VERSION
master3   Ready      <none>   14s   v1.13.0
worker1   NotReady   <none>   19m   v1.13.0
root@master3:~/package# logout
Connection to master3 closed.
root@master1:~/package# 
root@master1:~/package# kubectl get csr
NAME                                                   AGE   REQUESTOR                 CONDITION
csr-fmgxr                                              20s   system:node:master3       Pending
node-csr-LxL5nLHUWv3pko4ERDg3me--iqykz9kEtpotZ9JcKRg   22s   system:bootstrap:07401b   Approved,Issued
root@master1:~/package# 
root@master1:~/package# 
root@master1:~/package# kubectl certificate approve csr-fmgxr
certificatesigningrequest.certificates.k8s.io/csr-fmgxr approved
root@master1:~/package# kubectl get csr
NAME                                                   AGE   REQUESTOR                 CONDITION
csr-fmgxr                                              35s   system:node:master3       Approved,Issued
node-csr-LxL5nLHUWv3pko4ERDg3me--iqykz9kEtpotZ9JcKRg   37s   system:bootstrap:07401b   Approved,Issued
root@master1:~/package# kubectl get nodes
NAME      STATUS     ROLES    AGE   VERSION
master3   Ready      <none>   40s   v1.13.0
worker1   NotReady   <none>   19m   v1.13.0
root@master1:~/package# cd
root@master1:~# 
root@master1:~# ssh worker1
Welcome to Ubuntu 16.04.6 LTS (GNU/Linux 4.4.0-1099-aws x86_64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/advantage

 * Overheard at KubeCon: "microk8s.status just blew my mind".

     https://microk8s.io/docs/commands#microk8s.status

  Get cloud support with Ubuntu Advantage Cloud Guest:
    http://www.ubuntu.com/business/services/cloud

15 packages can be updated.
0 updates are security updates.

New release '18.04.3 LTS' available.
Run 'do-release-upgrade' to upgrade to it.


*** System restart required ***
Last login: Fri Jan 24 17:32:27 2020 from 172.31.122.25
root@worker1:~# tar -xzf cni-plugins-amd64-v0.7.5.tgz --directory /opt/cni/bin/ls -l /opt/cni/bin/d /opt/cni/bin/wget https://github.com/containernetworking/plugins/releases/download/v0.7.5/cni-plugins-amd64-v0.7.5.tgzcd package/at /etc/hostssystemctl status systemd-resolved.servicekubectl get nodes --kubeconfig admin.kubeconfigsystemctl status kubelet kube-proxykubectl get nodes --kubeconfig admin.kubeconfigls -lcd keys/ls -lkubectl get nodes --kubeconfig admin.kubeconfigsystemctl status kubelet kube-proxyrtenablestartre
root@worker1:~# systemctl restart kubelet kube-proxydsstatus
 kubelet.service - Kubernetes Kubelet
   Loaded: loaded (/etc/systemd/system/kubelet.service; enabled; vendor preset: enabled)
   Active: active (running) since Fri 2020-01-24 17:46:24 UTC; 5s ago
     Docs: https://github.com/kubernetes/kubernetes
 Main PID: 5941 (kubelet)
    Tasks: 14
   Memory: 21.5M
      CPU: 411ms
   CGroup: /system.slice/kubelet.service
           5941 /usr/local/bin/kubelet --config=/var/lib/kubelet/kubelet-config.yaml --image-pull-progress-deadline=2m --ku

Jan 24 17:46:25 worker1 kubelet[5941]: I0124 17:46:25.662667    5941 operation_generator.go:567] MountVolume.SetUp succeeded 
Jan 24 17:46:25 worker1 kubelet[5941]: I0124 17:46:25.662686    5941 operation_generator.go:567] MountVolume.SetUp succeeded 
Jan 24 17:46:25 worker1 kubelet[5941]: I0124 17:46:25.662703    5941 operation_generator.go:567] MountVolume.SetUp succeeded 
Jan 24 17:46:25 worker1 kubelet[5941]: I0124 17:46:25.662722    5941 operation_generator.go:567] MountVolume.SetUp succeeded 
Jan 24 17:46:25 worker1 kubelet[5941]: I0124 17:46:25.765282    5941 kuberuntime_manager.go:397] No sandbox for pod "weave-ne
Jan 24 17:46:25 worker1 kubelet[5941]: E0124 17:46:25.765378    5941 kuberuntime_sandbox.go:41] GeneratePodSandboxConfig for 
Jan 24 17:46:25 worker1 kubelet[5941]: E0124 17:46:25.765394    5941 kuberuntime_manager.go:662] createPodSandbox for pod "we
Jan 24 17:46:25 worker1 kubelet[5941]: E0124 17:46:25.765481    5941 pod_workers.go:190] Error syncing pod adaf478c-3ecf-11ea
Jan 24 17:46:30 worker1 kubelet[5941]: W0124 17:46:30.302095    5941 cni.go:203] Unable to update cni config: No networks fou
Jan 24 17:46:30 worker1 kubelet[5941]: E0124 17:46:30.302263    5941 kubelet.go:2192] Container runtime network not ready: Ne

 kube-proxy.service - Kubernetes Kube Proxy
   Loaded: loaded (/etc/systemd/system/kube-proxy.service; enabled; vendor preset: enabled)
   Active: active (running) since Fri 2020-01-24 17:46:24 UTC; 5s ago
     Docs: https://github.com/kubernetes/kubernetes
 Main PID: 5934 (kube-proxy)
    Tasks: 0
   Memory: 7.1M
      CPU: 102ms
   CGroup: /system.slice/kube-proxy.service
            5934 /usr/local/bin/kube-proxy --config=/var/lib/kube-proxy/kube-proxy-config.yaml

Jan 24 17:46:24 worker1 kube-proxy[5934]: I0124 17:46:24.953733    5934 server_others.go:148] Using iptables Proxier.
Jan 24 17:46:24 worker1 kube-proxy[5934]: I0124 17:46:24.955170    5934 server_others.go:178] Tearing down inactive rules.
Jan 24 17:46:24 worker1 kube-proxy[5934]: I0124 17:46:24.980284    5934 server.go:464] Version: v1.13.0
Jan 24 17:46:25 worker1 kube-proxy[5934]: I0124 17:46:24.996559    5934 conntrack.go:52] Setting nf_conntrack_max to 131072
Jan 24 17:46:25 worker1 kube-proxy[5934]: I0124 17:46:24.996759    5934 config.go:102] Starting endpoints config controller
Jan 24 17:46:25 worker1 kube-proxy[5934]: I0124 17:46:24.996770    5934 controller_utils.go:1027] Waiting for caches to sync 
Jan 24 17:46:25 worker1 kube-proxy[5934]: I0124 17:46:24.996791    5934 config.go:202] Starting service config controller
Jan 24 17:46:25 worker1 kube-proxy[5934]: I0124 17:46:24.996797    5934 controller_utils.go:1027] Waiting for caches to sync 
Jan 24 17:46:25 worker1 kube-proxy[5934]: I0124 17:46:25.096901    5934 controller_utils.go:1034] Caches are synced for endpo
Jan 24 17:46:25 worker1 kube-proxy[5934]: I0124 17:46:25.097000    5934 controller_utils.go:1034] Caches are synced for servi
lines 1-43lines 1-43/43 (END)root@worker1:~# systemctl status kubelet kube-proxyrestartstatuskuebctl get pods
kuebctl: command not found
root@worker1:~# kubectl get pods
The connection to the server localhost:8080 was refused - did you specify the right host or port?
root@worker1:~# logout
Connection to worker1 closed.
root@master1:~# kubectl get pods
No resources found.
root@master1:~# kubectl get podsnodes
NAME      STATUS     ROLES    AGE   VERSION
master3   Ready      <none>   93s   v1.13.0
worker1   NotReady   <none>   20m   v1.13.0
root@master1:~# 
root@master1:~# 
root@master1:~# 
root@master1:~# 
root@master1:~# 
root@master1:~# 
root@master1:~# 