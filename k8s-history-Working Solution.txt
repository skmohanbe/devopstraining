    1  passwd root
    2  sed -i 's/PermitRootLogin without-password/PermitRootLogin yes/' /etc/ssh/sshd_config
    3  systemctl restart sshd
    4  ssh 172.31.24.188
    5  ssh 172.31.24.188 -l cloud_user
    6  sudo hostnamectl set-hostname master1
    7  pwd
    8  id
    9  ssh-keygen -i rsa -b 2048
   10  ssh-keygen -t rsa -b 2048
   11  ls -la
   12  vi /etc/hosts
   13  cat /etc/host
   14  cat /etc/hosts
   15  cd .ssh/
   16  ls -la
   17  for i in master1 master2 master3 worker1 worker2 loadbalancer;do  ssh-copy-id -i $i;done
   18  ssh worker1
   19  cat /etc/resolv.conf
   20  for i in master1 master2 master3 worker1 worker2 loadbalancer;do  ssh $i sysctl net.bridge.bridge-nf-call-iptables=1;done
   21  sysctl net.bridge.bridge-nf-call-iptables=1
   22  sysctl -w net.bridge.bridge-nf-call-iptables=1
   23  sysctl -a | grep -i net.bridge.bridge-nf-call-iptables
   24  sysctl -a | grep -i net.bridge.bridge
   25  cat /etc/sysctl.conf
   26  sysctl -a | grep -i bridge
   27  sysctl -a
   28  vi /etc/sysctl.conf
   29  sysctl -p
   30  vi /etc/sysctl.conf
   31  cd /proc/sys/net/
   32  ls -l
   33  cd
   34  openssl
   35  mkdir packages
   36  cd packages/
   37  wget https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kubectl
   38  chmod +x kubectl
   39  mv kubectl /usr/local/bin/
   40  kubectl version --client
   41  cd
   42  mkdir keys
   43  cd keys/
   44  ls -l
   45  openssl genrsa -out ca.key 2048
   46  openssl req -new -key ca.key -subj "/CN=KUBERNETES-CA" -out ca.csr
   47  openssl x509 -req -in ca.csr -signkey ca.key -CAcreateserial  -out ca.crt -days 1000
   48  ls -l
   49  openssl genrsa -out admin.key 2048
   50  openssl req -new -key admin.key -subj "/CN=admin/O=system:masters" -out admin.csr
   51  openssl x509 -req -in admin.csr -CA ca.crt -CAkey ca.key -CAcreateserial  -out admin.crt -days 1000
   52  ls -l
   53  openssl genrsa -out kube-controller-manager.key 2048
   54  openssl req -new -key kube-controller-manager.key -subj "/CN=system:kube-controller-manager" -out kube-controller-manager.csr
   55  openssl x509 -req -in kube-controller-manager.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out kube-controller-manager.crt -days 1000
   56  openssl genrsa -out kube-proxy.key 2048
   57  openssl req -new -key kube-proxy.key -subj "/CN=system:kube-proxy" -out kube-proxy.csr
   58  openssl x509 -req -in kube-proxy.csr -CA ca.crt -CAkey ca.key -CAcreateserial  -out kube-proxy.crt -days 1000
   59  openssl genrsa -out kube-scheduler.key 2048
   60  openssl req -new -key kube-scheduler.key -subj "/CN=system:kube-scheduler" -out kube-scheduler.csr
   61  openssl x509 -req -in kube-scheduler.csr -CA ca.crt -CAkey ca.key -CAcreateserial  -out kube-scheduler.crt -days 1000
   62  ls -l
   63  cat /etc/hosts
   64  s\\\
   65  nslookup 172.31.24.188
   66  nslookup 172.31.16.151
   67  cat /etc/resolv.conf
   68  nslookup rameshhms1c.mylabserver.com
   69  nslookup 54.153.125.159
   70  nslookup localhost
   71  nslookup 127.0.0.1
   72  nslookup localhost.localdomain
   73  ls -l
   74  cat > openssl.cnf <<EOF
   75  [req]
   76  req_extensions = v3_req
   77  distinguished_name = req_distinguished_name
   78  [req_distinguished_name]
   79  [ v3_req ]
   80  basicConstraints = CA:FALSE
   81  keyUsage = nonRepudiation, digitalSignature, keyEncipherment
   82  subjectAltName = @alt_names
   83  [alt_names]
   84  DNS.1 = kubernetes
   85  DNS.2 = kubernetes.default
   86  DNS.3 = kubernetes.default.svc
   87  DNS.4 = kubernetes.default.svc.cluster.local
   88  DNS.5 = rameshhms1c.mylabserver.com
   89  DNS.6 = rameshhms2c.mylabserver.com
   90  DNS.7 = rameshhms3c.mylabserver.com
   91  DNS.8 = rameshhms4c.mylabserver.com
   92  DNS.9 = rameshhms5c.mylabserver.com
   93  DNS.10 = rameshhms6c.mylabserver.com
   94  DNS.11 = localhost
   95  DNS.12 = localhost.localdomain
   96  IP.1 = 172.31.16.151
   97  IP.2 = 172.31.24.188
   98  IP.3 = 172.31.22.217
   99  IP.4 = 172.31.29.27
  100  IP.5 = 172.31.31.131
  101  IP.6 = 172.31.29.55
  102  IP.7 = 127.0.0.1
  103  EOF
  104  openssl genrsa -out kube-apiserver.key 2048
  105  openssl req -new -key kube-apiserver.key -subj "/CN=kube-apiserver" -out kube-apiserver.csr -config openssl.cnf
  106  openssl x509 -req -in kube-apiserver.csr -CA ca.crt -CAkey ca.key -CAcreateserial  -out kube-apiserver.crt -extensions v3_req -extfile openssl.cnf -days 1000
  107  ls -l
  108  cat > openssl-etcd.cnf <<EOF
  109  [req]
  110  req_extensions = v3_req
  111  distinguished_name = req_distinguished_name
  112  [req_distinguished_name]
  113  [ v3_req ]
  114  basicConstraints = CA:FALSE
  115  keyUsage = nonRepudiation, digitalSignature, keyEncipherment
  116  subjectAltName = @alt_names
  117  [alt_names]
  118  IP.1 = 172.31.16.151
  119  IP.2 = 172.31.24.188
  120  IP.3 = 172.31.22.217
  121  IP.4 = 127.0.0.1
  122  EOF
  123  ls -lrt
  124  openssl genrsa -out etcd-server.key 2048
  125  openssl req -new -key etcd-server.key -subj "/CN=etcd-server" -out etcd-server.csr -config openssl-etcd.cnf
  126  openssl x509 -req -in etcd-server.csr -CA ca.crt -CAkey ca.key -CAcreateserial  -out etcd-server.crt -extensions v3_req -extfile openssl-etcd.cnf -days 1000
  127  ls -l
  128  openssl genrsa -out service-account.key 2048
  129  openssl req -new -key service-account.key -subj "/CN=service-accounts" -out service-account.csr
  130  openssl x509 -req -in service-account.csr -CA ca.crt -CAkey ca.key -CAcreateserial  -out service-account.crt -days 1000
  131  ls -l
  132  for i in 1 2 3 ;do ssh master${i} mkdir -pm 755 /root/keys;done
  133  for i in master1 master2 master3 worker1 worker2 loadbalancer;do  ssh $i mkdir -pm 755 /root/keys;done
  134  for i in 1 2 3 ;do scp ca.crt ca.key kube-apiserver.key kube-apiserver.crt  service-account.key service-account.crt etcd-server.key etcd-server.crt master${i}:/root/keys/;done
  135  cat > openssl-worker-1.cnf <<EOF
  136  [req]
  137  req_extensions = v3_req
  138  distinguished_name = req_distinguished_name
  139  [req_distinguished_name]
  140  [ v3_req ]
  141  basicConstraints = CA:FALSE
  142  keyUsage = nonRepudiation, digitalSignature, keyEncipherment
  143  subjectAltName = @alt_names
  144  [alt_names]
  145  DNS.1 = worker1
  146  DNS.2 = rameshhms4c.mylabserver.com
  147  IP.1 = 172.31.29.27
  148  EOF
  149  openssl genrsa -out worker-1.key 2048
  150  openssl genrsa -out worker1.key 2048
  151  openssl req -new -key worker1.key -subj "/CN=system:node:worker1/O=system:nodes" -out worker1.csr -config openssl-worker1.cnf
  152  rm worker-1.key
  153  ls -lrt
  154  rm worker1.key
  155  rm openssl-worker-1.cnf
  156  cat > openssl-worker1.cnf <<EOF
  157  [req]
  158  req_extensions = v3_req
  159  distinguished_name = req_distinguished_name
  160  [req_distinguished_name]
  161  [ v3_req ]
  162  basicConstraints = CA:FALSE
  163  keyUsage = nonRepudiation, digitalSignature, keyEncipherment
  164  subjectAltName = @alt_names
  165  [alt_names]
  166  DNS.1 = worker1
  167  DNS.2 = rameshhms4c.mylabserver.com
  168  IP.1 = 172.31.29.27
  169  EOF
  170  openssl genrsa -out worker1.key 2048
  171  openssl req -new -key worker1.key -subj "/CN=system:node:worker1/O=system:nodes" -out worker1.csr -config openssl-worker1.cnf
  172  openssl x509 -req -in worker1.csr -CA ca.crt -CAkey ca.key -CAcreateserial  -out worker1.crt -extensions v3_req -extfile openssl-worker1.cnf -days 1000
  173  cat /etc/hosts
  174  ssh loadbalancer
  175  LOADBALANCER_ADDRESS=172.31.29.55
  176    kubectl config set-cluster kubernetes-the-hard-way     --certificate-authority=ca.crt     --embed-certs=true     --server=https://${LOADBALANCER_ADDRESS}:6443     --kubeconfig=kube-proxy.kubeconfig
  177    kubectl config set-credentials system:kube-proxy     --client-certificate=kube-proxy.crt     --client-key=kube-proxy.key     --embed-certs=true     --kubeconfig=kube-proxy.kubeconfig
  178    kubectl config set-context default     --cluster=kubernetes-the-hard-way     --user=system:kube-proxy     --kubeconfig=kube-proxy.kubeconfig
  179    kubectl config use-context default --kubeconfig=kube-proxy.kubeconfig
  180  kubectl config set-cluster kubernetes-the-hard-way     --certificate-authority=ca.crt     --embed-certs=true     --server=https://127.0.0.1:6443     --kubeconfig=kube-controller-manager.kubeconfig
  181    kubectl config set-credentials system:kube-controller-manager     --client-certificate=kube-controller-manager.crt     --client-key=kube-controller-manager.key     --embed-certs=true     --kubeconfig=kube-controller-manager.kubeconfig
  182    kubectl config set-context default     --cluster=kubernetes-the-hard-way     --user=system:kube-controller-manager     --kubeconfig=kube-controller-manager.kubeconfig
  183    kubectl config use-context default --kubeconfig=kube-controller-manager.kubeconfig
  184  kubectl config set-cluster kubernetes-the-hard-way     --certificate-authority=ca.crt     --embed-certs=true     --server=https://127.0.0.1:6443     --kubeconfig=kube-scheduler.kubeconfig
  185    kubectl config set-credentials system:kube-scheduler     --client-certificate=kube-scheduler.crt     --client-key=kube-scheduler.key     --embed-certs=true     --kubeconfig=kube-scheduler.kubeconfig
  186    kubectl config set-context default     --cluster=kubernetes-the-hard-way     --user=system:kube-scheduler     --kubeconfig=kube-scheduler.kubeconfig
  187    kubectl config use-context default --kubeconfig=kube-scheduler.kubeconfig
  188  kubectl config set-cluster kubernetes-the-hard-way     --certificate-authority=ca.crt     --embed-certs=true     --server=https://127.0.0.1:6443     --kubeconfig=admin.kubeconfig
  189    kubectl config set-credentials admin     --client-certificate=admin.crt     --client-key=admin.key     --embed-certs=true     --kubeconfig=admin.kubeconfig
  190    kubectl config set-context default     --cluster=kubernetes-the-hard-way     --user=admin     --kubeconfig=admin.kubeconfig
  191    kubectl config use-context default --kubeconfig=admin.kubeconfig
  192  for instance in worker1 worker2; do  scp kube-proxy.kubeconfig ${instance}:/root/keys/;done
  193  for instance in master1 master2 master3; do scp admin.kubeconfig kube-controller-manager.kubeconfig kube-scheduler.kubeconfig ${instance}:~/root/keys/;done
  194  for instance in master1 master2 master3; do scp admin.kubeconfig kube-controller-manager.kubeconfig kube-scheduler.kubeconfig ${instance}:/root/keys/;done
  195  echo $LOADBALANCER_ADDRESS
  196    kubectl config set-cluster kubernetes-the-hard-way     --certificate-authority=ca.crt     --embed-certs=true     --server=https://${LOADBALANCER_ADDRESS}:6443     --kubeconfig=worker-1.kubeconfig
  197  ls -lrt
  198  rm worker-1.kubeconfig
  199  echo $LOADBALANCER_ADDRESS
  200   kubectl config set-cluster kubernetes-the-hard-way     --certificate-authority=ca.crt     --embed-certs=true     --server=https://${LOADBALANCER_ADDRESS}:6443     --kubeconfig=worker1.kubeconfig
  201    kubectl config set-credentials system:node:worker1     --client-certificate=worker1.crt     --client-key=worker1.key     --embed-certs=true     --kubeconfig=worker1.kubeconfig
  202    kubectl config set-context default     --cluster=kubernetes-the-hard-way     --user=system:node:worker1     --kubeconfig=worker1.kubeconfig
  203    kubectl config use-context default --kubeconfig=worker1.kubeconfig
  204  scp ca.crt worker1.crt worker1.key worker1.kubeconfig worker1:/root/keys/
  205  ENCRYPTION_KEY=$(head -c 32 /dev/urandom | base64)
  206  echo $ENCRYPTION_KEY=$(head -c 32 /dev/urandom | base64
  207  echo $ENCRYPTION_KEY
  208  ENCRYPTION_KEY=$(head -c 32 /dev/urandom | base64)
  209  echo $ENCRYPTION_KEY
  210  cat > encryption-config.yaml <<EOF
  211  kind: EncryptionConfig
  212  apiVersion: v1
  213  resources:
  214    - resources:
  215        - secrets
  216      providers:
  217        - aescbc:
  218            keys:
  219              - name: key1
  220                secret: ${ENCRYPTION_KEY}
  221        - identity: {}
  222  EOF
  223  ls -lrt
  224  for instance in master1 master2 master3; do   scp encryption-config.yaml ${instance}:~/; done
  225  cd
  226  cd packages/
  227  for instance in master1 master2 master3; do  ssh $i mkdir -pm /root/packages; done
  228  for instance in master1 master2 master3; do  ssh $instance mkdir -pm /root/packages; done
  229  for instance in master1 master2 master3; do  ssh $instance mkdir -pm 755 /root/packages; done
  230  ls-l
  231  ls -l
  232  wget -q --show-progress --https-only --timestamping  "https://github.com/coreos/etcd/releases/download/v3.3.9/etcd-v3.3.9-linux-amd64.tar.gz"
  233  rm etcd-v3.3.9-linux-amd64.tar.gz
  234  wget -q --show-progress --https-only --timestamping  "https://github.com/coreos/etcd/releases/download/v3.3.9/etcd-v3.3.9-linux-amd64.tar.gz"
  235  ls -lrt
  236    tar -xvf etcd-v3.3.9-linux-amd64.tar.gz
  237  ls-l
  238  ls -lrt
  239  for instance in master1 master2 master3; do scp -rv etcd-v3.3.9-linux-amd64/etcd* $instance:/usr/local/bin/; done
  240  ls -l /usr/local/bin/
  241  ls -l
  242  ls -l etcd-v3.3.9-linux-amd64/etcd*
  243  for instance in master1 master2 master3; do  ssh $instance mkdir -p /etc/etcd /var/lib/etcd; done
  244  for instance in master1 master2 master3; do  ssh $instance  cp /root/keys/ca.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /etc/etcd/; done
  245  ls -l /etc/etcd/
  246  ip a
  247  ip addr show ens5
  248  ip addr show ens5| grep "inet " | awk '{print $2}' | cut -d / -f 1
  249  INTERNAL_IP=$(ip addr show ens5| grep "inet " | awk '{print $2}' | cut -d / -f 1)
  250  ETCD_NAME=$(hostname -s)
  251  cat /etc/hosts
  252  cat <<EOF | sudo tee /etc/systemd/system/etcd.service
  253  [Unit]
  254  Description=etcd
  255  Documentation=https://github.com/coreos
  256  [Service]
  257  ExecStart=/usr/local/bin/etcd \\
  258    --name ${ETCD_NAME} \\
  259    --cert-file=/etc/etcd/etcd-server.crt \\
  260    --key-file=/etc/etcd/etcd-server.key \\
  261    --peer-cert-file=/etc/etcd/etcd-server.crt \\
  262    --peer-key-file=/etc/etcd/etcd-server.key \\
  263    --trusted-ca-file=/etc/etcd/ca.crt \\
  264    --peer-trusted-ca-file=/etc/etcd/ca.crt \\
  265    --peer-client-cert-auth \\
  266    --client-cert-auth \\
  267    --initial-advertise-peer-urls https://${INTERNAL_IP}:2380 \\
  268    --listen-peer-urls https://${INTERNAL_IP}:2380 \\
  269    --listen-client-urls https://${INTERNAL_IP}:2379,https://127.0.0.1:2379 \\
  270    --advertise-client-urls https://${INTERNAL_IP}:2379 \\
  271    --initial-cluster-token etcd-cluster-0 \\
  272    --initial-cluster master1=https://172.31.16.151:2380,master2=https://172.31.24.188:2380,master3=https://172.31.22.217:2380 \\
  273    --initial-cluster-state new \\
  274    --data-dir=/var/lib/etcd
  275  Restart=on-failure
  276  RestartSec=5
  277  [Install]
  278  WantedBy=multi-user.target
  279  EOF
  280  cat /etc/systemd/system/etcd.service
  281  ssh master2
  282  ssh master3
  283  for instance in master1 master2 master3; do  ssh $instance systemctl daemon-reload; done
  284  for instance in master1 master2 master3; do  ssh $instance systemctl enable etcd; done
  285  for instance in master1 master2 master3; do  ssh $instance systemctl start etcd; done
  286  for instance in master1 master2 master3; do  ssh $instance systemctl status etcd; done
  287  ETCDCTL_API=3 etcdctl member list  --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt  --cert=/etc/etcd/etcd-server.crt --key=/etc/etcd/etcd-server.key
  288  ETCDCTL_API=3 etcdctl -w table member list  --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt  --cert=/etc/etcd/etcd-server.crt --key=/etc/etcd/etcd-server.key
  289  for instance in master1 master2 master3; do  ssh $instance mkdir -p /etc/kubernetes/config; done
  290  wget -q --show-progress --https-only --timestamping   "https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kube-apiserver"   "https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kube-controller-manager"   "https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kube-scheduler"   "https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kubectl"
  291  chmod +x kube-apiserver kube-controller-manager kube-scheduler kubectl
  292  for instance in master1 master2 master3; do  scp kube-apiserver kube-controller-manager kube-scheduler kubectl $instance:/usr/local/bin/; done
  293  ls -l /usr/local/bin/
  294  for instance in master1 master2 master3; do  ssh  $instance ls -l /usr/local/bin/; done
  295  for instance in master1 master2 master3; do  ssh $instance mkdir -p /var/lib/kubernetes/; done
  296  for instance in master1 master2 master3; do  ssh $instance cp /root/keys/ca.crt /root/keys/ca.key /root/keys/kube-apiserver.crt /root/keys/kube-apiserver.key /root/keys/service-account.key /root/keys/service-account.crt /root/keys/etcd-server.key /root/keys/etcd-server.crt /root/keys/encryption-config.yaml /var/lib/kubernetes/; done
  297  ls -l /root/keys/encryption-config.yaml
  298  cat /root/keys/encryption-config.yaml
  299  for instance in master1 master2 master3; do scp /root/keys/encryption-config.yaml $instance:/var/lib/kubernetes/; done
  300  for instance in master1 master2 master3; do  ssh $instance ls -l /var/lib/kubernetes/; done
  301  eco $/root/keys/encryption-config.yaml
  302  echo $INTERNAL_IP
  303  ip a
  304  cat /etc/hosts
  305  ls -l /var/lib/kubernetes/kube-apiserver.key
  306  cat <<EOF | sudo tee /etc/systemd/system/kube-apiserver.service
  307  [Unit]
  308  Description=Kubernetes API Server
  309  Documentation=https://github.com/kubernetes/kubernetes
  310  [Service]
  311  ExecStart=/usr/local/bin/kube-apiserver \\
  312    --advertise-address=${INTERNAL_IP} \\
  313    --allow-privileged=true \\
  314    --apiserver-count=3 \\
  315    --audit-log-maxage=30 \\
  316    --audit-log-maxbackup=3 \\
  317    --audit-log-maxsize=100 \\
  318    --audit-log-path=/var/log/audit.log \\
  319    --authorization-mode=Node,RBAC \\
  320    --bind-address=0.0.0.0 \\
  321    --client-ca-file=/var/lib/kubernetes/ca.crt \\
  322    --enable-admission-plugins=NodeRestriction,ServiceAccount \\
  323    --enable-swagger-ui=true \\
  324    --enable-bootstrap-token-auth=true \\
  325    --etcd-cafile=/var/lib/kubernetes/ca.crt \\
  326    --etcd-certfile=/var/lib/kubernetes/etcd-server.crt \\
  327    --etcd-keyfile=/var/lib/kubernetes/etcd-server.key \\
  328    --etcd-servers=https://172.31.16.151:2379,https://172.31.24.188:2379,https://172.31.22.217:2379 \\
  329    --event-ttl=1h \\
  330    --encryption-provider-config=/var/lib/kubernetes/encryption-config.yaml \\
  331    --kubelet-certificate-authority=/var/lib/kubernetes/ca.crt \\
  332    --kubelet-client-certificate=/var/lib/kubernetes/kube-apiserver.crt \\
  333    --kubelet-client-key=/var/lib/kubernetes/kube-apiserver.key \\
  334    --kubelet-https=true \\
  335    --runtime-config=api/all \\
  336    --service-account-key-file=/var/lib/kubernetes/service-account.crt \\
  337    --service-cluster-ip-range=10.96.0.0/24 \\
  338    --service-node-port-range=30000-32767 \\
  339    --tls-cert-file=/var/lib/kubernetes/kube-apiserver.crt \\
  340    --tls-private-key-file=/var/lib/kubernetes/kube-apiserver.key \\
  341    --v=2
  342  Restart=on-failure
  343  RestartSec=5
  344  [Install]
  345  WantedBy=multi-user.target
  346  EOF
  347  more /etc/systemd/system/kube-apiserver.service
  348  ls -l /var/lib/kubernetes/ca.crt
  349  ssh -q master2
  350  ssh -q master3
  351  ls -l
  352  cd ../keys/
  353  ls -l kube-controller-manager.*
  354  for instance in master1 master2 master3; do  scp kube-controller-manager.kubeconfig $instance:/var/lib/kubernetes/;done
  355  ls -l /var/lib/kubernetes/
  356  more kube-controller-manager.kubeconfig
  357  ls -lrt
  358  ip a
  359  cat /etc/hosts
  360  ssh master2
  361  ssh master2\3 ip a
  362  ssh master3 ip a
  363  ls -l
  364  cat <<EOF | sudo tee /etc/systemd/system/kube-controller-manager.service
  365  [Unit]
  366  Description=Kubernetes Controller Manager
  367  Documentation=https://github.com/kubernetes/kubernetes
  368  [Service]
  369  ExecStart=/usr/local/bin/kube-controller-manager \\
  370    --address=0.0.0.0 \\
  371    --cluster-cidr=172.31.0.0/20 \\
  372    --cluster-name=kubernetes \\
  373    --cluster-signing-cert-file=/var/lib/kubernetes/ca.crt \\
  374    --cluster-signing-key-file=/var/lib/kubernetes/ca.key \\
  375    --kubeconfig=/var/lib/kubernetes/kube-controller-manager.kubeconfig \\
  376    --leader-elect=true \\
  377    --root-ca-file=/var/lib/kubernetes/ca.crt \\
  378    --service-account-private-key-file=/var/lib/kubernetes/service-account.key \\
  379    --service-cluster-ip-range=10.96.0.0/24 \\
  380    --use-service-account-credentials=true \\
  381    --v=2
  382  Restart=on-failure
  383  RestartSec=5
  384  [Install]
  385  WantedBy=multi-user.target
  386  EOF
  387  more /etc/systemd/system/kube-controller-manager.service
  388  pwd
  389  for instance in master1 master2 master3; do  scp /etc/systemd/system/kube-controller-manager.service $instance:/etc/systemd/system/kube-controller-manager.service;done
  390  ls -l /etc/systemd/system/kube-controller-manager.service
  391  for instance in master1 master2 master3; do  scp kube-scheduler.kubeconfig $instance:/var/lib/kubernetes/;done
  392  ls-l /var/lib/kubernetes/
  393  ls -l /var/lib/kubernetes/
  394  cat <<EOF | sudo tee /etc/systemd/system/kube-scheduler.service
  395  [Unit]
  396  Description=Kubernetes Scheduler
  397  Documentation=https://github.com/kubernetes/kubernetes
  398  [Service]
  399  ExecStart=/usr/local/bin/kube-scheduler \\
  400    --kubeconfig=/var/lib/kubernetes/kube-scheduler.kubeconfig \\
  401    --address=127.0.0.1 \\
  402    --leader-elect=true \\
  403    --v=2
  404  Restart=on-failure
  405  RestartSec=5
  406  [Install]
  407  WantedBy=multi-user.target
  408  EOF
  409  more /etc/systemd/system/kube-scheduler.service
  410  for instance in master1 master2 master3; do  scp /etc/systemd/system/kube-scheduler.service $instance:/etc/systemd/system/kube-scheduler.service;done
  411  ls -l /etc/systemd/system/kube-scheduler.service
  412  ls -l /etc/systemd/system/
  413  for instance in master1 master2 master3; do ssh $instance systemctl daemon-reload;done
  414  for instance in master1 master2 master3; do ssh $instance systemctl enable kube-apiserver kube-controller-manager kube-scheduler;done
  415  for instance in master1 master2 master3; do ssh $instance systemctl start kube-apiserver kube-controller-manager kube-scheduler;done
  416  for instance in master1 master2 master3; do ssh $instance systemctl status kube-apiserver kube-controller-manager kube-scheduler;done
  417  kubectl get pods
  418  kubectl get pods --all-namespaces
  419  systemctl status kube-apiserver.service
  420  systemctl status kube-scheduler.service
  421  systemctl status kube-controller-manager.service
  422  kubectl get componentstatuses --kubeconfig admin.kubeconfig
  423  ssh loadbalancer
  424  cat /etc/hosts
  425  ssh loadbalancer
  426  kubectl version
  427  ssh worker1
  428  su -
  429  ssh worker1
  430  ssh worker2
  431  ssh worker1
  432  kubectl get nodes
  433  kubectl get nodes --kubeconfig admin.kubeconfig
  434  cd keys/
  435  kubectl get nodes --kubeconfig admin.kubeconfig
  436  cd
  437  systemctl status kube-apiserver.service
  438  more /etc/systemd/system/kube-apiserver.service
  439  more /etc/systemd/system/kube-controller-manager.service
  440  pwd
  441  ls z-l
  442  ls -l
  443  cd keys/ls -l
  444  cd keys/
  445  ls -l
  446  scp ca.crt worker2:/root/keys/
  447  ssh worker2
  448  ls -lrt
  449  cat > bootstrap-token-07401b.yaml <<EOF
  450  apiVersion: v1
  451  kind: Secret
  452  metadata:
  453    # Name MUST be of form "bootstrap-token-<token id>"
  454    name: bootstrap-token-07401b
  455    namespace: kube-system
  456  # Type MUST be 'bootstrap.kubernetes.io/token'
  457  type: bootstrap.kubernetes.io/token
  458  stringData:
  459    # Human readable description. Optional.
  460    description: "The default bootstrap token generated by 'kubeadm init'."
  461    # Token ID and secret. Required.
  462    token-id: 07401b
  463    token-secret: f395accd246ae52d
  464    # Expiration. Optional.
  465    expiration: 2021-03-10T03:22:11Z
  466    # Allowed usages.
  467    usage-bootstrap-authentication: "true"
  468    usage-bootstrap-signing: "true"
  469    # Extra groups to authenticate the token as. Must start with "system:bootstrappers:"
  470    auth-extra-groups: system:bootstrappers:worker
  471  EOF
  472  ls -lrt
  473  kubectl create -f bootstrap-token-07401b.yaml
  474  kubectl create clusterrolebinding create-csrs-for-bootstrapping --clusterrole=system:node-bootstrapper --group=system:bootstrappers -o yaml --dry-run
  475  kubectl create clusterrolebinding create-csrs-for-bootstrapping --clusterrole=system:node-bootstrapper --group=system:bootstrappers
  476  kubectl create clusterrolebinding auto-approve-csrs-for-group --clusterrole=system:certificates.k8s.io:certificatesigningrequests:nodeclient --group=system:bootstrappers
  477  kubectl create clusterrolebinding auto-approve-renewals-for-nodes --clusterrole=system:certificates.k8s.io:certificatesigningrequests:selfnodeclient --group=system:nodes
  478  cat /etc/hosts
  479  ssh worker2
  480  kubectl get csr
  481  kubectl certificate approve csr-9ktps
  482  kubectl get csr
  483  kubectl get nodes
  484  kubectl get nodes --kubeconfig admin.kubeconfig
  485  kubectl get componentstatuses
  486  kubectl config get-contexts
  487  kubectl config get-contexts --kube-config admin.kubeconfig
  488  kubectl config get-contexts --kube-config=admin.kubeconfig
  489  kubectl config get-contexts kube-config admin.kubeconfig
  490  kubectl config get-contexts kubeconfig admin.kubeconfig
  491  kubectl config get-contexts --kubeconfig admin.kubeconfig
  492  kubectl config get-contexts
  493  kubectl cluster-info
  494  kubectl cluster-info --kubeconfig admin.kubeconfig
  495  more admin.kubeconfig
  496  cat /etc/hosts
  497  KUBERNETES_LB_ADDRESS=172.31.29.55
  498  apt list | grep -i nginx
  499    kubectl config set-cluster kubernetes-the-hard-way     --certificate-authority=ca.crt     --embed-certs=true     --server=https://${KUBERNETES_LB_ADDRESS}:6443
  500  pwd
  501    kubectl config set-credentials admin     --client-certificate=admin.crt     --client-key=admin.key
  502    kubectl config set-context kubernetes-the-hard-way     --cluster=kubernetes-the-hard-way     --user=admin
  503   kubectl config use-context kubernetes-the-hard-way
  504  kubectl get use-contexts
  505  kubectl config get-contexts
  506  kubectl cluster-info
  507  kubectl get componentstatuses
  508  ETCDCTL_API=3 etcdctl -w table member list  --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt  --cert=/etc/etcd/etcd-server.crt --key=/etc/etcd/etcd-server.key
  509  ETCDCTL_API=3 etcdctl -w table endpoints --cluster health  --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt  --cert=/etc/etcd/etcd-server.crt --key=/etc/etcd/etcd-server.key
  510  ETCDCTL_API=3 etcdctl -w table endpoint --cluster health  --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt  --cert=/etc/etcd/etcd-server.crt --key=/etc/etcd/etcd-server.key
  511  ETCDCTL_API=3 etcdctl -w table endpoint --cluster status  --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt  --cert=/etc/etcd/etcd-server.crt --key=/etc/etcd/etcd-server.key
  512  kubectl get pods
  513  kubectl get nodes
  514  ssh 54.215.241.129
  515  ls -l
  516  cd packages/
  517  ls -l
  518  ssh worker1
  519  cat /etc/hosts
  520  ssh worker1
  521  cd
  522  kubectl apply -f "https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\n')"
  523  kubectl get pods -n kube-system
  524  kubectl describe weave-net-gcqkf
  525  kubectl describe pod weave-net-gcqkf
  526  kubectl get pods -n kube-system
  527  kubectl describe pod weave-net-gcqkf -n kube-system
  528  ls -l /run/systemd/resolve/resolv.conf
  529  kubectl get pods -n kube-system
  530  kubectl get pods -n kube-system -o wide
  531  ssh worker1
  532  ssh worker2
  533  kubectl get pods
  534  kubectl get pods -n kube-system -o wide
  535  kubectl describe pods weave-net-gcqkf -n kube-system
  536  kubectl get pods -n kube-system -o wide
  537  kubectl describe pods weave-net-v6ndp -n kube-system
  538  kubectl describe pods weave-net-gcqkf -n kube-system
  539  kubectl get pods -n kube-system -o wide
  540  kubectl get daemonsets
  541  kubectl get daemonsets -n kube-system
  542  kubectl get pods -n kube-system -o wide
  543  kubectl describe pods weave-net-gcqkf -n kube-system
  544  ssh master1
  545  ssh worker1
  546  kubeadm
  547  systemctl status kube-apiserver.service
  548  kubectl get nodes
  549  more /etc/systemd/system/kube-apiserver.service
  550  cd /var/lib/kubernetes/
  551  ls -l
  552  openssl x509 -in kube-apiserver.crt -text -noout
  553  cd
  554  systemctl stop kube-apiserver.service
  555  systemctl status kube-apiserver.service
  556  kubectl get nodes
  557  pwd
  558  mkdir apikey
  559  cd apikey/
  560  ls-l
  561  ls -l
  562  cat > openssl.cnf <<EOF
  563  [req]
  564  req_extensions = v3_req
  565  distinguished_name = req_distinguished_name
  566  [req_distinguished_name]
  567  [ v3_req ]
  568  basicConstraints = CA:FALSE
  569  keyUsage = nonRepudiation, digitalSignature, keyEncipherment
  570  subjectAltName = @alt_names
  571  [alt_names]
  572  DNS.1 = kubernetes
  573  DNS.2 = kubernetes.default
  574  DNS.3 = kubernetes.default.svc
  575  DNS.4 = kubernetes.default.svc.cluster.local
  576  DNS.5 = rameshhms1c.mylabserver.com
  577  DNS.6 = rameshhms2c.mylabserver.com
  578  DNS.7 = rameshhms3c.mylabserver.com
  579  DNS.8 = rameshhms4c.mylabserver.com
  580  DNS.9 = rameshhms5c.mylabserver.com
  581  DNS.10 = rameshhms6c.mylabserver.com
  582  DNS.11 = localhost
  583  DNS.12 = localhost.localdomain
  584  IP.1 = 172.31.16.151
  585  IP.2 = 172.31.24.188
  586  IP.3 = 172.31.22.217
  587  IP.4 = 172.31.29.27
  588  IP.5 = 172.31.31.131
  589  IP.6 = 172.31.29.55
  590  IP.7 = 10.96.0.1
  591  IP.8 = 127.0.0.1
  592  EOF
  593  openssl genrsa -out kube-apiserver.key 2048
  594  openssl req -new -key kube-apiserver.key -subj "/CN=kube-apiserver" -out kube-apiserver.csr -config openssl.cnf
  595  ls -l
  596  cp ../keys/ca.* .
  597  ls -l
  598  openssl x509 -req -in kube-apiserver.csr -CA ca.crt -CAkey ca.key -CAcreateserial  -out kube-apiserver.crt -extensions v3_req -extfile openssl.cnf -days 1000
  599  ls -l
  600  openssl x509 -in kube-apiserver.crt -text -noout
  601  ssh worker1
  602  pwd
  603  for instance in master2 master3; do scp ca.crt ca.key kube-apiserver.key kube-apiserver.crt  ${instance}:~/; done
  604  ssh master2
  605  ls -l
  606  cd /var/lib/kubernetes/
  607  ls -l
  608  mv kube-apiserver.crt kube-apiserver.key /var/tmp/
  609  cp /root/apikey/kube-apiserver.crt /root/apikey/kube-apiserver.key .
  610  ls -lrt
  611  systemctl start kube-apiserver.service
  612  systemctl status kube-apiserver.service
  613  ssh master2
  614  ssh master3
  615  kubectl get pods
  616  kubectl get pods -n kube-system
  617  kubectl logs weave-net-gcqkf
  618  kubectl logs weave-net-gcqkf -n kube-sy
  619  kubectl logs weave-net-gcqkf -n kube-system
  620  kubectl get pods -n kube-system
  621  cd
  622  kubectl get svc
  623  kubectl get svc -n kube-system
  624  kubectl get svc
  625  kubectl get pods
  626  kubectl get pods -n kube-system
  627  kubectl describe pods weave-net-gcqkf
  628  kubectl describe pods weave-net-gcqkf -n kube-config
  629  kubectl describe pods weave-net-gcqkf -n kube-system
  630  kubectl describe pods weave-net-gcqkf -n kube-system -o wide
  631  kubectl get pods -n kube-system -o wide
  632  ssh worker1
  633  kubectl get pods -n kube-system -o wide
  634  kubectl get nodes
  635  ubectl get pods -n kube-system -l name=weave-net
  636  kkubectl get pods -n kube-system -l name=weave-net
  637  kubectl get pods -n kube-system -l name=weave-net
  638  kubectl logs -n kube-system weave-net-gcqkf weave
  639  kubectl config get-contexts
  640  kubectl exec -n kube-system weave-net-gcqkf -c weave -- /home/weave/weave --local status
  641  ssh worker1
  642  kubectl get svc
  643  ls -l
  644  cd keys/
  645  ls -l
  646  cat <<EOF | kubectl apply --kubeconfig admin.kubeconfig -f -
  647  apiVersion: rbac.authorization.k8s.io/v1beta1
  648  kind: ClusterRole
  649  metadata:
  650    annotations:
  651      rbac.authorization.kubernetes.io/autoupdate: "true"
  652    labels:
  653      kubernetes.io/bootstrapping: rbac-defaults
  654    name: system:kube-apiserver-to-kubelet
  655  rules:
  656    - apiGroups:
  657        - ""
  658      resources:
  659        - nodes/proxy
  660        - nodes/stats
  661        - nodes/log
  662        - nodes/spec
  663        - nodes/metrics
  664      verbs:
  665        - "*"
  666  EOF
  667  vi kubeapi-server-to-kubletrole.yaml
  668  echo "kubectl apply -f kubeapi-server-to-kubletrole.yaml --kubeconfig admin.kubeconfig"
  669  cat <<EOF | kubectl apply --kubeconfig admin.kubeconfig -f -
  670  apiVersion: rbac.authorization.k8s.io/v1beta1
  671  kind: ClusterRoleBinding
  672  metadata:
  673    name: system:kube-apiserver
  674    namespace: ""
  675  roleRef:
  676    apiGroup: rbac.authorization.k8s.io
  677    kind: ClusterRole
  678    name: system:kube-apiserver-to-kubelet
  679  subjects:
  680    - apiGroup: rbac.authorization.k8s.io
  681      kind: User
  682      name: kube-apiserver
  683  EOF
  684  vi kube-apiserver-to-kublet-binding.yaml
  685  kubectl get clusterrole
  686  kubectl exec -n kube-system weave-net-gcqkf -c weave -- /home/weave/weave --local status
  687  kubectl apply -f https://raw.githubusercontent.com/mmumshad/kubernetes-the-hard-way/master/deployments/coredns.yaml
  688  kubectl get pods -l k8s-app=kube-dns -n kube-system -o wide
  689  kubectl get svc -n kube-system
  690  kubectl get svc
  691  kubectl describe svc kube-dns -n kube-system
  692  kubectl run --generator=run-pod/v1  busybox --image=busybox:1.28 --command -- sleep 3600
  693  kubectl get svc
  694  kubectl get pods
  695  kubectl exec -ti busybox -- nslookup kubernetes
  696  kubectl get pods -o wide
  697  ssh worker1
  698  cat /etc/resolv.conf
  699  nslookup worker1
  700  cat /etc/resolv.conf
  701  cat /etc/hosts
  702  ssh worker1
  703  nslookup rameshhms4c.mylabserver.com
  704  cat /etc/hosts
  705  nslookup 172.31.16.151
  706  nslookup master1.localhost.localdomain
  707  nslookup master1.localhost
  708  nslookup master1
  709  nslookup 172.31.16.151
  710  cat /etc/resolv
  711  cat /etc/resolv.conf
  712  nslookup localhost
  713  dig localhost
  714  dig master
  715  kubectl exec -ti busybox -- nslookup kubernetes
  716  ls -l /etc/dhcp/dhclient.conf
  717  cat /etc/dhcp/dhclient.conf
  718  ip addr show
  719  kubectl exec -ti busybox -- nslookup kubernetes
  720  struss kubectl exec -ti busybox -- nslookup kubernetes
  721  stress kubectl exec -ti busybox -- nslookup kubernetes
  722  apt install stress
  723  stress kubectl exec -ti busybox -- nslookup kubernetes
  724   kubectl exec -ti busybox -- nslookup kubernetes
  725  kubectl gety pods
  726  kubectl get pods
  727   kubectl exec -ti busybox -- nslookup kubernetes
  728  ssh worker1
  729   kubectl exec -ti busybox -- nslookup kubernetes
  730  kubectl get svc
  731  kubectl get nodes
  732  kubectl create secret generic kubernetes-the-hard-way   --from-literal="mykey=mydata"
  733  ETCDCTL_API=3 etcdctl get   --endpoints=https://127.0.0.1:2379   --cacert=/etc/etcd/ca.crt   --cert=/etc/etcd/etcd-server.crt   --key=/etc/etcd/etcd-server.key  /registry/secrets/default/kubernetes-the-hard-way | hexdump -C
  734  kubectl delete secret kubernetes-the-hard-way
  735  kubectl create deployment nginx --image=nginx
  736  kubectl get pods
  737  kubectl get deployments
  738  kubectl exec -it nginx-5c7588df-knbgg bash
  739  kubectl get deployments
  740  kubectl expose deploy nginx --type=NodePort --port 80
  741  kubectl get svcs
  742  kubectl get svc
  743  curl http://worker1:31819
  744  kubectl get svc -l app=nginx -o jsonpath="{.items[0].spec.ports[0].nodePort}"
  745  kubectl get svc -o jsonpath="{.items[0].spec.ports[0].nodePort}"
  746  kubectl get svc -l app=nginx -o jsonpath="{.items[0].spec.ports[0].nodePort}"
  747  kubectl get svc
  748  kubectl describe svc nginx
  749  kubectl get svc nginx -oyaml
  750  kubectl get svc -l app=nginx -o jsonpath="{.items[0].spec.ports[0].port}"
  751  kubectl get svc -l app=nginx -o jsonpath="{.items[0].spec.selector[0].type}"
  752  kubectl get svc -l app=nginx -o jsonpath="{.items[0].spec.selector.type}"
  753  kubectl get svc -l app=nginx -o jsonpath="{.items[0].spec.selector.app}"
  754  kubectl get pods -l app=nginx -o jsonpath="{.items[0].metadata.name}"
  755  POD_NAME=$(kubectl get pods -l app=nginx -o jsonpath="{.items[0].metadata.name}")
  756  kubectl logs $POD_NAME
  757  kubectl exec -ti $POD_NAME -- nginx -v
  758  wget https://dl.google.com/go/go1.12.1.linux-amd64.tar.gz
  759  ls -l
  760  mv go1.12.1.linux-amd64.tar.gz packages/
  761  cd packages/
  762  ls -l
  763  tar -C /usr/local -xzf go1.12.1.linux-amd64.tar.gz
  764  ls -l /usr/local
  765  go get -v -u k8s.io/test-infra/kubetest
  766  export PATH=$PATH:/usr/local/go/bin:$GOPATH/bin
  767  go get -v -u k8s.io/test-infra/kubetest
  768  kubetest --extract=v1.13.0
  769  pwd
  770  ls -l
  771  locate kubetest
  772  cd /
  773  find . -name kubetest
  774  cd
  775  kubectl get pods
  776  NODE_NAME=worker1
  777  curl -sSL "https://localhost:6443/api/v1/nodes/${NODE_NAME}/proxy/configz" -k --cert admin.crt --key admin.key
  778  cd keys/
  779  curl -sSL "https://localhost:6443/api/v1/nodes/${NODE_NAME}/proxy/configz" -k --cert admin.crt --key admin.key
  780  apt install -y jq
  781  curl -sSL "https://localhost:6443/api/v1/nodes/${NODE_NAME}/proxy/configz" -k --cert admin.crt --key admin.key| jq '.kubeletconfig|.kind="KubeletConfiguration"|.apiVersion="kubelet.config.k8s.io/v1beta1"'
  782  pwd
  783  cd
  784  ssh master3
  785  ls -ld /etc/cni/net.d   /opt/cni/bin   /var/lib/kubelet   /var/lib/kube-proxy   /var/lib/kubernetes   /var/run/kubernetes
  786  ls -l /var/lib/kubernetes
  787  mkdir -p  /etc/cni/net.d   /opt/cni/bin   /var/lib/kubelet   /var/lib/kube-proxy /var/run/kubernetes
  788  ls -l
  789  cd packages/
  790  ls -l
  791  chmod +x kubectl kube-proxy kubelet
  792  ssh master3
  793  cd ../keys/
  794  ls -l /var/lib/kube
  795  ls -l /var/lib/kubernetes/
  796  more kube-proxy.kubeconfig
  797  ls -l kube-proxy.kubeconfig
  798  scp kube-proxy.kubeconfig master3:/var/lib/kube-proxy/kubeconfig
  799  ssh master3
  800  ssh worker2
  801  ssh master3
  802  ssh worker2
  803  ssh worker1
  804  ssh master3
  805  ssh master2
  806  ssh master3
  807  cat /etc/hosts
  808  ssh master2
  809  ETCDCTL_API=3 etcdctl -w table member list  --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt  --cert=/etc/etcd/etcd-server.crt --key=/etc/etcd/etcd-server.key
  810  ETCDCTL_API=3 etcdctl -w table endpoint --cluster status --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt  --cert=/etc/etcd/etcd-server.crt --key=/etc/etcd/etcd-server.key
  811  ETCDCTL_API=3 etcdctl -w table name --cluster status --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt  --cert=/etc/etcd/etcd-server.crt --key=/etc/etcd/etcd-server.key
  812  ETCDCTL_API=3 etcdctl -w table id --cluster status --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt  --cert=/etc/etcd/etcd-server.crt --key=/etc/etcd/etcd-server.key
  813  ETCDCTL_API=3 etcdctl -w table endpoint name --cluster status --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt  --cert=/etc/etcd/etcd-server.crt --key=/etc/etcd/etcd-server.key
  814  ETCDCTL_API=3 etcdctl -w table endpoint --cluster status --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt  --cert=/etc/etcd/etcd-server.crt --key=/etc/etcd/etcd-server.key
  815  kubectl run nginx-now --image=nginx --replicas=2
  816  kubectl get deployments
  817  ETCDCTL_API=3 etcdctl -w table endpoint --cluster status --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt  --cert=/etc/etcd/etcd-server.crt --key=/etc/etcd/etcd-server.key
  818  history
root@master1:~#
root@master1:~#


master 3

==================

    1  sed -i 's/PermitRootLogin without-password/PermitRootLogin yes/' /etc/ssh/sshd_config
    2  systemctl restart sshd
    3  echo -e "root123\nroot123\n" | passwd root
    4  INTERNAL_IP=$(ip addr show ens5| grep "inet " | awk '{print $2}' | cut -d / -f 1)
    5  ETCD_NAME=$(hostname -s)
    6  cat <<EOF | sudo tee /etc/systemd/system/etcd.service
    7  [Unit]
    8  Description=etcd
    9  Documentation=https://github.com/coreos
   10  [Service]
   11  ExecStart=/usr/local/bin/etcd \\
   12    --name ${ETCD_NAME} \\
   13    --cert-file=/etc/etcd/etcd-server.crt \\
   14    --key-file=/etc/etcd/etcd-server.key \\
   15    --peer-cert-file=/etc/etcd/etcd-server.crt \\
   16    --peer-key-file=/etc/etcd/etcd-server.key \\
   17    --trusted-ca-file=/etc/etcd/ca.crt \\
   18    --peer-trusted-ca-file=/etc/etcd/ca.crt \\
   19    --peer-client-cert-auth \\
   20    --client-cert-auth \\
   21    --initial-advertise-peer-urls https://${INTERNAL_IP}:2380 \\
   22    --listen-peer-urls https://${INTERNAL_IP}:2380 \\
   23    --listen-client-urls https://${INTERNAL_IP}:2379,https://127.0.0.1:2379 \\
   24    --advertise-client-urls https://${INTERNAL_IP}:2379 \\
   25    --initial-cluster-token etcd-cluster-0 \\
   26    --initial-cluster master1=https://172.31.16.151:2380,master2=https://172.31.24.188:2380,master3=https://172.31.22.217:2380 \\
   27    --initial-cluster-state new \\
   28    --data-dir=/var/lib/etcd
   29  Restart=on-failure
   30  RestartSec=5
   31  [Install]
   32  WantedBy=multi-user.target
   33  EOF
   34  ls -l  /etc/etcd /var/lib/etcd
   35  INTERNAL_IP=$(ip addr show ens5| grep "inet " | awk '{print $2}' | cut -d / -f 1)
   36  echo $INTERNAL_IP
   37  cat <<EOF | sudo tee /etc/systemd/system/kube-apiserver.service
   38  [Unit]
   39  Description=Kubernetes API Server
   40  Documentation=https://github.com/kubernetes/kubernetes
   41  [Service]
   42  ExecStart=/usr/local/bin/kube-apiserver \\
   43    --advertise-address=${INTERNAL_IP} \\
   44    --allow-privileged=true \\
   45    --apiserver-count=3 \\
   46    --audit-log-maxage=30 \\
   47    --audit-log-maxbackup=3 \\
   48    --audit-log-maxsize=100 \\
   49    --audit-log-path=/var/log/audit.log \\
   50    --authorization-mode=Node,RBAC \\
   51    --bind-address=0.0.0.0 \\
   52    --client-ca-file=/var/lib/kubernetes/ca.crt \\
   53    --enable-admission-plugins=NodeRestriction,ServiceAccount \\
   54    --enable-swagger-ui=true \\
   55    --enable-bootstrap-token-auth=true \\
   56    --etcd-cafile=/var/lib/kubernetes/ca.crt \\
   57    --etcd-certfile=/var/lib/kubernetes/etcd-server.crt \\
   58    --etcd-keyfile=/var/lib/kubernetes/etcd-server.key \\
   59    --etcd-servers=https://172.31.16.151:2379,https://172.31.24.188:2379,https://172.31.22.217:2379 \\
   60    --event-ttl=1h \\
   61    --encryption-provider-config=/var/lib/kubernetes/encryption-config.yaml \\
   62    --kubelet-certificate-authority=/var/lib/kubernetes/ca.crt \\
   63    --kubelet-client-certificate=/var/lib/kubernetes/kube-apiserver.crt \\
   64    --kubelet-client-key=/var/lib/kubernetes/kube-apiserver.key \\
   65    --kubelet-https=true \\
   66    --runtime-config=api/all \\
   67    --service-account-key-file=/var/lib/kubernetes/service-account.crt \\
   68    --service-cluster-ip-range=10.96.0.0/24 \\
   69    --service-node-port-range=30000-32767 \\
   70    --tls-cert-file=/var/lib/kubernetes/kube-apiserver.crt \\
   71    --tls-private-key-file=/var/lib/kubernetes/kube-apiserver.key \\
   72    --v=2
   73  Restart=on-failure
   74  RestartSec=5
   75  [Install]
   76  WantedBy=multi-user.target
   77  EOF
   78  ls -l /usr/local/bin/kube-apiserver
   79  ls -l /var/lib/kubernetes/ca.crt
   80  ls -l /var/lib/kubernetes/service-account.crt
   81  ls -l
   82  cd /var/lib/kubernetes
   83  systemctl stop kube-apiserver.service
   84  mv kube-apiserver.crt kube-apiserver.key /var/tmp/
   85  mv /root/kube-apiserver.* .
   86  ls -l
   87  systemctl start kube-apiserver.service
   88  systemctl status kube-apiserver.service
   89  cd
   90  ls -la
   91   apt install -y jq
   92  ls -l
   93  kubectl get pods
   94  kubectl get nodes
   95  NODE_NAME="hostname"
   96  NODE_NAME=$(hostname)
   97  hostname
   98  hostname -s
   99  hostname
  100  cd keys/
  101  ls -l
  102  NODE_NAME="worker-1"; curl -sSL "https://localhost:6443/api/v1/nodes/${NODE_NAME}/proxy/configz" -k --cert admin.crt --key admin.key | jq '.kubeletconfig|.kind="KubeletConfiguration"|.apiVersion="kubelet.config.k8s.io/v1beta1"' > kubelet_configz_${NODE_NAME}
  103  echo $NODE_NAME
  104  NODE_NAME=$(hostname);curl -sSL "https://localhost:6443/api/v1/nodes/${NODE_NAME}/proxy/configz" -k --cert admin.crt --key admin.key | jq '.kubeletconfig|.kind="KubeletConfiguration"|.apiVersion="kubelet.config.k8s.io/v1beta1"' > kubelet_configz_${NODE_NAME}
  105  which kubelet
  106  cd
  107  cd packages/
  108  ls -l
  109  wget -q --show-progress --https-only --timestamping   https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kubectl   https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kube-proxy   https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kubelet
  110   mkdir -p  /etc/cni/net.d   /opt/cni/bin   /var/lib/kubelet   /var/lib/kube-proxy /var/run/kubernetes
  111  cd packages/
  112  chmod +x kubectl kube-proxy kubelet
  113  cp kubectl kube-proxy kubelet /usr/local/bin/
  114  apt-get update
  115  apt-get install     apt-transport-https     ca-certificates     curl     gnupg-agent     software-properties-common
  116  curl -fsSL https://download.docker.com/linux/ubuntu/gpg | apt-key add -
  117  apt-key fingerprint 0EBFCD88
  118  add-apt-repository    "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) 122     stable"
  119  apt-get update
  120  apt-get install docker-ce docker-ce-cli containerd.io
  121  docker ps -a
  122  docker run hello-world
  123  docker ps -a
  124  kubectl get clusterrolebindings
  125  kubectl get clusterrolebindings | grep -i create-csrs-for-bootstrapping
  126  kubectl config --kubeconfig=/var/lib/kubelet/bootstrap-kubeconfig set-cluster bootstrap --server='https://172.31.29.55:6443' --certificate-
  127  kubectl config --kubeconfig=/var/lib/kubelet/bootstrap-kubeconfig set-cluster bootstrap --server='https://172.31.29.55:6443' --certificate-authority=/var/lib/kubernetes/ca.crt
  128  kubectl config --kubeconfig=/var/lib/kubelet/bootstrap-kubeconfig set-credentials kubelet-bootstrap --token=07401b.f395accd246ae52d
  129  kubectl config --kubeconfig=/var/lib/kubelet/bootstrap-kubeconfig set-context bootstrap --user=kubelet-bootstrap --cluster=bootstrap
  130  kubectl config --kubeconfig=/var/lib/kubelet/bootstrap-kubeconfig use-context bootstrap
  131  ls -l /var/lib/kubernetes/ca.crt
  132  ls -l /run/systemd/resolve/resolv.conf
  133  systemctl status systemd-resolved.service
  134  systemctl start systemd-resolved.service
  135  systemctl enable systemd-resolved.service
  136  cat <<EOF | sudo tee /var/lib/kubelet/kubelet-config.yaml
  137  kind: KubeletConfiguration
  138  apiVersion: kubelet.config.k8s.io/v1beta1
  139  authentication:
  140    anonymous:
  141      enabled: false
  142    webhook:
  143      enabled: true
  144    x509:
  145      clientCAFile: "/var/lib/kubernetes/ca.crt"
  146  authorization:
  147    mode: Webhook
  148  clusterDomain: "cluster.local"
  149  clusterDNS:
  150    - "10.96.0.10"
  151  resolvConf: "/run/systemd/resolve/resolv.conf"
  152  runtimeRequestTimeout: "15m"
  153  EOF
  154  more /var/lib/kubelet/kubelet-config.yaml
  155  cat <<EOF | sudo tee /etc/systemd/system/kubelet.service
  156  [Unit]
  157  Description=Kubernetes Kubelet
  158  Documentation=https://github.com/kubernetes/kubernetes
  159  After=docker.service
  160  Requires=docker.service
  161  [Service]
  162  ExecStart=/usr/local/bin/kubelet \\
  163    --bootstrap-kubeconfig="/var/lib/kubelet/bootstrap-kubeconfig" \\
  164    --config=/var/lib/kubelet/kubelet-config.yaml \\
  165    --image-pull-progress-deadline=2m \\
  166    --kubeconfig=/var/lib/kubelet/kubeconfig \\
  167    --cert-dir=/var/lib/kubelet/pki/ \\
  168    --rotate-certificates=true \\
  169    --rotate-server-certificates=true \\
  170    --network-plugin=cni \\
  171    --register-node=true \\
  172    --v=2
  173  Restart=on-failure
  174  RestartSec=5
  175  [Install]
  176  WantedBy=multi-user.target
  177  EOF
  178  ls -l "/var/lib/kubelet/bootstrap-kubeconfig"
  179  ls -l /var/lib/kubelet/kubeconfig
  180  ls -l /var/lib/kube-proxy/kubeconfig
  181  ls -l
  182  cd ../keys/
  183  ls -l
  184  ls -l /var/lib/kube-proxy/kubeconfig
  185  cat <<EOF | sudo tee /var/lib/kube-proxy/kube-proxy-config.yaml
  186  kind: KubeProxyConfiguration
  187  apiVersion: kubeproxy.config.k8s.io/v1alpha1
  188  clientConnection:
  189    kubeconfig: "/var/lib/kube-proxy/kubeconfig"
  190  mode: "iptables"
  191  clusterCIDR: "172.31.0.0/20"
  192  EOF
  193  ls -l /var/lib/kube-proxy/kube-proxy-config.yaml
  194  ls -l /var/lib/kube-proxy/
  195  cat <<EOF | sudo tee /etc/systemd/system/kube-proxy.service
  196  [Unit]
  197  Description=Kubernetes Kube Proxy
  198  Documentation=https://github.com/kubernetes/kubernetes
  199  [Service]
  200  ExecStart=/usr/local/bin/kube-proxy \\
  201    --config=/var/lib/kube-proxy/kube-proxy-config.yaml
  202  Restart=on-failure
  203  RestartSec=5
  204  [Install]
  205  WantedBy=multi-user.target
  206  EOF
  207  ls -l /usr/local/bin/kube-proxy
  208  ls -l /var/lib/kube-proxy/kube-proxy-config.yaml
  209    sudo systemctl daemon-reload
  210  systemctl daemon-reload
  211    systemctl enable kubelet kube-proxy
  212    systemctl start kubelet kube-proxy
  213  systemctl status kubelet
  214  systemctl status kube-proxy
  215  kubectl get nodes
  216  kubectl get csr
  217  kubectl certificate approve csr-7gkdf
  218  kubectl get csr
  219  kubectl get nodes
  220  docker ps -a
  221  cd /etc/cni/net.d/
  222  ls -l
  223  cat 10-weave.conflist
  224  cd
  225  ls -l /opt/cni/bin/
  226  ls -l
  227  cd packages/
  228  ls -l
  229  docker ps -a
  230  kubectl get pods -o wide
  231  kubectl describe pods nginx-12-6d649cd655-p4z7p
  232  kubectl get pods -o wide
  233  ls -l
  234  cd packages/
  235  ls -l
  236  tar -xzvf cni-plugins-amd64-v0.7.5.tgz --directory /opt/cni/bin/
  237  kubectl get pods -o wide
  238  kubectl describe pods nginx-12-6d649cd655-p4z7p
  239  kubectl get pods -o wide
  240  cd ../keys/
  241  ls -l
  242  ETCDCTL_API=3 etcdctl -w table member list  --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt  --cert=/etc/etcd/etcd-server.crt --key=/etc/etcd/etcd-server.key
  243  ETCDCTL_API=3 etcdctl -w table endpoint --cluster status --endpoints=https://127.0.0.1:2379  --cacert=/etc/etcd/ca.crt  --cert=/etc/etcd/etcd-server.crt --key=/etc/etcd/etcd-server.key
  244  cat /etc/osts
  245  cat /etc/hosts

==================================================

worker1


    1  ]sed -i 's/PermitRootLogin without-password/PermitRootLogin yes/' /etc/ssh/sshd_config
    2  systemctl restart sshd
    3  sed -i 's/PermitRootLogin without-password/PermitRootLogin yes/' /etc/ssh/sshd_config
    4  systemctl restart sshd
    5  echo -e "root123\nroot123\n" | passwd root
    6  hostnamectl set-hostname worker1
    7  ls -la
    8  cd keys/
    9  ls -l
   10  wget -q --show-progress --https-only --timestamping   https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kubectl   https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kube-proxy   https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kubelet
   11  ls -l
   12  more worker1.kubeconfig
   13  more kube-proxy.kubeconfig
   14  ls -l
   15  mkdir -p  /etc/cni/net.d   /opt/cni/bin   /var/lib/kubelet   /var/lib/kube-proxy   /var/lib/kubernetes   /var/run/kubernetes
   16  chmod +x kubectl kube-proxy kubelet
   17  mv kubectl kube-proxy kubelet /usr/local/bin/
   18  ls -l
   19  HOSTNAME=$(hostname -s)
   20  echo $HOSTNAME
   21    mv ${HOSTNAME}.key ${HOSTNAME}.crt /var/lib/kubelet/
   22    mv ${HOSTNAME}.kubeconfig /var/lib/kubelet/kubeconfig
   23    mv ca.crt /var/lib/kubernetes/
   24  ls -l /var/lib/kubelet/
   25  ls -l /var/lib/kubelet/kubeconfig
   26  ls -l
   27  cat <<EOF | sudo tee /var/lib/kubelet/kubelet-config.yaml
   28  kind: KubeletConfiguration
   29  apiVersion: kubelet.config.k8s.io/v1beta1
   30  authentication:
   31    anonymous:
   32      enabled: false
   33    webhook:
   34      enabled: true
   35    x509:
   36      clientCAFile: "/var/lib/kubernetes/ca.crt"
   37  authorization:
   38    mode: Webhook
   39  clusterDomain: "cluster.local"
   40  clusterDNS:
   41    - "10.96.0.10"
   42  resolvConf: "/run/systemd/resolve/resolv.conf"
   43  runtimeRequestTimeout: "15m"
   44  EOF
   45  more /var/lib/kubelet/kubelet-config.yaml
   46  cat <<EOF | sudo tee /etc/systemd/system/kubelet.service
   47  [Unit]
   48  Description=Kubernetes Kubelet
   49  Documentation=https://github.com/kubernetes/kubernetes
   50  After=docker.service
   51  Requires=docker.service
   52  [Service]
   53  ExecStart=/usr/local/bin/kubelet \\
   54    --config=/var/lib/kubelet/kubelet-config.yaml \\
   55    --image-pull-progress-deadline=2m \\
   56    --kubeconfig=/var/lib/kubelet/kubeconfig \\
   57    --tls-cert-file=/var/lib/kubelet/${HOSTNAME}.crt \\
   58    --tls-private-key-file=/var/lib/kubelet/${HOSTNAME}.key \\
   59    --network-plugin=cni \\
   60    --register-node=true \\
   61    --v=2
   62  Restart=on-failure
   63  RestartSec=5
   64  [Install]
   65  WantedBy=multi-user.target
   66  EOF
   67  ls -l /var/lib/kubelet/kubelet-config.yaml
   68  more /etc/systemd/system/kubelet.service
   69  mv kube-proxy.kubeconfig /var/lib/kube-proxy/kubeconfig
   70   cat <<EOF | sudo tee /var/lib/kube-proxy/kube-proxy-config.yaml
   71  kind: KubeProxyConfiguration
   72  apiVersion: kubeproxy.config.k8s.io/v1alpha1
   73  clientConnection:
   74    kubeconfig: "/var/lib/kube-proxy/kubeconfig"
   75  mode: "iptables"
   76  clusterCIDR: "172.31.0.0/20"
   77  EOF
   78  more /var/lib/kube-proxy/kube-proxy-config.yaml
   79  cat <<EOF | sudo tee /etc/systemd/system/kube-proxy.service
   80  [Unit]
   81  Description=Kubernetes Kube Proxy
   82  Documentation=https://github.com/kubernetes/kubernetes
   83  [Service]
   84  ExecStart=/usr/local/bin/kube-proxy \\
   85    --config=/var/lib/kube-proxy/kube-proxy-config.yaml
   86  Restart=on-failure
   87  RestartSec=5
   88  [Install]
   89  WantedBy=multi-user.target
   90  EO
   91  rm  /etc/systemd/system/kube-proxy.service
   92  cat <<EOF | sudo tee /etc/systemd/system/kube-proxy.service
   93  [Unit]
   94  Description=Kubernetes Kube Proxy
   95  Documentation=https://github.com/kubernetes/kubernetes
   96  [Service]
   97  ExecStart=/usr/local/bin/kube-proxy \\
   98    --config=/var/lib/kube-proxy/kube-proxy-config.yaml
   99  Restart=on-failure
  100  RestartSec=5
  101  [Install]
  102  WantedBy=multi-user.target
  103  EOF
  104  more /etc/systemd/system/kube-proxy.service
  105  ls -l /etc/systemd/system/kube*
  106    systemctl daemon-reload
  107    systemctl enable kubelet kube-proxy
  108    systemctl start kubelet kube-proxy
  109  systemctl status kubelet
  110  systemctl status kube-proxy
  111  systemctl start kubelet
  112  more /etc/systemd/system/kubelet.service
  113  apt-key fingerprint 0EBFCD88
  114  apt-get install     apt-transport-https     ca-certificates     curl     gnupg-agent     software-properties-common
  115  apt-get update
  116  apt-get install     apt-transport-https     ca-certificates     curl     gnupg-agent     software-properties-common
  117  curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
  118  curl -fsSL https://download.docker.com/linux/ubuntu/gpg | apt-key add -
  119  apt-key fingerprint 0EBFCD88
  120  add-apt-repository    "deb [arch=amd64] https://download.docker.com/linux/ubuntu \
  121     $(lsb_release -cs) \
  122     stable"
  123  apt-get update
  124  apt-get install docker-ce docker-ce-cli containerd.io
  125  apt-cache madison docker-ce
  126  docker run hello-world
  127  docker ps -a
  128  history
  129  systemctl status docker.s
  130  systemctl status docker
  131  systemctl status docker.service
  132  systemctl enable docker.service
  133  systemctl status kubelet.service
  134  systemctl start kubelet.service
  135  systemctl status kubelet.service
  136  kubectl get pods
  137  kubectl get nodes
  138  ls -l
  139  wget https://github.com/containernetworking/plugins/releases/download/v0.7.5/cni-plugins-amd64-v0.7.5.tgz
  140  tar -xzvf cni-plugins-amd64-v0.7.5.tgz --directory /opt/cni/bin/
  141  ls -l
  142  scp cni-plugins-amd64-v0.7.5.tgzcni-plugins-amd64-v0.7.5.tgz worker2:/root/
  143  cat /etc/hosts
  144  vi /etc/hosts
  145  scp cni-plugins-amd64-v0.7.5.tgzcni-plugins-amd64-v0.7.5.tgz worker2:/root/
  146  ssh worker2
  147  l s-l
  148  ls -l
  149  scp cni-plugins-amd64-v0.7.5.tgz worker2:/root/
  150  ssh worker2
  151  ls -l /run/systemd/resolve/resolv.conf
  152  cd /var/lib/kubelet/
  153  ls -l
  154  cd /run/systemd/r
  155  cd /run/systemd/
  156  ls -l
  157  resolvectl status
  158  systemctl list-unit-file | grep -i resol
  159  systemctl list-unit-files | grep -i resol
  160  systemctl status systemd-resolved.service
  161  more /lib/systemd/system/systemd-resolved.service
  162  systemctl enable systemd-resolved.service
  163  systemctl status systemd-resolved.service
  164  systemctl start systemd-resolved.service
  165  ls -l
  166  cd resolve/
  167  ls -l
  168  cat resolv.conf
  169  cd
  170  docker ps -a
  171  docker logs 2be4bad228e9
  172  docker logs 2433c31df794
  173  docker ps -a
  174  docker exec -it 2433c31df794 bash
  175  docker exec -it 2433c31df794 /bin/bash
  176  docker exec -it 2433c31df794 /bin/sh
  177  docker exec -itd 2433c31df794 /bin/sh
  178  docker exec -itd 2433c31df794 /bin/sh uname -a
  179  docker exec -it 2433c31df794 /bin/sh uname -a
  180  docker exec -it 2433c31df794 /bin/sh -- uname -a
  181  docker exec -it 2433c31df794 /bin/sh
  182  docker ps -a
  183  k
  184  ln -s /var/run/docker/netns /var/run/
  185  ip netns
  186  docker ps -a
  187  docker ps -a
  188  docker exec -it 4a91feb47853 -c weave -- ls -l /home/weave/
  189  docker ps -a
  190  docker exec -it bd81af8be623 -c weave -- ls -l /home/weave/
  191  docker exec -it bd81af8be623 -- ls -l /home/weave/
  192  docker exec -it bd81af8be623 ls -l /home/weave/
  193  docker exec -it bd81af8be623 /home/weave/weave --local status
  194  kubectl get pods
  195  cat /etc/resolv.conf
  196  docker ps -a | grep -i busybox
  197  free -m
  198  docker exec -it d19483c98b80 nslookup kubernetes
  199  ip a
  200  free -m
  201  top
  202  free -m
  203  cd pa
  204  ls -l
  205  scp cni-plugins-amd64-v0.7.5.tgz master3:/root/packages/

worker2
===========
    1  sed -i 's/PermitRootLogin without-password/PermitRootLogin yes/' /etc/ssh/sshd_config
    2  systemctl restart sshd
    3  echo -e "root123\nroot123\n" | passwd root
    4  hostnamectl set-hostname worker2
    5  apt-key fingerprint 0EBFCD88
    6  apt-get install     apt-transport-https     ca-certificates     curl     gnupg-agent     software-properties-common
    7  apt-get update
    8  curl -fsSL https://download.docker.com/linux/ubuntu/gpg | apt-key add -
    9  apt-key fingerprint 0EBFCD88
   10  apt-get update
   11  add-apt-repository    "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) 122     stable"
   12  apt-get update
   13  apt-get install docker-ce docker-ce-cli containerd.io
   14  docker run hello-world
   15  docker ps -a
   16  systemctl status docker.service
   17  systemctl enable docker.service
   18  ls -l
   19  mkdir packages
   20  cd packages/
   21  ls -l
   22  wget -q --show-progress --https-only --timestamping   https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kubectl   https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kube-proxy   https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kubelet
   23  mkdir -p /etc/cni/net.d /opt/cni/bin  /var/lib/kubelet  /var/lib/kube-proxy  /var/lib/kubernetes /var/run/kubernetes
   24  chmod +x kubectl kube-proxy kubelet
   25  mv kubectl kube-proxy kubelet /usr/local/bin/
   26  mv ca.crt /var/lib/kubernetes/
   27  cd ../keys/
   28  mv ca.crt /var/lib/kubernetes/
   29  hostid
   30  cat > bootstrap-token-07401b.yaml <<EOF
   31  apiVersion: v1
   32  kind: Secret
   33  metadata:
   34    # Name MUST be of form "bootstrap-token-<token id>"
   35    name: bootstrap-token-07401b
   36    namespace: kube-system
   37  # Type MUST be 'bootstrap.kubernetes.io/token'
   38  type: bootstrap.kubernetes.io/token
   39  stringData:
   40    # Human readable description. Optional.
   41    description: "The default bootstrap token generated by 'kubeadm init'."
   42    # Token ID and secret. Required.
   43    token-id: 07401b
   44    token-secret: f395accd246ae52d
   45    # Expiration. Optional.
   46    expiration: 2021-03-10T03:22:11Z
   47    # Allowed usages.
   48    usage-bootstrap-authentication: "true"
   49    usage-bootstrap-signing: "true"
   50    # Extra groups to authenticate the token as. Must start with "system:bootstrappers:"
   51    auth-extra-groups: system:bootstrappers:worker
   52  EOF
   53  more bootstrap-token-07401b.yaml
   54  ls -l
   55  kubectl create -f bootstrap-token-07401b.yaml
   56  ls -l /var/lib/kubelet/bootstrap-kubeconfig
   57  cd keys/
   58  ls -lrt
   59  kubectl config --kubeconfig=/var/lib/kubelet/bootstrap-kubeconfig set-cluster bootstrap --server='https://172.31.29.55:6443' --certificate-authority=/var/lib/kubernetes/ca.crt
   60  file /var/lib/kubelet/bootstrap-kubeconfig
   61  more /var/lib/kubelet/bootstrap-kubeconfig
   62  kubectl config --kubeconfig=/var/lib/kubelet/bootstrap-kubeconfig set-credentials kubelet-bootstrap --token=07401b.f395accd246ae52d
   63  more /var/lib/kubelet/bootstrap-kubeconfig
   64  kubectl config --kubeconfig=/var/lib/kubelet/bootstrap-kubeconfig set-context bootstrap --user=kubelet-bootstrap --cluster=bootstrap
   65  more /var/lib/kubelet/bootstrap-kubeconfig
   66  kubectl config --kubeconfig=/var/lib/kubelet/bootstrap-kubeconfig use-context bootstrap
   67  kubectl config get-contexts
   68  kubectl config get-contexts --all-namespaces
   69  kubectl config get-contexts --kubeconfig=/var/lib/kubelet/bootstrap-kubeconfig
   70  kubectl config get-contexts
   71  cat <<EOF | sudo tee /var/lib/kubelet/kubelet-config.yaml
   72  kind: KubeletConfiguration
   73  apiVersion: kubelet.config.k8s.io/v1beta1
   74  authentication:
   75    anonymous:
   76      enabled: false
   77    webhook:
   78      enabled: true
   79    x509:
   80      clientCAFile: "/var/lib/kubernetes/ca.crt"
   81  authorization:
   82    mode: Webhook
   83  clusterDomain: "cluster.local"
   84  clusterDNS:
   85    - "10.96.0.10"
   86  resolvConf: "/run/systemd/resolve/resolv.conf"
   87  runtimeRequestTimeout: "15m"
   88  EOF
   89  more /var/lib/kubelet/kubelet-config.yaml
   90  cat <<EOF | sudo tee /etc/systemd/system/kubelet.service
   91  [Unit]
   92  Description=Kubernetes Kubelet
   93  Documentation=https://github.com/kubernetes/kubernetes
   94  After=docker.service
   95  Requires=docker.service
   96  [Service]
   97  ExecStart=/usr/local/bin/kubelet \\
   98    --bootstrap-kubeconfig="/var/lib/kubelet/bootstrap-kubeconfig" \\
   99    --config=/var/lib/kubelet/kubelet-config.yaml \\
  100    --image-pull-progress-deadline=2m \\
  101    --kubeconfig=/var/lib/kubelet/kubeconfig \\
  102    --cert-dir=/var/lib/kubelet/pki/ \\
  103    --rotate-certificates=true \\
  104    --rotate-server-certificates=true \\
  105    --network-plugin=cni \\
  106    --register-node=true \\
  107    --v=2
  108  Restart=on-failure
  109  RestartSec=5
  110  [Install]
  111  WantedBy=multi-user.target
  112  EOF
  113  ls -l /var/lib/kubelet/bootstrap-kubeconfig
  114  ls -l /var/lib/kubelet/kubeconfig
  115  ls -l
  116  mv kube-proxy.kubeconfig /var/lib/kube-proxy/kubeconfig
  117  ls -l /var/lib/kubelet/kubeconfig
  118  cat <<EOF | sudo tee /var/lib/kube-proxy/kube-proxy-config.yaml
  119  kind: KubeProxyConfiguration
  120  apiVersion: kubeproxy.config.k8s.io/v1alpha1
  121  clientConnection:
  122    kubeconfig: "/var/lib/kube-proxy/kubeconfig"
  123  mode: "iptables"
  124  clusterCIDR: "172.31.0.0/20"
  125  EOF
  126  more /var/lib/kube-proxy/kube-proxy-config.yaml
  127  cat <<EOF | sudo tee /etc/systemd/system/kube-proxy.service
  128  [Unit]
  129  Description=Kubernetes Kube Proxy
  130  Documentation=https://github.com/kubernetes/kubernetes
  131  [Service]
  132  ExecStart=/usr/local/bin/kube-proxy \\
  133    --config=/var/lib/kube-proxy/kube-proxy-config.yaml
  134  Restart=on-failure
  135  RestartSec=5
  136  [Install]
  137  WantedBy=multi-user.target
  138  EOF
  139  ls -l /var/lib/kubelet/kubeconfig
  140  cat /var/lib/kubelet/kubelet-config.yaml
  141  cat /etc/systemd/system/kubelet.service
  142  systemctl daemon-reload
  143  systemctl enable kubelet kube-proxy
  144  systemctl start kubelet kube-proxy
  145  systemctl status kubelet
  146  ls -l /var/lib/kubelet/
  147  cat /var/lib/kubelet/kubeconfig
  148  more /etc/systemd/system/kubelet.service
  149  kubectl get csr
  150  tar -xzvf cni-plugins-amd64-v0.7.5.tgz --directory /opt/cni/bin/
  151  ls -l
  152  cd packages/
  153  ls -l
  154  cd ..
  155  tar -xzvf cni-plugins-amd64-v0.7.5.tgz --directory /opt/cni/bin/
  156  systemctl status resolvconf.service
  157  systemctl status systemd-resolved.service
  158  systemctl enable systemd-resolved.service
  159  systemctl start systemd-resolved.service
  160  ls -l /var/lib/kube-proxy/
  161  ls -l /opt/cni/bin/
